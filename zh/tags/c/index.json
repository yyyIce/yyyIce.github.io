[{"content":"机器学习入门 1 基本概念 　注：仅作简要介绍，帮助理解。需要阅读或学习过《机器学习》、《线性代数》课程（可以没学明白，但得上过课）。\n1.1 线性代数 　向量在机器学习中就是对象的属性列表，可以理解为一个属性list，比如[白(颜色), 体积(大), 成熟(是否成熟)]，颜色、体积、成熟程度显然没有在一个次元里，不能直接做加减乘除运算，直接运算（比如三个值相加）没有任何实际意义；为了计算出合理而有意义的值，用一个列表来表示这些属性，每一个属性处在自己的维度中，这就是线性代数，然后利用线性代数定义的规则进行运算。为了计算方便，用不同的字母表示这些属性[a, b, c]。\n　很多文章用二维三维图来帮助理解线性代数，读完以后【困惑增加了】，二维三维图是为了帮助理解线性代数的几何含义，理解这些属性在维度上的区别和联系，即虽然它们不在同一个维度里，依然能够互相影响，证明线性代数运算法则的正确性。\n1.2 监督学习 　数据集中的每条记录都包含一个标签或标志；即数据集有明确的分类结果。\n 回归：输出连续值，比如预测粗糙度。模型包括支持向量机（SVM），人工神经网络，logistic回归，决策树和随机树； 分类：输出0/1或者离散值，比如预测它不是一个好吃的瓜🍉。模型包括线性回归，贝叶斯线性回归，决策树回归。  1.3 无监督学习 　数据集中的记录不包含任何标签或标志；即数据集没有明确的分类\n 聚类：通过聚类算法把某些数据聚集在一起，表现为一团一团或一堆一堆。模型包括层次聚类，k- 均值聚类。  1.4 强化学习 　感知环境状态，根据反馈的结果(奖励，Reward)，学习出一个最大化长期总收益的策略（动作，Action），并不断强化策略。如AlphaGo。\n1.5 特征工程 　对上课内容没什么印象😅，我的理解是一种物体有很多个特征，但是不同场景下，一种物体和另一种物体区分开只需要其中几种特征（比如一个袋子中只有钢球和棉花球，只需要用软硬程度一种特征就可以区分了），特征工程就是在问题场景下，筛选出能够解决问题的特征，简化运算过程，节省计算资源。下面是几种特征分析方法的提名。\n　主成分分析（PCA）：线性降维方法，找出包含信息量较高的特征主成分。\n　前向搜索：最开始不选取任何特征，计算模型的交叉验证误差，然后选择最相关的特征，将这个特征加入到已有特征；重复选取其它所有候选特征直到达到期望数量的特征为止。\n　后向搜索：从所有特征开始。计算模型的交叉验证误差先移除最不相关的特征，对其它所有候选特征，重复这一过程直到达到期望数量的特征为止。\n1.6 模型  摘录总结自《机器学习》周志华\n 　机器学习研究的主要内容是这样一种学习算法：利用计算机，从数据中产生模型的算法。\n　模型：把经验数据提供给学习算法，学习算法根据这些数据产生模型，即从数据中学得的结果。\n1.7 查准率(Precision)和查全率(Recall) 　Precision和Recall通常用来评估机器学习模型的性能。\n　🍓查全率很多人称为召回率，但召回和其计算方式完全找不到联系，个人这个翻译不够灵活，不利于理解。\n TP：真正例(True Positive)，真值1，预测值1； FP：假正例(False Positive)，真值0，预测值1； TN：真反例(True Negative)，真值0，预测值0； FN：假反例(False Negative)，真值1，预测值0；  　查准率(Precision)计算方法：P=TP/(TP+FP)；\n　查全率(Recall)计算方法：R=TP/(TP+FN)。\n2 过程 2.1 工具 　数据：csv文件\n　编程语言：便于学习的Python。\n pandas：数据分析库，扩展了数据关系，提供了大量能使我们快速便捷地处理数据的函数和方法。可用于导入数据 numpy：是一个由多维数组对象和用于处理数组的例程集合组成的库。可完成基础数值计算。 matplotlib：用于数据可视化，与numpy一起使用，成为了有效地Matlab开源替代方案。 scikit-learn：开源的Python机器学习库，提供了大量用于数据挖掘和分析的工具，包括数据预处理、交叉验证、算法与可视化算法等一系列接口。基本功能分为六个部分，分类，回归，聚类，数据降维，模型选择，数据预处理。  　ipython notebook：是一个 Web应用程序，便于创建和共享文学化程序文档，支持实时代码，数学方程，可视化和markdown。 用途包括：数据清理和转换，数值模拟，统计建模，机器学习等等。第3章中Kaggle的Code平台就是用的这个应用程序。\n2.2 机器学习方法应用流程 得到数据集，开始使用机器学习方法：\n　-\u0026gt;了解数据(箱型图、密度图/直方图、散点图)\n　-\u0026gt;数据预处理（处理缺失值和异常值；利用特征工程选出特征）\n　-\u0026gt;把数据拆分为测试集和训练集\n　-\u0026gt;挑选一个模型\n　-\u0026gt;使用管道组装\n　-\u0026gt;训练模型-\u0026gt;使用模型，输入测试集\n　-\u0026gt;评估模型并可视化\n　-\u0026gt;调整超参数（人为设置的参数）\n了解数据的方法：\n 箱型图：识别异常值 密度图/直方图：显示数据的分布 散点图：描述双变量关系  3 练习 　暂时用大家都推荐的平台进行学习和探索：https://www.kaggle.com/\n　选用kaggle的Titanic教程进行练习，参考其教程，对教程进行解析，不再重复其平台操作教程。\n　📣：可能找不到控制台，Code就是控制台，改过好多次名。\n 参考练习的教程：https://www.kaggle.com/alexisbcook/titanic-tutorial\n 3.1 问题描述 　Titanic：什么样的人更有可能生存？使用乘客数据（即姓名，年龄，性别，社会经济舱等）\n　数据集：给定了训练集train.csv和test.csv。train.csv给定了乘客的详细属性以及是否获救。test.csv没有标定乘客的获救信息。使用891个数据生成的预测模型，预测418名乘客是否获救。\n　输出：一个csv文件，包含两列，一共418行，第一列为PassengerId，第二列为Survived，值为0/1。\n　属性集：PassengerId、Survived(0-未获救，1-获救)、Pclass(社会经济地位代表，1-高，2-中，3-低)、Name、Sex、Age(20% missing)、SibSp(几个兄弟/配偶)、Parch(几个孩子/父母)、Ticket、Fare。\n3.2 了解数据 　用pandas读入数据，用scikit-learn建立机器学习模型。\n pandas文档：https://pandas.pydata.org/pandas-docs/stable/\nsklearn文档：https://scikit-learn.org/stable/\n 3.2.1 读入数据 1 2 3 4 5  #pd.read_csv读取csv文件，test_data是DataFrame对象 test_data = pd.read_csv(\u0026#34;/kaggle/input/titanic/test.csv\u0026#34;) train_data = pd.read_csv(\u0026#34;/kaggle/input/titanic/train.csv\u0026#34;) #dataFrame.head()，列出该dataFrame的前5行 test_data.head()   图1 输出test_data的前5行:\r\r 3.2.2 粗略分析数据 　下面的代码中，dataFrame.loc[行][列]表示提取指定的行和列，这里提取Sex=female的行对应的Survived列。一共有314行，women的长度为314，而获救的Survived值为1，所以可以用sum(women)快速统计获救的女性数量，从而用sum(women)/len(women)计算出女性获救的比率。\n1 2 3 4 5 6 7 8 9 10 11  #提取Sex=female的行对应的Survived列 women = train_data.loc[train_data.Sex == \u0026#39;female\u0026#39;][\u0026#34;Survived\u0026#34;] print(women) rate_women = sum(women)/len(women) print(\u0026#34;% of women who survived:\u0026#34;, rate_women) men = train_data.loc[train_data.Sex == \u0026#39;male\u0026#39;][\u0026#34;Survived\u0026#34;] rate_men = sum(men)/len(men) print(\u0026#34;% of men who survived:\u0026#34;, rate_men)   图2 输出男性和女性获救的比率:\r\r 　可以看出性别是一个很强的获救特征。而仅通过一个特征就可能做出有效的预测，如果考虑多个特征（列），可能会有更有效地预测结果，可以通过机器学习（实际就是利用线性代数进行运算）来完成综合多个列的预测。\n3.2.3 处理空值 　观察数据，发现年龄有空值，并且根据常识，年龄可能会影响获救，考虑处理年龄的空值。(根据实际情况，年龄丢失的，应当100%未获救，获救怎么可能唯独不知道年龄，除非收集好的数据在后续存储出现了丢失）\n　两种办法处理空值：（1）删除[8]；（2）填充\n　根据个人水平（很🥦），选择为年龄填充平均值的方法（猜测填充众数更合理）：\n1 2 3 4 5  #fill na age with avg #inplace : boolean, 默认值 False。如果为Ture,在原地填满。 #fill na age with avg train_data[\u0026#39;Age\u0026#39;].fillna(train_data[\u0026#39;Age\u0026#39;].mean(),inplace = True) test_data[\u0026#39;Age\u0026#39;].fillna(test_data[\u0026#39;Age\u0026#39;].mean(),inplace = True)   3.3 拆分数据集 　这里已经拆好数据集和测试集，直接使用即可。\n3.4 了解模型，选择模型 　这里没有进行比较，为教学说明，直接选择了随机森林模型。\n3.4.1 随机森林  随机森林内容引用：https://easyai.tech/ai-definition/random-forest/\n 　随机森林由许多决策树构成，不同决策树之间没有关联；当执行分类任务时，输入样本，样本进入每一棵决策树进行判断，每棵树会得到一个分类结果，最终属于哪个分类的结果最多，就把该样本判断为哪个分类。\n决策树形成：\n 一个样本容量为N的样本，有放回的抽取N次，每次抽取1个，最终形成了N个样本。这选择好了的N个样本用来训练一个决策树，作为决策树根节点处的样本。 当每个样本有M个属性时，在决策树的每个节点需要分裂时，随机从这M个属性中选取出m个属性，满足条件m \u0026laquo; M。然后从这m个属性中采用某种策略（比如说信息增益）来选择1个属性作为该节点的分裂属性。 决策树形成过程中每个节点都要按照步骤2来分裂（很容易理解，如果下一次该节点选出来的那一个属性是刚刚其父节点分裂时用过的属性，则该节点已经达到了叶子节点，无须继续分裂了）。一直到不能够再分裂为止。注意整个决策树形成过程中没有进行剪枝。 按照步骤1~3建立大量的决策树，这样就构成了随机森林了。  优缺点：\n 优点：实现简单；无需降维，无需特征选择，可用于高维数据；有部分特征遗失，仍可以维持准确度；训练速度较快，容易实现并行方法。 缺点：取值划分多的属性会对随机森林产生更大的影响。  实现：\n　DolphinDB速度最快，scikit-learn效果也不错。\n　这里选用scikit-learn的python包sklearn，其随机森林类为RandomForestClassifier。\n3.5 训练并预测 　开始训练并预测：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  from sklearn.ensemble import RandomForestClassifier y = train_data[\u0026#34;Survived\u0026#34;] features = [\u0026#34;Pclass\u0026#34;, \u0026#34;Sex\u0026#34;, \u0026#34;SibSp\u0026#34;, \u0026#34;Parch\u0026#34;, \u0026#34;Age\u0026#34;] #get_demmies(data,...)提取指定特征，即从train_data中提取这5个特征 X = pd.get_dummies(train_data[features]) X_test = pd.get_dummies(test_data[features]) #n_estimators：随机森林中树的个数；max_depth：树的最大深度；random_state：随机状态，默认由np.numpy生成 model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1) #fit:X是输入数据，y是标签 model.fit(X, y) #predict的返回值是数值，表示样本属于每一个类别的概率 predictions = model.predict(X_test) output = pd.DataFrame({\u0026#39;PassengerId\u0026#39;: test_data.PassengerId, \u0026#39;Survived\u0026#39;: predictions}) output.to_csv(\u0026#39;my_submission.csv\u0026#39;, index=False) print(\u0026#34;Your submission was successfully saved!\u0026#34;)   　结果出现下图，则预测成功。\n图3 训练成功:\r\r 　然后右上角点击Save Version。保存好后重新进入Code页面，选择该Work，右边栏选择Output，选中该文件，然后Submit。\n图4 Code页面:\r\r 图5 Output页面提交:\r\r 　提交后查看结果，😅。\n图6 预测结果1:\r\r 　不使用Age特征的结果，🤓。\n图7 预测结果2:\r\r 　🍰机器学习的体验过程到这里就结束了。\n参考资料 1.机器学习基础：https://developer.ibm.com/zh/articles/introduction-to-machine-learning/\n2.机器学习入门实战：https://developer.ibm.com/zh/tutorials/build-and-test-your-first-machine-learning-model-using-python-and-scikit-learn/\n3.学习机器学习之如何根据需求选择一种算法：https://blog.csdn.net/weixin_43730955/article/details/100599229\n4.如何正确选择机器学习算法：https://zhuanlan.zhihu.com/p/141985216\n5.随身GPU服务器：Kaggle中kernels的快速入门指南：https://oldpan.me/archives/kaggle-kernels-quick-introduction\n6.pandas读取或选择某几列：https://blog.csdn.net/aaa_aaa1sdf/article/details/77414387\n7.fillna方法实现部分自动填充：https://zhuanlan.zhihu.com/p/114319226\n8.[数据清洗]pandas dataframe空值的处理方法：https://zhuanlan.zhihu.com/p/35321806\n9.将DataFrame某列中的空值填充为0：https://blog.csdn.net/weixin_43474731/article/details/101689897\n","description":"包括机器学习的基本概念，运用机器学习方法的过程以及一个简单的机器学习方法运用实例","id":3,"section":"posts","tags":["分布式"],"title":"研究方法：机器学习","uri":"https://yyyIce.github.io/zh/posts/%E7%A0%94%E7%A9%B6%E6%96%B9%E6%B3%95%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"content":"　论文名称：Offloading Real-time DDoS Attack Detection to Programmable Data Planes\n　会议信息：2020 IFIP Networking Conference (Networking)\n　成果：在受到DDoS攻击时，源IP地址和目标IP地址的分布往往会偏离合法模式，本文参考异常检测常用特征，由m个数据包内的源IP和目的IP的熵计算源IP和目的IP的集中趋势指数和分散指数，利用两个指数在可编程数据平面进行DDoS攻击检测。\n　前人工作不足：防御机制依赖于监视原语：分组采样(sFlow)、基于流的统计(NetFlow、OpenFlow)，监视原语带来数据包处理和资源利用的大量开销（采样和草图），控制循环长，检测等待时间长。Snoata、Marple基于可编程数据平面配置自适应过滤器，由滤波器确定需要转发到控制平面进行检查的数据包流，影响了网络使用率，用于攻击检测可能造成较高的延迟；StateSec是完全基于软件的SDN DDoS攻击检测机制，但速度较慢。\n　本文工作：在转发设备上完全实现实时DDoS攻击检测。估计传入数据包源IP和目的IP的熵，用熵值计算两个特征的阈值——集中趋势指数和分散指数，用于检测DDoS攻击。为满足转发设备的限制，使用定点表示法表示浮点数，通过专门定制的计数草图(sketch)估算不同IP地址的频数，使用LPM表查找的方式近似对数运算，利用熵值增减减少直接根据公式计算熵值的计算量。\n一、背景 　DDoS攻击检测的现有方案理论上可行，但基本存在检测时间长、对网络使用率影响大、速度慢等缺点。文章参考异常入侵检测的方法，通过观测源IP地址和目的IP地址的香农信息熵计算两个特征指数，得到源IP地址和目的IP地址的分布，从而判断是否发生DDoS攻击。\n香农信息熵 　香农信息熵：衡量信息的不确定程度，越不确定，熵越大。\n自信息量  信息出现的概率越大，不确定程度越小，不确定性函数f是概率P的减函数； 两个独立符号所产生的不确定性应该等于各自不确定性之和，即f(P1,P2)=f(P1)+f(P2)，即可加性。  　对数函数满足上述两个条件：f(P) = log(1/p)=-log(p)\n　I(X)：自信息量，I(x)=log(1/x)\n　信息熵是信息量的期望（均值），它不是针对每条信息，而是针对整个不确定性结果集而言，信息熵越大，事件不确定性就越大。单条信息只能从某种程度上影响结果集概率的分布。\n图1 信息熵:\r\r 二、本文的工作 　攻击场景和威胁模型：攻击者协调分布各地的主机，向单个受害者发送非法的服务请求\n　假设DDoS攻击的特征是大量主机流量汇聚到一个或几个受害者，在存在恶意活动的情况下，源IP地址和目的IP地址的分布往往偏离合法模式。\n　估计输入数据包流的连续分区(观察窗口)的IP地址的熵，在每个观察窗口的结尾，用流量表征单元读取熵值以生成合法的流量模型(即两个特征指数：EWMA和EWMMD)；异常检测单元根据模型计算2个值，判断是否发生DDoS攻击，如果发生DDoS攻击则发出警报。\n图2 DDOS攻击检测模型:\r\r 三、实现 1 熵估计模块 熵的推导 　设X为每个窗口中的全部IP地址，共计m个，N种，则：\n图3 m个IP地址的熵计算:\r\r 　当m能够充分代表当前源、目的IP地址的分布时，发生攻击时，源IP地址的熵随其频数的增加而增大，目的IP地址的熵随其频数的增加而降低。\n　m值增大，则每次测量需要接收更多的数据包，从而增加攻击检测延迟；m值减小，则无法区分与恶意流量相关的分布变化与合法流量的短期波动。\n熵估计的实现 图4 IP地址的熵:\r\r 　得到的熵计算式对于可编程交换机来说较为复杂，文章利用近似来简化计算过程：\n 使用Count-Sketch估计窗口中IP地址的频数 将m设置为2的乘方，以便log2(m)是整数，并且熵计算式的第二项S/m可以表示为移位计算 用熵的增量计算下一个窗口的熵值 提前计算不同频数下熵的增量值，构建LPM查找表，Key为频数  图5 熵估计流水线:\r\r Count Sketch数据结构：d个寄存器(深度)，共w个槽(宽度)，每个槽是一个IP地址的计数器和该IP所在窗口的ID\n  哈希函数h_i将IP地址映射到第i个寄存器的槽中\n  哈希函数g_i确定IP地址的计数器是递增还是递减的，处理h_i的IP地址冲突\n  定义了两个操作：\n Update(C;x)：计数器的值（哈希h_i）加上哈希g_i的结果 Estimate(C,x)：x出现的频率计数的估计值，d个哈希g_i和哈希h_i的乘积的中位数，此中位数作为频数    图6 Count-Sketch计算流程:\r频数估计方法\r\r 图7 熵值估算方法:\r\r 2 流量表征模块 　计算两个指数表征流量：\n 集中趋势指数Mn：指数加权移动平均值（EWMA） 分散指数Dn：指数加权移动平均差（EWMMD）  图8 指数计算公式:\r\r 3 异常检测模块 　成立下图中的一个条件，就会触发DDoS攻击警报：\n图9 异常检测公式:\r\r 　其中k是灵敏度系数，k值增加会使检测条件更严格，以获得更高的准确性；k值降低可能会增加误报，从而扩大异常检测的覆盖范围。\n四、评估 1 实验环境 数据集  合法流量：CAIDA Anonymized Internet Traces 2016 恶意流量：CAIDA DDoS Attack 2007  P4实现  为每个Sketch分配一个32位寄存器，并为其关联的观察窗口标识符分配一个8位寄存器。 考虑到具有4个小数位的定点表示形式，我们将S和H的估值存储在32位寄存器中。 建立LPM查找表，以确保每个条目的最大误差为2^(-4)，总共245个TCAM条目。  参数设置 图10 系统参数设置:\r\r 2 评估结果 　熵估计误差随着Sketch宽度的增加而减小，但是这种减小随着宽度的增加而衰减并稳定在接近1％的水平；Sketch深度的增加会减少碰撞概率，但增加深度会导致需要对每个IP地址处理更多的Hash函数，增加值运算的复杂性。\n图11 熵估计误差与Sketch宽度和深度的关系:\r\r 　较低的灵敏度系数值会提高检测阈值，从而导致较高的检测率，但会造成高误报率。生产网络中具有动态性，可能需要定期调整k值。\n图12 灵敏度系数和真阳性假阳性的关系:\r\r 　恶意流量所占的比例越高，检测准确率将越来越高（超过90％），该精度受计数草图宽度的影响很大。\n图13 恶意流量占比和检测准确率的关系:\r\r 　与sFlow对比，文章题出的方法均比sFlow(采样比为1:100和1:1000)好。\n图14 与sFlow对比:\r\r ","description":"在受到DDoS攻击时，源IP地址和目标IP地址的分布往往会偏离合法模式，本文参考异常检测常用特征，由m个数据包内的源IP和目的IP的熵计算源IP和目的IP的集中趋势指数和分散指数，利用两个指数在可编程数据平面进行DDoS攻击检测。","id":4,"section":"posts","tags":["P4"],"title":"论文阅读：卸载实时DDoS攻击检测到可编程数据平面","uri":"https://yyyIce.github.io/zh/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E5%8D%B8%E8%BD%BD%E5%AE%9E%E6%97%B6ddos%E6%94%BB%E5%87%BB%E6%A3%80%E6%B5%8B%E5%88%B0%E5%8F%AF%E7%BC%96%E7%A8%8B%E6%95%B0%E6%8D%AE%E5%B9%B3%E9%9D%A2/"},{"content":"　论文名称：Machine-learning-assisted DDoS attack detection with P4 language\n　会议信息：2020 IEEE International Conference on Communications (ICC). IEEE, 2020: 1-6.\n　成果：开发了用于SDN网络的机器学习辅助DDoS攻击检测框架，利用P4可编程数据平面完成特征提取，减少检测延迟。\n　前人工作不足：在SDN控制器上进行特征提取造成延迟较大。\n　本文工作：利用P4可编程数据平面完成特征提取，定期向控制器报告特征，在控制器上利用三种机器学习算法对特征进行二分类，做出决策，实时检测DDoS攻击（以TCP Flood攻击为例）。\n一、背景 　软件定义网络（SDN）与传统网络相比具有许多优势，如自动化网络控制、有效资源利用、灵活和快速的重配置等。由于SDN控制器的集中式特点，它容易受到DDoS攻击，发送非法数据包会使控制器超载，从而抑制数据平面设备的正常运行，即使DDoS攻击的目标不是SDN控制器，由于SDN交换机实现的默认转发策略，它也可能被淹没。\n　DDoS攻击检测（DAD）需要自动学习流量中的隐藏模式并检测异常，通常依赖于机器学习（ML）。 已有的解决方案包括使用支持向量机分类器（SVM）、使用string kernel改进SVM分类、深度递归神经网络、改进k-近邻等方法。利用状态数据平面协助DDoS攻击检测是最近的研究趋势。\n　针对网络/传输级的DDoS防御机制：基于源、基于目标、基于网络。\nTCP Flood 　攻击者伪装成多个IP地址向受害者同时发送多个SYN请求，受害者的系统发送ACK响应，等待SYN-ACK数据包，攻击者不发送SYN-ACK数据包，导致受害者一直等待，资源被大量消耗，直至死机，导致受害者无法响应其它正常用户的TCP连接请求。\n　攻击者需要注意，伪装的IP地址不能够对收到的SYN-ACK数据包进行响应。\n 防御手段参考1：https://www.cnblogs.com/sunsky303/p/11811097.html\n 减少SYN-ACK数据包的重发次数； 使用SYN Cookie； 增加backlog队列； 限制SYN并发数。  SYN Flood原理防御手段参考2：https://blog.csdn.net/shixin_0125/article/details/78829069\n　TCB(TCP 传输控制块)是一种包含一个连接所有信息的传输协议数据结构(实际上在许多操作系统中它是用于处理进站(inbound)连接请求的一个队列，该队列保存那些处于半开放(half-open)状态的TCP连接项目，以及已建立完整连接但仍未由应用程序通过accept()调用提取的项目)。\n　一个单一的TCB所占内存大小取决于连接中所用的TCP选项和其他一些功能的实现。通常一个TCB至少280字节，在某些操作系统中已经超过了1300字节。TCP的SYN-RECEIVED状态用于指出这个连接仅仅是半开连接，请求是否合法仍被质疑。注意，TCB分配空间的大小取决于接收的SYN包。\n　到达的SYN包将被分配过多的TCB而导致主机的内核内存被耗尽。为了避免这种内存耗尽，操作系统通常给监听接口关联了一个\u0026quot;backlog\u0026quot;队列参数，它同时维护连接的TCB上限数量和SYN-RECEIVED状态。尽管这种方案使主机的可用内存免遭攻击，但是backlog队列本身就带来了一个(小的)受攻击源。当backlog中没有空间时，就不可能再响应新的连接请求，除非TCB能被回收或者从SYN-RECIEVE状态中移除。\n　试图发送足够多的SYN包而耗尽backlog是TCP SYN洪泛的目的。攻击者在SYN包中加入源IP地址，这样就不会导致主机将已分配的TCB从SYN-RECEVIED状态队列中移除(因为主机将响应SYN-ACK)。因为TCP是可靠的，目的主机在断开半开连接并在SYN-RECIEVED队列中移除TCB之前将等待相当长的时间。在此期间，服务器将不能响应其他应用程序合法的新TCP连接请求。\n 　根据TCP Flood原理，基于目标的防御手段可以采用参考1中的方法，如SYN Cookie，基于网络的防御方法包括过滤（用处不大）、防火墙代理、活动监视器。\n 防火墙作为客户端和服务器之间的代理，在防火墙上配置SYN Cookies或SYN缓存，只需要防火墙顶住SYN Flood攻击。 活动监视器如果发现SYN包来源于它知道的攻击者源地址就会立刻发送伪装RST包给服务器，释放SYN连接。  二、本文的工作 　文章采用基于网络的防御机制，结合机器学习和P4有效执行DDoS攻击中的TCP Flood检测。正确的攻击检测需要耗时且昂贵的深度数据包检查，需要减轻SDN控制器的负担，所以文章使用P4可编程数据平面进行数据包处理，并将DDoS攻击检测建模为基于机器学习的分类问题。文章说他们是第一个将机器学习和P4数据平面结合的工作。\n三、实现 　攻击检测系统整体框架如下图。\n图1 整体框架:\r\r 机器学习检测模块 　DDoS攻击检测模块定期从P4交换机接收流量信息，根据该信息执行攻击检测，决定是否转发数据包。检测模块对给定时间间隔内观察到的流量（即，一个或多个数据包到达P4交换机）输出决策，即标签为攻击或无攻击表示在所考虑的时间范围内是否存在攻击。\n　检测模块由两部分组成：\n 特征提取器； 机器学习分类器。  　特征提取器：提取5个特征\n Len(t)：时间窗口中数据包的平均大小，以字节为单位； RTCP(t):TCP数据包在时间窗口总数中所占的百分比； RUDP(t)：UDP数据包在时间窗口总数中所占的百分比； RTU(t)：时间窗口（t，t + T）中TCP和UDP数据包之间的比率。 Flags(t)：具有活动SYN标志的TCP数据包在总时间窗口（t，t + T）中所占的百分比。  　机器学习算法：二分类，输出0表示no attack，1表示TCP flood。\n 随机森林（RF）； 最近邻（KNN）； 支持向量机（SVM）。  P4程序 　流量信息在滑动窗口（持续时间为T）的基础上定期（每δ秒）从P4交换机发送到检测模块，每个窗口都包含最近T秒的信息，独立于其他窗口进行；然后利用分类得到的标签执行数据包操作，如丢弃。\n　文章使用P4_14语言。\n　程序定义三层协议和四层协议的数据包头部；定义自定义头部，包括switch_id和4个2字节的字段，报告总数、TCP、UDP、TCP SYN数据包的数量。\n　程序定义4个寄存器：存储IP、UDP、TCP、SYN数据包数量。\n　程序定义4张Match-Action Table：m_ip、m_transport、m_syn、go_header。\n　各类型数据包到来时，匹配对应的Table(如m_transport)，触发相应动作，更新寄存器（如udp_action）的值；\n　在流量窗口的数据包计数(meta.counter_tot)达到允许的最大数据包数时，应用go_header表，将自定义头部插入数据包(动作为add_int)，将寄存器中的值和和结果数据包发送到检测模块，然后寄存器复位(go_read_reset)。\n图2 部分P4代码:\r\r 四、评估 实验设置 　在具有8×2 GHz处理器和8 GB RAM的桌面上，使用keras和sklearn库，已经使用基于Python的脚本实现了ML算法。\n　使用Spirent N4U流量生成器收集用于训练和测试算法的流量数据。\n　生成了30分钟的流量，其中将10、50或100 kbit/s恒定比特率的TCP Flood攻击流添加到10 Mbit/s的常规后台流量中。攻击的平均持续时间为10秒，后台流量由三种不同的流量组成：4.5 Mbit/s TCP流量，3.8 Mbit/s UDP流量和1.7 Mbit/s IP流量，数据包长度遵循iMix分配。对所有持续时间为T的窗口，并仅在其包含至少一个属于TCP泛洪攻击的数据包时才分配标签1：TCP flood，否则为该窗口分配标签0：noattack。\n　实验调整了两个连续窗口之间的距离，即参数δ，因此数据集中窗口的总数取决于δ的值，δ=1s时，窗口总数为1800，δ=0.05s时，窗口总数为36000。对于每对(T，δ)都会生成一个新的数据集，用于训练和测试算法。\n表1 数据集流量参数:\r\r 机器学习算法性能评估 　对于所有机器学习算法，采用k倍交叉验证(k=5)，计算平均分类精度，并进行超参数选择(SVM中的kernel、RF中的树数、KNN中的邻居数)。\n　评估指标：\n 分类精度 算法复杂度：训练持续时间和预测时间  窗口距离δ的影响 　固定T=1s，逐渐增加δ值，观察分类精度（a）和算法复杂度（b、c）\n图4 T不变，分类精度和算法复杂度结果:\r\r  (a)：分类精度上，RF分类器 \u0026gt; SVM分类器 \u0026gt; KNN分类器；对于所有分类器，随着δ值增加，分类精度降低，这是因为数据集较小。 (b)：在训练和测试总时间（交叉验证时间）上，它随δ的增加而减少，其中RF的降幅最小，并且交叉验证时间最短。 (c)：测试时间上，SVM在δ≥0.1时测试时间最短，而δ值不显著影响RF和KNN的测试时间。  　综合来看，随机森林分类器（RF）和支持向量机（SVM）都是DDoS攻击检测的备选算法，RF的精度更高，SVM的算法复杂度更低。\n窗口持续时间T的影响 　固定δ=0.2s，逐渐增加T值。\n　分类精度上，RF分类器 \u0026gt; SVM分类器 \u0026gt; KNN分类器；对于所有分类器，随着T值增加，分类精度降低，是因为窗口持续时间相对于攻击来说过大，与常规背景流量相比，窗口中存在的攻击数据包数量较少，这使得识别攻击特征更加困难。\n图5 δ不变，分类精度:\r\r P4交换机中实现DDoS攻击检测 　假设已经部署了最合适的机器学习算法，评估在数据平面进行特征提取引入的延迟影响。考虑3种P4交换机向分类器提供流量信息的情况：\n a：发送数据包镜像到分类器 b：发送数据包头部到分类器 c：从头部提取信息存入元数据，将元数据发送到分类器  确定三种延迟：\n t1：P4交换机处理数据包的时间，并将数据包发送到攻击检测模块的时间； t2：在攻击检测模块中提取窗口特征所需时间； t3：分类器分类时间。  　分类器选择RF和SVM算法，对两种算法进行模型选择，RF采用10种不同的树和基于Gini impurity的分割标准，SVM分类器采用基于Radial的函数内核。\n　在T=1s，δ=0.2s的参数下，使用在Linux Box上运行BMV2，在Intel Xeon CPU E5-2620 v2 @ 2.10GHz，RAM 16GB和10G以太网光接口来评估P4交换机引入的延迟，并使用Spirent N4U Traffic Generator和分析仪进行测量。并按表1所示注入流量配置文件。\n　得到的结果如表2。\n表2 不同情况下的耗时:\r\r 　P4交换机提取特征并处理数据包大概只需要110μs，而在外部特征提取模块中提取特征需要14-16s，在交换机上所需的额外时间可以忽略不计，而分类时间取决于所选用的机器学习算法。\n参考资料 Spirent N4U：https://www.spirent.com/products/testcenter-ethernet-ip-cloud-test\n","description":"利用P4和机器学习算法，以TCP Flood为例，基于网络进行DDoS攻击检测","id":5,"section":"posts","tags":["P4"],"title":"论文阅读：基于P4的机器学习辅助DDoS攻击检测","uri":"https://yyyIce.github.io/zh/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E5%9F%BA%E4%BA%8Ep4%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%BE%85%E5%8A%A9ddos%E6%94%BB%E5%87%BB%E6%A3%80%E6%B5%8B/"},{"content":"　论文名称：P4DAD: Securing Duplicate Address Detection Using P4\n　会议信息：2020 IEEE International Conference on Communications (ICC). IEEE, 2020: 1-7.\n　成果：提出了P4DAD，是一种轻量级，可部署，健壮，安全的DAD机制。通过引入P4，P4DAD无需修改NDP或主机堆栈即可保护网络中的NDP消息。\n　前人工作不足：轻量、部署难易程度、健壮性、安全性不能兼顾。\n　本文工作：提出P4DAD的安全重复地址检测机制，并在bmv2上实现P4DAD原型，并从功能、性能、可扩展性三方面进行评估。\n一、背景 1.NDP(Neighbor Discovery Protocol) 　仅做简要介绍。\n 来源：RFC4861\n参考：https://cshihong.github.io/2018/01/29/IPv6%E9%82%BB%E5%B1%85%E5%8F%91%E7%8E%B0%E5%8D%8F%E8%AE%AE/\n NDP简介 　邻居发现协议，用于IPv6，负责在链路上发现其他节点和相应的IP地址，并确定可用路由和维护关于可用路径和其他活动节点的信息可达性。\n　和ARP的功能相似，在IPv6中通过NDP获得目标主机的链路层地址。NDP基于ICMPv6实现，以太网协议类型为0x86DD，即IPv6报文，下一个报头字段值为58，表示ICMPv6报文，NDP的所有报文都封装在ICMPv6报文中。\n　地址解析过程中使用了两种ICMPv6报文：\n 邻居请求报文NS（Neighbor Solicitation）：Type=135，Code=0，类似于ARP请求报文； 邻居通告报文NA（Neighbor Advertisement）：Type=136，Code=0，类似于ARP应答报文。  图1 NDP流程 :\r\r 　主机A向主机B发送报文之前必须知道B的链路层地址，所以主机A发送NS报文，主机A的链路层地址放在Options字段中；主机B收到NS报文以后，回应NA报文，主机B的链路层地址被放在Options字段中。\n重复地址检测(Duplicate Address Detect)  参考：https://zhuanlan.zhihu.com/p/110407399\n 　当节点获取到一个IPv6地址后，需要使用重复地址检测功能确定该地址是否已被其他节点使用（与IPv4的Gratuitous ARP功能相似）。通过NS和NA可以实现重复地址检测。\n Gratuitous ARP，无故（免费）ARP\n没有人问自己的情况下，无缘无故自问自答，是设备发送的一个发送端IP地址和目标IP地址都是本设备IP地址的ARP request/reply报文。\n如果ARP request收到了ARP reply，说明网络中存在和自己IP地址相同的设备。\n参考：https://zhiliao.h3c.com/Theme/details/27896\n 　在进行DAD检测时，一个IPv6单播地址在分配给一个接口之后且通过重复地址检测之前称为试验地址（Tentative Address）。此时该接口不能使用这个试验地址进行单播通信，但是仍然会加入两个组播组：ALL-NODES组播组和实验地址所对应的Solicited-Node组播组。\n　IPv6重复地址检测技术和IPv4中的Gratuitous ARP类似：节点向一个自己将使用的试验地址所在的Solicited-Node组播组发送一个以该实验地址为请求的目标地址的NS报文，如果收到节点回应的NA报文，就证明该地址已被网络上使用，节点将不能使用该实验地址通讯。\n图2 DAD示例 :\r\r 　PC1的IPv6地址2000::1为新配置地址，即2000::1为PC1的试验地址。PC1向2000::1的Solicited-Node组播组发送一个以2000::1为请求的目标地址的NS报文进行重复地址检测，由于2000::1并未正式指定，所以NS报文的源地址为未指定地址。当PC2收到该NS报文后，有两种处理方法：\n 如果PC2发现2000::1是自身的一个实验地址，则PC2放弃使用这个地址作为接口地址，并且不会发送NA报文。 如果PC2发现2000::1是一个已经正常使用的地址，那么PC2会向该地址的ALL-NODES组播组发送一个NA报文，该消息中会包含2000::1。这样，PC1收到这个消息后就会发现自身的实验地址是重复的，从而弃用该地址。  安全威胁  引用：https://www.secrss.com/articles/13813\n 　重复地址检测攻击：当目标节点向FF02 :: 16所有节点发送NS数据包进行重复地址检测时，攻击者可向该节点发送NA报文进行响应，并表明该地址已被自己使用。当节点接收到该地址已被占用消息后重新生成新的IPv6地址并再一次进行重复地址检测时，攻击者可继续进行NA响应实现DoS攻击。使目标节点无法配置任何地址。\n　泛洪攻击：攻击者可伪造不同网络前缀RA消息对FF02 :: 1进行泛洪攻击，接收节点将会根据不同的网络前缀进行更新，从而消耗大量的CPU资源。\n　2020年，将有超过200亿的物联网设备连接到互联网。这些物联网设备倾向于使用IPv6地址进行通信，并且它们仍需要使用重复地址检测机制来确定IPv6地址的唯一性。\n已有解决方案 　本文针对重复地址检测攻击的防御，在这个问题上基本有三种解决方案：\n 隐藏目标地址：发送NS数据包时将目标地址隐藏在NS消息中，NS消息不直接填写地址，而是填写地址的哈希值。其他主机计算自己地址的哈希值，与NS消息中的值进行比较。这需要对NDP进行修改。 验证NDP消息：将消息认证码附加到NDP消息。这需要对NDP进行修改。 统一答复NA消息：利用一个可靠的中央节点统一答复NA消息，其它节点发送的NA消息都将被忽略。它面临单点故障问题。  　表1总结了现有方案的局限性。\n表1 现有方案局限性:\r\r 二、本文的工作 　目标：增强重复地址检测的安全性，轻量（无哈希）易部署（不修改网络堆栈）且健壮（无中央节点）。\n　基于P4设计安全的重复地址检测机制。文章假设主机直接连接到交换机，主机可能是恶意的，交换机是可信任的。\n　解决两个挑战：每个主机通常配置多个IPv6地址；在本地配置和填充交换机的流规则。\n三、设计及实现 1 P4DAD设计 1）在解析器中提取NS/NA消息中的地址\n2）用有状态寄存器在数据平面中保留端口和IPv6地址的绑定，允许同一端口对应多个IPv6地址。\n3）P4DAD将所需信息的摘要以数据包形式传到控制平面，并通知控制面实时填充流规则。\nP4DAD的总体设计如图3。\n图3 P4DAD总体设计:\r\r NS/NA数据包经过的动作匹配表如表2。\n表2 NS/NA消息经过的功能:\r\r 2 P4程序实现 　解析器解析数据包头部字段。\n　ipv6_reg：记录主机IPv6地址与交换机端口的映射关系。使用2个寄存器，寄存器1的槽中存储IPv6地址，寄存器2中存储IPv6地址状态（暂定tentative，首选preferred，不推荐使用deprecated）\n　寄存器索引计算：索引号 = 主机IPv6地址个数 × 交换机端口号 + 该端口已保存的IPv6地址数量。如图4。\n图4 P4DAD寄存器设计:\r\r 　Match-Aciton表包括MAC-learning表、Target-Address-Query表、Forwarding表\n　Mac-learning表：使用packet digest，将摘要发送到控制平面实现MAC学习。\n　Target-Address-Query表：\n 如果数据包是NS包，且Target Address不在表中，则将其IPv6值和状态存入寄存器1和寄存器2中(default action)，并通知控制平面为表添加条目； 如果数据包是NA包，并且Target Address不在表中，说明发生了欺骗，丢弃。 如果数据包是NA包，并且Target Address在表中，则获取其索引(action)，根据索引从寄存器1和寄存器2中获取IPv6地址及其状态；  如果IPv6地址的状态为tentative，则P4DAD会重置对应的寄存器1和寄存器2。    3 P4DAD工作流程 　NS/NA消息通过匹配Target-Address-Query表防御重复地址检测DoS攻击。\n　主机1和主机2（恶意主机）分别配置了IPv6地址，因此IPv6 1和IPv6 2的绑定条目已在P4交换机1中建立。主机3和主机4正在进行DAD进程。\n　主机3尝试配置与主机1相同的IPv6地址，主机4配置新地址。\n　当P4交换机2接收到主机3和主机4发送的NS数据包时，将建立IPv6 1和IPv6 3的绑定条目，并将相应的IPv6地址状态设置为tentative。\n　主机1将回复以IPv6 1为源地址和目标地址的NA数据包。但恶意主机2将分别发送两个以IPv6 1和IPv6 3为Target Address的欺骗性NA数据包。当P4交换机1接收到欺骗性的NA数据包时，将对它们进行直接过滤，因为Target-Address-Query表中没有该Target Address的表项，即连接该交换机的主机没有此IPv6地址。这意味着可以有效地防止DAD受到DoS攻击。\n　当P4交换机2收到主机1发送的NA报文时，将清除IPv6 1的绑定表项。当P4交换机2在特定时间未收到有关IPv6 3的NA数据包时，相应的IPv6地址状态将设置为preferred。\n图5 P4DAD工作流程:\r\r 4 原型实现 　P4DAD原型由数据平面程序和控制平面程序组成。\n 数据平面程序由P4_16实现，可以直接在bmv2上编译。 控制平面程序是用Python编写的，它通过notifications-addr与数据平面通信。  四、评估 　实验在Intel®Core™i7-7700 CPU和7840 MB RAM的Dell OptiPlex 7050服务器上进行。\n功能测试 　将安装有parasite6工具的两个虚拟机（受害者和攻击者）连接到由bmv2实现的P4软件交换机。\n　攻击者随机发送欺骗性NS/NA消息，而受害者随机发送标准NS/NA消息。\n　计算由攻击者和受害者分别发送的数据包数量以及由P4DAD接收和过滤的数据包数量， 结果发现P4DAD过滤的数据包数量等于攻击者发送的数据包数量，这意味着P4DAD可以有效识别和过滤欺骗的NS/NA消息。\n性能测试 　选择原始NDP的性能（不进行任何更改）作为基准，并比较P4DAD和基准之间NS/NA消息的处理时间。\n　NS-For-DAD和NS-For-Others分别表示为用于处理DAD和其他NDP功能的NS消息，如图6所示。\n　NS-for-DAD和NA-for-DAD的P4DAD的处理时间大于基线，而NS-for-Others和NA-for-Others的P4DAD的处理时间非常接近基线，原因是NS-for-DAD和NA-for-DAD的操作比基线多三到四次。\n图6 交换机处理NS/NA消息的时间:\r\r 　文章测量从数据平面摘要数据包信息的开始到控制平面填充流规则结束的时间，平均时间为4.126毫秒。\n通常，DAD仅出现在地址配置过程中，而控制平面和数据平面之间的通信仅需要在DAD的过程中进行。因此，P4DAD带来的处理开销可以忽略不计。\n可扩展性测试 　增加主机数量时，测量P4交换机的内存消耗以评估P4DAD的可伸缩性。\n　P4DAD的内存消耗随主机数量线性增加，表明P4DAD具有令人满意的可扩展性。\n","description":"提出了P4DAD，是一种轻量级，可部署，健壮，安全的DAD机制。通过引入P4，P4DAD无需修改NDP或主机堆栈即可保护网络中的NDP消息。","id":6,"section":"posts","tags":["P4"],"title":"论文阅读：基于P4的安全重复地址检测","uri":"https://yyyIce.github.io/zh/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E5%9F%BA%E4%BA%8Ep4%E7%9A%84%E5%AE%89%E5%85%A8%E9%87%8D%E5%A4%8D%E5%9C%B0%E5%9D%80%E6%A3%80%E6%B5%8B/"},{"content":"　论文名称：Defeating Protocol Abuse with P4: Application to Explicit Congestion Notification\n　会议信息：2020 IFIP Networking Conference (Networking)\n　成果：提出进行网络验证的EFSM通用抽象，实现安全监视功能，以ECN为例在P4交换机中实现该抽象。\n　前人工作不足：P4CEP通过使用常规的有限状态机描述复杂的事件处理功能来简化P4的使用，可伸缩性不足，可能面临状态空间爆炸的危险。\n　本文工作：提出EFSM抽象，监视任何协议行为并对之做出反应；并将将EFSM模型映射到P4，以ECN为例对模型进行验证，对效果进行评估，建议部分部署EFSM。\n一、背景 1.ECN(Explicit Congestion Notification)  来源：RFC3168\n参考：https://blog.csdn.net/z1143709608/article/details/52682150\n 　在网络中的路由器的转发队列通常实现了Random Early Detection (RED)功能，即，路由器会根据当前转发队列的平均长度来做丢包决策，并且随机的丢弃一些TCP流量的报文，而不是等待队列溢出后丢弃全部的报文，这样能够很好的避免所有TCP同时超时的问题。由于按照队列的平均长度来进行丢包，而不是队列满长，所以会引起一部分TCP的退避，让一部分TCP先放缓，保证另一些TCP的通畅。并且使用随机丢弃，针对所有TCP连接来说是相对公平的。\n　在RFC3168中定义了ECN的设计目标，是通过TCP发送端和接收端以及中间路由器的配合，感知中间路径的拥塞，并主动的减缓TCP的发送速率，从而从早期避免拥塞而导致的丢包，实现网络性能的最大利用。能够解决的问题如下：\n 所有TCP发送端能够早期感知中间路径拥塞，并主动放缓发送速率，预防拥塞发生。 在中间路由器上转发的队列上，对于超过平均队列长度的TCP报文进行ECN标记，并继续进行转发，不再丢弃报文。避免了报文的丢弃和TCP的重传。 由于减少了丢包，TCP不需要经过几秒货几十秒的重传定时器出发报文重传，提高了时延敏感应用的用户感受。 与没有部署ECN功能的网络相比，网络的利用率更好，不再在过载和轻载之前来回震荡。  1.1 报文格式 IP头部的修改 　IP头部的TOS字段中的第7bit和8bit的res字段被重新定义为ECN字段，其中有四个取值\n 00代表该报文并不支持ECN，所以路由器的将该报文按照原始非ECN报文处理即可，即，过载丢包。 01和10这两个值针对路由器来说是一样的，都表明该报文支持ECN功能。01和10的具体区别请参考RFC3168。 如果发生拥塞，则ECN字段的这两个将修改为11来表示报文经过了拥塞，并继续被路由器转发。  　所以路由器转发侧要支持ECN，需要有以下新增功能：\n 当拥塞发生时，针对ECN=00的报文，走原有普通非ECN流程，进行RED丢包。 当拥塞发生时，针对ECN=01(ECT=1)或ECN=10(ECT=0)的报文，都需要修改为ECN=11，并继续转发流程。 当拥塞发生时，针对ECN=11(CE)的报文，需要继续转发。 为了保证与不支持ECN报文的公平性，在队列超过一定长度时，需要考虑对支持ECN报文的丢弃。  TCP头部的修改 　在主机端，将TCP头部的6位保留字段的后两位设置为CWR和ECE(即URG的前两位)。\n CWR：拥塞窗口缩小 ECE：ECN回显  　在RFC3168中设计如下：\n 在TCP接收端收到的IP头中有ECN=11标记，则在回复ACK时将ECE bit置1。并在后续的ACK总将ECE bit置1。 在TCP发送端收到ECE bit置1的ACK报文时，需要将自己的发送速率减半，并在发送下一个报文时，将CWR bit置1。 在接收端收到CWR bit置1的报文时，后续的ECE bit将不再置1。直到再次收到IP头部ECN=11时，重复上述过程。 TCP发送端在收到一个ECE=1时，缩小发送窗口，并且在本次RTT时间内将不再缩小发送窗口。 TCP接收端向发送端回应ACK时，如果该ACK是一个不带数据的“纯”ACK，那么IP头部必须设置ECN=00，因为TCP没有机制对纯ACK进行响应，就无法针对纯ACK发送拥塞通知。即握手阶段ECN=00。 对于支持IP ECN的主机，TCP层在发送报文时需要将IP首部中的ECN置为01或10。  安全问题  参考：TCP报文到达确认机制：http://blog.csdn.net/wjtxt/article/details/6606022\n　TCP数据包中的序列号（Sequence Number）不是以报文段来进行编号的，而是将连接生存周期内传输的所有数据当作一个字节流，序列号就是整个字节流中每个字节的编号。一个TCP数据包中包含多个字节流的数据（即数据段），而且每个TCP数据包中的数据大小不一定相同。在建立TCP连接的三次握手 过程中，通信双方各自已确定了初始的序号x和y，TCP每次传送的报文段中的序号字段值表示所要传送本报文中的第一个字节的序号。\n　TCP的报文到达确认（ACK），是对接收到的数据的最高序列号的确认，并向发送端返回一个下次接收时期望的TCP数据包的序列号（Ack Number）。例如， 主机A发送的当前数据序号是400，数据长度是100，则接收端收到后会返回一个确认号是501的确认号给主机A。\n　TCP提供的确认机制，可以在通信过程中可以不对每一个TCP数据包发出单独的确认包（Delayed ACK机制），而是在传送数据时，顺便把确认信息传出， 这样可以大大提高网络的利用率和传输效率。同时，TCP的确认机制，也可以一次确认多个数据报，例如，接收方收到了201，301，401的数据报，则只 需要对401的数据包进行确认即可，对401的数据包的确认也意味着401之前的所有数据包都已经确认，这样也可以提高系统的效率。\n　若发送方在规定时间内没有收到接收方的确认信息，就要将未被确认的数据包重新发送。接收方如果收到一个有差错的报文，则丢弃此报文，并不向发送方发送确认信息。因此，TCP报文的重传机制是由设置的超时定时器来决定的，在定时的时间内没有收到确认信息，则进行重传。这个定时的时间值的设定非常重要，太大会使包重传的延时比较大，太小则可能没有来得及收到对方的确认包发送方就再次重传，会使网络陷入无休止的重传过程中。接收方如果收到了重复的报文，将会丢弃重复的报文，但是必须发回确认信息，否则对方会再次发送。\n  终端主机宣布自己具有ECN功能但忽略来自交换机的拥塞通知，即收到ECN=11时，仍将ECE置0，导致发送方不减少拥塞窗口，造成拥塞； 在发送方已经减少拥塞窗口后，接收者仍然继续发送设置了ECE=1的数据包，导致拥塞窗口加倍减小，浪费带宽； 发送方在收到ECE=1之后，不将CWR置1，即不缩小拥塞窗口，造成拥塞。  　上述这三种不当行为都会严重降低网络性能。图1中箭头上蓝色字表示正确的ECN行为，红色的字表示错误的ECN行为。\n图1 ECN流程 :\r\r 二、本文的工作 　目标：实时监视网络流量识别协议滥用。\n　将协议规范转为扩展有限状态机(EFSM)，并用P4程序实现EFSM模型，编译P4程序并安装在PISA交换机上，通过维护每个连接的当前状态以及EFSM的所有相关变量来在线跟踪所有流。当EFSM模型进入标记为不当行为的状态时，程序可以触发不同的动作，如丢弃数据包、生成警报等。\n　以ECN为例，对此方法进行评估。\n图2 整体设计 :\r\r 三、实现 1 模型设计 　文章使用7元组(S, E, A, I, V, C, T)表示EFSM，各元含义如图3。\n图3 EFSM7元组:\r\r 　ECN的EFSM7元组对应实例如图4。\n图4 ECN的EFSM7元组:\r\r 　完整的ECN EFSM图模型如图5，然后使用P4交换机的Extern组件和P4程序实现这个模型。\n图5 ECN EFSM:\r\r 2 P4程序实现 2.1 Externs 　寄存器存储流状态：用寄存器存储连接状态，对五元组\u0026lt;dstIp、srcIp、dstPort、srcPort、协议\u0026gt;做HASH运算，得到该流五元组对应的寄存器索引，对于TCP连接的两个端点，如果dspIp \u0026gt; srcIp，按照\u0026lt;dstIp、srcIp、dstPort、srcPort、协议\u0026gt;的顺序做HASH运算，否则按照\u0026lt; srcIp、 dstIp、 srcPort、 dstPort、srcPort、协议\u0026gt;的顺序做HASH运算。一共6个状态，对应寄存器槽内的值是对应的状态，初始时为init状态。\n2.2 元数据  congestion：来自交换队列的占用级别 头部字段：标志位、校验和  2.3 匹配-动作表 　文章没有具体描述其设计，这里给出一个我理解的Naive 版本，如果仔细构思一下可能有更节省空间、更优雅的实现方式。\n   Key Action     流状态为init, ECT=1, congestion=1 CE=1, forward, 流状态改为congestion   流状态为congestion, ECE = 1 forward, 流状态改为notified   流状态为congestion, ECE = 0 ECE=1, update_chk, forward, 流状态改为notified(修正了misbehaving状态)   流状态为notified, CWR=1 forward, 流状态改为win_reduction   流状态为notified, CWR=0 drop, 流状态改为misbehaving   流状态为win_reduction, ECE=0 forward, 流状态改为notification_stopped   流状态为win_reduction, ECE=1 ECE=0, update_chk, forward, 流状态改为notification_stopped    2.4 动作  update_chk：使用增量过程计算数据包校验和，无需重新计算校验和。  TCP新校验和=旧校验和-TCP值字段的16位旧值的补码-16位字段的新值   forward drop CE置1 ECE置0  四、评估 　使用mininet构建网络，并使用P4-Bmv2交换机进行实验。构建的网络拓扑如图6。所有主机都具有ECN功能，并且链路延迟设置为1ms，限制了输出队列速率（默认为2000个数据包/秒）。根据先前工作，10 Gbits / s网络的情况下，65个数据包在交换机中排队后就发生了拥塞，对于mininet，观察到的最大吞吐量约为40 Mbits/s，因此队列中超过3个数据包就被视为拥塞，将触发事件congestion，从而离开EFSM的init状态。\n图6 网络拓扑图:\r\r  h1：不回显拥塞信息，即不设置TCP ECE标志，使h1成为异常主机； h1-\u0026gt;h2：异常流，在h1上使用iperf生成TCP流发送给h2。 h3-\u0026gt;h4：正常流，h3上使用iperf生成TCP流发送给h4。  　结果如图7， 其中noMisbehaving-forward表示h1-\u0026gt;h2，h3-\u0026gt;h4都是正常流；Misbehaving-noReaction表示h1行为异常，但交换机不做处理；Misbehaving-ECEreaction表示只实现了ECE纠正，未实现其它纠正；Misbehaving-fullReaction完全实现了图5的EFSM状态机。\n图7 ECN行为对带宽的影响:\r\r 　对于Misbehaving-noReaction，可以看到异常流h1-\u0026gt;h2消耗了大部分可用带宽，流h3-\u0026gt;h4受到了损失。实际上，正常流（h3-\u0026gt;h4）响应拥塞信号并降低其传输速率，从而为行为异常的流留出更多的队列空间，从而获得了更多的带宽份额。但是，有效吞吐量仍然受到发送方容量的限制，因此行为异常流的增加低于响应流吞吐量的损失。\n　对于Misbehaving-ECEreaction，重新正常的分配带宽，正常流的损失降低，但整体吞吐量下降。\n　对于Misbehaving-fullReaction，吞吐量严重下降，甚至不如Misbehaving-noReaction。\n　根据上述实验结果，建议部分部署EFSM。\n　在部署EFSM之前，必须先验证是否适合网络条件；EFSM越复杂，开销越高。（EFSM虽然有效但不是特别好）\n","description":"建立ECN滥用防御的EFSM(有限状态机)模型，并将其映射到P4程序上，实现数据平面的ECN滥用防御","id":7,"section":"posts","tags":["P4"],"title":"论文阅读：基于P4的ECN滥用防御","uri":"https://yyyIce.github.io/zh/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E5%9F%BA%E4%BA%8Ep4%E7%9A%84ecn%E5%8D%8F%E8%AE%AE%E6%BB%A5%E7%94%A8%E9%98%B2%E5%BE%A1/"},{"content":"1 概述 　S3: Simple Storage Service 是对象存储服务，具体来说是可以通过一个URL（如http://endpoint_url/\u0026lt;bucket_name\u0026gt;/\u0026lt;key\u0026gt;）获取存储对象，服务对外提供HTTP接口，可以通过PUT请求上传对象，GET请求获取对象等。\n　应用场景（大数据分析）：内容存储和分发；用于数据分析的存储；备份、存档与灾难恢复；静态网站托管。\n　从任意位置存储和检索任意数量的数据而构建的对象存储服务，是面向对象的文件系统，适合静态文件一次写入，不适合经常修改的文件。\n　S3中的概念Bucket 、Object 、Endpoint 、AccessKey 和SecretKey ：\n Bucket：存放Object的容器，不能嵌套。 Object：对象，包含key和value。 Endpoint：对外服务的访问域名。 AccessKey：ASCII字符串，用于标识客户身份。 SecretKey：ASC字符串，作为私钥存储在客户服务器，不在网络中传递；使用AccessKey进行身份识别，用SecretKey进行数字签名，从而完成应用接入与认证授权；用于访问桶、获取桶所在的数据中心。  2 对象存储 　扁平化的命名空间：将数据以对象（Object）形式存储在桶（Bucket）中，通过桶名称和对象的键名（Bucket_name + Key_name）来定位一个对象的最终路径。\n　对象（Object）：由键名（Key）、键值（Value）、访问控制列表（ACL）、元数据（Metadata）组成。\n图1 S3对象:\r\r 3 Amazon S3的使用 3.1 注册 　(1)普通免费一年的Amazon账号需要绑定银行卡，可能会产生奇怪的费用，所以我们使用学生账号，从https://www.awseducate.com/注册，注册后点击登录。\n图2 登录:\r\r 　(2)右上导航栏\u0026quot;AWS Acount\u0026quot;，点击“AWS Educate Starter Account”\n图3 进入学生账号:\r\r 　(3)进入下图页面后，点击AWS Console，即可进入AWS控制台\n图4 进入AWS控制台:\r\r 　(4)在控制台界面搜索S3，进入S3控制台\n图5 进入S3控制台:\r\r 　(5)创建一个Bucket用于测试\n图6 创建一个桶:\r\r 3.2 获取AcessKey和SecretKey 　在客户端使用S3时，需要配置认证Key，即AccessKey和SecretKey，才能和S3建立连接，普通用户在控制台主页搜索IAM，按照网上的解决方案生成AccessKey即可。教育账号需要在下图这个界面点击“Account Details”\n图7 进入AWS控制台:\r\r 　在弹出的子窗口中点击“show”，则能够获得AccessKey和SecretKey，其有效期是三小时\n图8 获取AccessKey:\r\r 3.3 使用python操作S3 　boto3是S3官方建议使用的python包，安装：\n1  $ pip install boto3   　连接到s3：使用上面2中获得的AccessKey和SecretKey就可以，不报错就连上了，注意一定要有session_token，否则会查找不到AccessKey。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  #!/usr/bin/python #encoding:utf-8  import boto3 from boto3.session import Session session = Session(aws_access_key_id=\u0026#39;ASIASR3FIDV6NEAZGO3V\u0026#39;, aws_secret_access_key=\u0026#39;1WuKe42HfTslTtMuH885D442t1OWVo/vg59Uk/N3\u0026#39;, aws_session_token=\u0026#39;\u0026lt;太长了，略过不写\u0026gt;\u0026#39;, region_name=\u0026#39;us-east-1\u0026#39;) s3 = session.resource(\u0026#39;s3\u0026#39;) client = session.client(\u0026#39;s3\u0026#39;) #上传 data = open(\u0026#39;pcapng-demo.pcap.pcapng\u0026#39;, \u0026#39;rb\u0026#39;) file_obj = s3.Bucket(\u0026#39;mesalybtest\u0026#39;).put_object(Key=\u0026#39;pcapng-demo.pcap.pcapng\u0026#39;, Body=data) #获取URL presigned_url = client.generate_presigned_url( \u0026#39;get_object\u0026#39;, Params={\u0026#39;Bucket\u0026#39;: file_obj.bucket_name, \u0026#39;Key\u0026#39;: file_obj.key}, ExpiresIn= 3600*30*12 ) print(presigned_url)   4 参考资料 1.一文读懂AWS S3：https://zhuanlan.zhihu.com/p/112057573\n2.对象存储概念：https://cloud.tencent.com/developer/article/1073409\n3.AWS S3开发指南：https://docs.aws.amazon.com/zh_cn/AmazonS3/latest/dev/VirtualHosting.html#path-style-access\n4.KS3对象存储概念：https://docs.ksyun.com/documents/2286\n5.file_transfer：https://docs.aws.amazon.com/code-samples/latest/catalog/python-s3-file_transfer-demo_file_transfer.py.html\n6.boto3官方使用：https://github.com/boto/boto3\n7.使用Python操作Amazon S3：https://xingzuoshe.cn/python-operate-s3.html\nbin/kafka-console-consumer.sh \u0026ndash;bootstrap-server localhost:9092 \u0026ndash;topic test \u0026ndash;from-beginning\n","description":"S3服务的使用","id":8,"section":"posts","tags":["分布式"],"title":"工具使用：S3","uri":"https://yyyIce.github.io/zh/posts/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8s3/"},{"content":"　论文名称：Distributed SIP DDoS Defense with P4\n　会议信息：2019 IEEE Wireless Communications and Networking Conference (WCNC)\n　成果：利用可编程交换机缓解SIP INVITE DDoS攻击\n　贡献：通过对以太网交换机的数据平面编程（P4）和控制平面编程进行实验，为每个交换端口的SIP INVITE DDoS攻击提供第一跳检测和缓解功能。\n　前人工作不足：基于目标的方法需要网络设备上大量CPU和内存资源；缺少第一跳检测和缓解，检测和识别SIP事务的传感器太少；缓解点数量有限。\n　本文工作：通过使用以太网交换机的数据平面编程进行SIP DDoS检测，对以太网交换机上每个端口的第一跳SIP DDoS攻击检测和缓解功能以及分布式SIP在网络边缘使用以太网交换机的DDoS防御方法。\n一、背景 1.SIP Flood攻击  来源：https://forum.huawei.com/enterprise/zh/thread-298913.html\n 　SIP(Session Initiation Protocol)是一个应用层的信令控制协议。用于创建、修改和释放一个或多个参与者的会话。这些会话可以是Internet多媒体会议、IP电话或多媒体分发。例如，SIP服务提供商可以建立包含语音、视频和聊天内容的全新媒体。\n1.1 SIP协议流程简介  参考：https://blog.csdn.net/c80486/article/details/43391961\n参考：https://www.w3cschool.cn/session_initiation_protocol/session_initiation_protocol_messaging.html\n 　SIP协议工作的流程和人打电话的过程是一样的，所以也称为软电话，不同之处不是通过讲话而是通过IP数据包来传递信息。\n　SIP默认端口为5060，默认采取UDP传输。\n　SIP账号：采用URI表示方法，即sip:username@ip:port，其中ip也可以填写服务器所属域名。\n　SIP消息：用来传递通话信号的IP数据包。包括6中核心消息：INVITE、BYE、REGISTER、CANCEL、ACK、OPTIONS。\n　SIP通话过程如图1。\n图1 SIP通话过程 :\r\r  Alice向Bob发送一个请求SIP消息INVITE，邀请Bob参与通话 Bob振铃，向Alice回复响应180 Ringing，通知Alice自己正在振铃，请Alice等待 Bob接起软电话，向Alice发送响应200 OK，通知Alice可以通话了 Alice向Bob发送请求SIP消息ACK，通话正式建立 然后开始通话，通过RTP或TCP Bob挂掉软电话，向Alice发送请求SIP消息BYE，通知Alice通话结束 Alice向B回复一个200 OK，通话结束。  1.2 SIP Flood的源认证防御原理  来源：https://blog.csdn.net/c80486/article/details/43391961\n 　攻击者通过发送大量的INVITE消息或REGISTER消息到SIP服务器，导致被攻击SIP服务器分配大量的资源用以记录和跟踪会话，直到资源耗尽而无法响应合法用户的呼叫请求；或者针对VoIP设备在SIP协议实现上的漏洞构造并发送相应的畸形SIP报文，从而导致SIP服务器拒绝服务。\n　OPTIONS方法用于SIP协议通信双方查询对方支持的方法、内容类型、扩展等。SIP源认证是发送OPTIONS请求报文作为探测报文探测源的真实性，如果发送端的源IP真实存在，就会对该探测报文进行回应，Anti-DDoS设备检查回应报文是否正确，正确则允许通过，将源IP地址加入白名单，否则丢弃报文。具体处理过程如图2所示。\n图2 SIP源认证 :\r\r 二、本文的工作 　P4控制器通过TCP套接字连接控制P4交换机。\n　交换机上的每个端口都可以对INVITE或REGISTER执行数据包检查，每个端口都有一个计数器，对收到的INVITE或REGISTER的数量进行计数。\n　P4控制器每秒都对这个计数器进行评估，确定是否发生了SIP INVITE Flood攻击，当确定发生了攻击时，它向P4交换机发送一条命令，以从该特定端口丢弃后续的INVITE或REGISTER数据包。当攻击停止1分钟后，P4控制器向P4交换机发送命令，从而恢复到正常处理模式。\n图3 系统设计 :\r\r 三、实现 1.1 P4控制器：Python脚本 　初始化：初始化表项，在sipinvite_table表中添加\u0026lt;入口端口 SIP数据包第一行\u0026gt;的表项，并设置默认操作为_nop（即无操作），例：table_add sipinvite_table _nop 2 0x494e56495445 =\u0026gt;\n　评估sipinvite计数器：计数器每秒检查每个交换机端口上的sipinvite_counter来实现攻击检测。例：counter_read sipinvite_counter 2，检查端口2接收到的SIP INVITE数据包的数量。\n　通过或放弃：当每秒超过10个SIP INVITE数据包时，将检测到SIP DOS攻击，为该端口激活DOS模式，即向P4交换机发送命令将表sipinvite_table的默认动作改为drop。当一分钟内SIP INVITE数据包的个数都低于阈值时，将端口设置为正常模式，即向P4交换机发送命令将表sipinvite_table的默认动作改为_nop。攻击停止后，允许合法用户在接下来的60秒内发起呼叫。\n图4 sipinvite_table表:\r\r 1.2 P4程序  定义以太网帧、IPv4、UDP、SIP数据包，在解析器中进行解析； 设置ipv4_lpm、forward、sipinvite_table表，前两个用于常规IP数据包转发，第三个表用于查找SIP INVITE，key是ingress_port和SIP INVITE。 定义了一个计数器来记录每个端口接收到的SIP INVITE数据包的数量，连接到sipinvite_table。  四、评估 　使用具有2GB RAM和2个CPU的Ubuntu虚拟机来运行mininet，在Ubuntu虚拟机上创建3个虚拟主机和3个虚拟交换机拓扑。\n SIP代理（10.0.0.1）连接到交换机1的端口1 攻击者（10.0.0.2）连接到交换机2的端口2 合法用户（10.0.0.3）连接到交换机- 3端口3  　控制器是python脚本，在主机上运行，并通过套接字连接与三个交换机通信（交换机1的端口TCP/22221，交换机2的TCP/22222和交换机3的TCP/ 22223）。\n　使用bmv2 P4兼容虚拟交换机，而不是mininet附带的默认虚拟交换机；用p4c-bm的P4配置生成器用于将P4代码转换为bmv2所需的JSON配置文件。\n　SIPp是用于生成SIP流量的SIP数据包生成工具。对于SIP代理，它设置为在用户代理服务器（UAS）模式下运行，而对于SIP客户端，它在用户代理客户端（UAC）模式下运行。\n　数据包捕获（pcap）实用工具tshark用于验证SIP代理（在交换机1：端口1）和SIP客户端（在交换机2：端口2）发送和接收的数据包。\n图5 测试环境:\r\r 　评估主要分为三个方面：检测和缓解能力；检测和缓解时间；系统资源消耗\n　评估跟踪变量：发送和接收的SIP INVITE数据包数；发送和接收的ICMP数据包数；CPU和内存消耗\n　评估结果表明：\n P4交换机仅丢弃SIP INVITE数据包，ICMP数据包不受影响，如果计算机感染了僵尸网络/恶意软件，则在阻止由恶意软件生成的SIP INVITE数据包的同时，用户仍然可以使用其他应用程序。 开始阻止SIP INVITE数据包所花费的时间为1.47秒。 在攻击期间，平均CPU利用率为24.49％（峰值为71％）。内存消耗最高达到3％。  ","description":"利用可编程交换机和P4语言实现基于源的SIP Flood攻击防御和缓解","id":9,"section":"posts","tags":["P4"],"title":"论文阅读：基于P4的SIP DDoS攻击防御","uri":"https://yyyIce.github.io/zh/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E5%9F%BA%E4%BA%8Ep4%E7%9A%84sip-ddos%E6%94%BB%E5%87%BB%E9%98%B2%E5%BE%A1/"},{"content":"1 概述 　Kafka是消息系统。\n  消息系统：在应用程序之间发送消息\n  应用场景：日志收集系统和消息系统，采用发布-订阅模式\n  常用的Message Queue：RabbitMQ(重量级)，Redis，ZeroMQ，ActiveMQ，Kafka\n  　kafka工作示意图：\n图1 kafka工作示意图:\r\r 　topic：消息类别\n　partition：topic中的数据分割成partition，partition中的数据由多个segment文件存储，partition中的数据（消息）是有序的；同一个Partition的Replica尽量分散到不同的机器上。\npartition中的0，1，2，3，是offset，也就是消息位置，由Consumer决定，Consumer消费完一条消息，会递增offset。\n　broker：存储partition的服务器节点，一个broker存储topic的一个partition；broker接收到生产者发送的消息后，将该消息追加到当前用于追加数据的segment文件中。\n　Producer使用push模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。（Push模式：主动发送内容更新；Pull模式：询问是否有更新）\n　Producer发送消息到broker，会根据Partition机制选择将其存储到哪个Partition，如果Partition机制设置合理，所有消息可以均匀分布到不同Partition中。在发送一条消息时，可以指定这条消息的key，Producer根据这个key和Partition机制来判断将这条消息发送到哪个Partition。\n　同一Topic的一条消息只能被同一个Consumer Group内的一个Consumer消费，但多个Consumer Group可同时消费这一消息。\n　广播：每个Consumer有一个独立的Group，单播：所有的Consumer在同一个Group里。\n　对于kafka而言，pull模式更合适，使Consumer自主控制消费消息的速率。\n　kafka默认保证 At least one，即消息绝不会丢，但可能会重复：体现在设置参数为auto_offset_reset='earliest'，如果Consumer Group中的一个Consumer挂了，剩余的Consumer会重新从头消费消息。\n　Producer和Consumer只与Leader交互，其他Replica作为Follower从Leader中复制数据。\n2 安装  安装方法：https://blog.csdn.net/qq_42881421/article/details/86741617\n软链接用法：https://blog.csdn.net/Leonis_v/article/details/52353706\n 安装环境：ubuntu16.0.4\n　(1)下载地址：https://kafka.apache.org/downloads\n　如：kafka_2.12-2.7.0.tgz，其中2.12是Scala版本号，2.7.0是kafka版本号。\n　(2)解压安装包\n1 2  $ cd soft/ $ tar -zxf kafka_2.11-0.10.2.0.tgz   　(3)配置环境变量\n1  $ nano ~/.bashrc   　添加下列语句：\n1 2  export KAFKA_HOME=~/soft/kafka export PATH=$PATH:$KAFKA_HOME/bin   　(4)保存后，让环境变量立即生效\n1  $ source ~/.bashrc   3 简单使用 3.1 使用官方提供的Shell脚本操作kafka 　在kafka的安装目录下：\n　启动Zookeeper：bin/zookeeper-server-start.sh config/zookeeper.properties\n1  bin/zookeeper-server-start.sh config/zookeeper.properties   　启动kafka：bin/kafka-server-start.sh config/server.properties\n1  bin/kafka-server-start.sh config/server.properties   　创建topic：bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor \u0026lt;\u0026gt; --partitions \u0026lt;partition_number\u0026gt; --topic \u0026lt;topic_name\u0026gt;\n1  bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test   　启动生产者：bin/kafka-console-producer.sh --broker-list \u0026lt;produce_servers\u0026gt; --topic \u0026lt;topic_name\u0026gt;\n1  bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test   　启动消费者：bin/kafka-console-consumer.sh --bootstrap-server \u0026lt;consume_servers\u0026gt; --topic \u0026lt;topic_name\u0026gt;--from-beginning\n1  bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning   3.2 使用Python操作Kafka 消费者 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  #!/usr/bin/python #encoding:utf-8  from kafka import KafkaConsumer import json \u0026#39;\u0026#39;\u0026#39; 消费者 消费test主题中的数据 注意事项：如需以json格式读取数据需加上value_deserializer参数 \u0026#39;\u0026#39;\u0026#39; def consume_to_kafka(): consumer = KafkaConsumer(\u0026#39;test1\u0026#39;, auto_offset_reset=\u0026#39;earliest\u0026#39;, bootstrap_servers=[\u0026#39;localhost:9092\u0026#39;], value_deserializer=lambda m: json.loads(m.decode(\u0026#39;ascii\u0026#39;)) ) for message in consumer: test_data = message.value url = test_data[\u0026#39;packet_url\u0026#39;] print(url) if __name__ == \u0026#34;__main__\u0026#34;: try: consume_to_kafka() except KeyboardInterrupt: print(\u0026#34;Quit.\u0026#34;)   生产者 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  #!/usr/bin/python #encoding:utf-8  from kafka import KafkaProducer import json def produce_one_item(topic, producer): pkt = { \u0026#34;id\u0026#34;: 1, \u0026#34;nicname\u0026#34;:\u0026#34;enp6s0\u0026#34;, \u0026#34;raw_packet\u0026#34;: \u0026#34;TOu9fJMVMKrkRBubCABFIAAoEh0AAHQGjPrYOtKuwKg8BwG75osRSr9s/dLbA1AQAQl1XgAAAAAAAAAA\u0026#34; } producer.send(topic, pkt) producer.close() def produce_more_items(count,topic,producer): i = 0 for i in range(count): pkt = { \u0026#34;id\u0026#34;: 1, \u0026#34;nicname\u0026#34;:\u0026#34;enp6s0\u0026#34;, \u0026#34;raw_packet\u0026#34;: \u0026#34;TOu9fJMVMKrkRBubCABFIAAoEh0AAHQGjPrYOtKuwKg8BwG75osRSr9s/dLbA1AQAQl1XgAAAAAAAAAA\u0026#34; } producer.send(topic, pkt) i = i + 1 #注意全发完了再close producer.close() if __name__ == \u0026#34;__main__\u0026#34;: producer = KafkaProducer( value_serializer=lambda v: json.dumps(v).encode(\u0026#39;utf-8\u0026#39;), bootstrap_servers=\u0026#34;localhost:9092\u0026#34; ) #produce_one_item(\u0026#39;test1\u0026#39;,producer) produce_more_items(2000,\u0026#39;test1\u0026#39;, producer)   3.3 kafka消费者分组与分区数（Partition）的关系  来源：https://blog.csdn.net/gdkyxy2013/article/details/86644919\n  消费者数 ＞ 分区数：多余的消费者空闲 消费者数 ＜ 分区数：多消费者对应多个分区 消费者数 = 分区数：一个消费者对应一个分区  参考资料 1.kafka学习之路一：https://www.cnblogs.com/qingyunzong/p/9004509.html\n2.kafka学习之路二：https://www.cnblogs.com/qingyunzong/archive/2004/01/13/9004593.html\n3.kafka学习之路三：https://www.cnblogs.com/qingyunzong/archive/2004/01/13/9004703.html\n4.kafka中文文档：https://kafka.apachecn.org/intro.html\n5.kafka安装：https://www.cnblogs.com/qingyunzong/archive/2004/01/13/9005062.html\n6.kafka-python的基本使用：https://zhuanlan.zhihu.com/p/38330574\n7.通过python操作kafka：https://developer.aliyun.com/article/584524\n","description":"Kafka的安装与使用，仅做简单的测试用，用法较为简单","id":10,"section":"posts","tags":["分布式"],"title":"工具使用：Kafka","uri":"https://yyyIce.github.io/zh/posts/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8kafka/"},{"content":"　论文名称：NetCache: Balancing Key-Value Stores with Fast In-Network Caching\n　会议信息：SOSP ’17, October 28, 2017, Shanghai, China\n　成果：利用ToR可编程交换机做缓存层，实现机架规模的数十亿吞吐量的读密集型键值存储系统\n　贡献：使用缓存解决负载不均衡问题，利用可编程交换机的线速处理，解决了缓存和存储层之间没有明显速度差别的问题；利用了可编程交换机的特性，是可编程交换机的一个应用实例，详细讲解了可编程交换机的使用方法和思路\n　前人工作不足：传统的键值存储当存储层也在内存时，缓存和存储层之间没有明显速度差别；为保证各个副本间的数据迁移，数据一致性和查询路由使得系统更加复杂并引入了开销\n　本文工作：利用ToR可编程交换机做键值存储系统的缓存层，设计NetCache数据包，在可编程交换机上实现路由模块、键值存储模块（入口的Lookup Table和出口的Value Table）、查询统计模块（Count-Min草图和Bloom Filter）；客户端实现查询API，服务端把NetCache数据包转换成查询；NetCache适用范围和不足的讨论；性能评估，主要与NoCache对比。\n　详细阅读可以参考演示页面下的NetCache，本文只简单地进行一下总结。\n一、背景 1.内存键值存储 　现代网络服务（如科研、社会网络和电子商务）高度依赖于高性能键值存储。系统运营商需要内存中的键值存储系统（Memcached、Redis）来满足必要的吞吐量和延迟需求。\n　现代网络服务的热点事件查询次数远超其它事件，并且热点事件的集合处于快速变动的状态中，这种偏斜的负载导致严重的系统性能下降。\n　缓存是均衡负载的有效方法。传统的键值存储（基于闪存、基于硬盘）使用快速内存缓存层均衡负载。而基于服务的缓存由于其存储层就在内存中，基于内存的缓存层并不生效。\n1.1 缓存大小 　根据论文Small Cache, Big Eect: Provable Load Balancing for Randomly Partitioned Cluster Services.得知，平衡N个存储节点的hash分区键值集群，只需要设置能够存储O(NlogN)个项目的缓存。\n1.2 缓存放置的位置 　客户端\u0026mdash;\u0026gt;网络\u0026mdash;\u0026gt;服务端\n 放在客户端上：难以保证缓存一致性；客户端访问热点时间的公共集合并不对每个客户端都是热点事件 放在服务端上：存储层本身就在内存中，基于内存的缓存层并不生效 放在网络中：由于硬件的发展，可编程交换机的芯片资源足够存储O(NlogN)项，并且它每秒能够处理数十亿数据包  　所以考虑将缓存层构建到网络(可编程交换机)中。\n二、本文的工作 1.系统设计 　系统设计见图1，系统设计主要有3个点，前两点较为巧妙，第三点比较普通，具体实现参考演示页面下的NetCache，这里仅概括核心思想，不再详细表述。\n图1 NetCache设计:\r\r 1.1 实现变长键值存储，并最小化开销  使用多个阶段把值连接起来构成大的值； 在查找表(Lookup Table)使用位图索引到ValueTable，动作数据只有位图和槽索引，节省了查找表(Lookup Table)的空间；读取给定寄存器的索引槽(idx)，Key是位图的一个位，节省了值表(Value Table)的空间； 用重复的动作定义（代码的增加）代替存储空间的增加，多个寄存器的相同索引的槽可以存储不同Key的Value，从而能够大限度地将所有寄存器的槽占用，充分利用了空间。  1.2 标记热点事件  使用Count-Min草图对Key的查询频率进行计数，不存储key，每次对key做Hash运算，映射到4个寄存器数组的4个索引上，4个索引中的值加1，4个值中最小的值作为查询频率，如果最小值超过了控制器配置的阈值，就把它标记为热点，发送给控制器。 使用Bloom Filter检测该Key是否已经上报给控制器。  1.3 缓存更新 　Heavy Hitter向控制器报告访问次数超过了阈值的键；\n　控制器从缓存中采样很少的Key，将他们的计数器与HH报告的进行比较，驱逐不流行的Key，插入更流行的Key\n 驱逐Key即将其各阶段寄存器的对应的索引槽中的值全清零； 插入Key是背包问题，采用最先适合算法分配寄存器的索引槽，然后从存储服务器获取这些Key的值。  2.流水线布局 　流水线布局如图2，具体实现参考演示页面下的NetCache。\n图2 NetCache流水线布局:\r\r 三、实现 　各部分实现的简洁图示参考演示页面下的NetCache。\n　交换机数据平面用P4编写，并用Barefoot Capilano软件套件编译到Barefoot Tofino ASIC上。缓存查找表的16字节键有64K条目。值表和寄存器数组分布在8个阶段。每个阶段提供64K 16字节的槽。这缓存的总大小是8MB，其值大小为16字节，最大为128字节。Count-Min草图包括4个寄存器组，每个有64K 16位的槽。布隆过滤器包括3个寄存器数组，每个有256K 1位的槽。Count-Min草图和布隆过滤器使用Tofino ASIC提供的哈希函数，执行键字段的位的任意异或运算。\n　控制器可以配置重置Count-Min草图和布隆过滤器的频率。文章在实验中每秒重置它们一次。总的来说，我们的数据平面实现使用的片上内存少于Tofino ASIC提供的50%，留下的空间足够用于传统网络处理。我们使用标准L3路由作为路由模块，基于目的IP地址转发数据包。\n　控制器使用Python编写。P4编译器通过交换机驱动在运行时为控制器生成Thrift API。控制器从数据平面使用这些API像4.3节那样来接收heavy hitter报告，获取计数器，并更新缓存的事项。\n　为优化IO性能，客户端库和服务器代理用Intel DPDK和C语言实现。客户端库提供键值接口，并将API调用转换为NetCache数据包。根据混合读写操作的Zipf版本，客户端可以在文章的服务器上用40G的网卡生成多达35MQPS的键值查询。\n四、涉及到的基础知识 　本文讲述的非常清晰，几乎不需要额外查找相关资料。\n","description":"利用高速缓存解决内存键值存储系统的负载不均衡问题，通过将缓存放置在可编程交换机上实现“高速”","id":11,"section":"posts","tags":["P4"],"title":"NetCache ：基于网络内缓存快速均衡键值存储负载","uri":"https://yyyIce.github.io/zh/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BBnetcache/"},{"content":"Some photos.\n","description":"随便拍拍，记录快乐","id":13,"section":"gallery","tags":null,"title":"随拍","uri":"https://yyyIce.github.io/zh/gallery/%E9%9A%8F%E6%8B%8D/"},{"content":"随便画画。\n","description":"随便画点什么","id":14,"section":"gallery","tags":null,"title":"随笔","uri":"https://yyyIce.github.io/zh/gallery/%E9%9A%8F%E7%AC%94/"},{"content":"　Mininet是一个网络模拟器，可以创建虚拟主机，交换机，控制器和连接的网络。\n　Mininet主机运行标准的Linux网络软件，支持OpenFlow。支持开发、学习、测试、调试，让使用者在笔记本电脑上就可以拥有完整的实验网络。在Mininet上为OpenFlow控制器，修改后的交换机或主机开发和测试的代码可以迁移到具有较少更改的实际系统中。通常Mininet中运行的设计可以直接移植到硬件交换机，以进行线速数据包转发。基于Mininet的网络不能超过当前CPU或在单个服务器上所获得的带宽。\n1.安装   mininet的官方页面：http://mininet.org/\n  mininet的github：https://github.com/mininet/mininet\n  1.1 虚拟机整机   下载地址：https://github.com/mininet/mininet/releases\n  amd64是64位的ubuntu；i386是32位的ubuntu。\n  用户名：mininet 密码：mininet\n  获取root权限：\n  1  sudo -i   1.2 在已有虚拟机上安装  安装参考：https://blog.csdn.net/AsNeverBefore/article/details/78916645\n (1)获取源码\n1  git clone git://github.com/mininet/mininet   (2)进入mininet目录，可通过查看INSTALL文件查询版本目录\n1  cd mininet   (3)安装Mininet，根据./mininet/util/install.sh -h命令选择参数进行安装\n1  util/install.sh -n3V 2.5.9   (4)安装成功，并查看mininet的版本\n1 2 3 4  mn --version #测试Mininet是否安装成功 sudo mn --test pingall   图1 安装成功:\r\r 　注：尽量不要用-a选项进行安装。我用了，装了3天，最后还不好用。\n1.3 可能出现的问题 　(1)由于频繁结束安装进程可能出现Could not get lock /var/lib/apt/lists/lock - open (11: Resource temporarily unavailable)，解决办法：https://blog.csdn.net/weixin_42489042/article/details/81296472 或重启。\n　(2)mininet用./mininet/miniedit.py做的图形化界面，pingall一个都不通；版本2.3.0d6\n图2 ping不通:\r\r 　解决方案：菜单栏Edit-\u0026gt;Preferences，只勾选OpenFlow1.0，或同时勾选OpenFlow1.0和OpenFlow1.3，只勾选1.3就会出现上面的现象。\n2.使用 2.1 网络构建 2.1.1 利用topo参数构建 可以快速构建一个交换机连接两台主机的拓扑\n1  sudo mn   (1)单一拓扑\n1 2 3 4  sudo mn --topo=single,3 # 构建拓扑的连线 (h1, s1) (h2, s1) (h3, s1)   (2)线性拓扑\n1 2 3 4  sudo mn --topo=linear,4 # 构建拓扑的连线 (h1, s1) (h2, s2) (h3, s3) (h4, s4) (s2, s1) (s3, s2) (s4, s3)   (3)树形拓扑\n1 2 3 4  sudo mn --topo=tree,depth=2,fanout=2 # 构建拓扑的连线 (s1, s2) (s1, s3) (s2, h1) (s2, h2) (s3, h3) (s3, h4)   (4)自定义拓扑\n1  sudo mn --custom file.py --topo mytopo   2.1.2 利用文件构建 (1)写好一个mininet的python脚本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95  #!/usr/bin/python import mininet.term from mininet.net import Mininet from mininet.node import Controller, RemoteController, OVSController from mininet.node import CPULimitedHost, Host, Node from mininet.node import OVSKernelSwitch, UserSwitch from mininet.node import IVSSwitch from mininet.cli import CLI from mininet.log import setLogLevel, info from mininet.link import TCLink, Intf from subprocess import call import os def myNetwork(): net = Mininet( topo=None, build=False, ipBase=\u0026#39;10.0.0.0/8\u0026#39;) info( \u0026#39;*** Adding controller\\n\u0026#39; ) c0=net.addController(name=\u0026#39;c0\u0026#39;, controller=RemoteController, ip=\u0026#39;127.0.0.1\u0026#39;, protocol=\u0026#39;tcp\u0026#39;, port=6633) info( \u0026#39;*** Add switches\\n\u0026#39;) s1 = net.addSwitch(\u0026#39;s1\u0026#39;, cls=OVSKernelSwitch, dpid=\u0026#39;0000000000000001\u0026#39;) s2 = net.addSwitch(\u0026#39;s2\u0026#39;, cls=OVSKernelSwitch, dpid=\u0026#39;0000000000000002\u0026#39;) s3 = net.addSwitch(\u0026#39;s3\u0026#39;, cls=OVSKernelSwitch, dpid=\u0026#39;0000000000000003\u0026#39;) s4 = net.addSwitch(\u0026#39;s4\u0026#39;, cls=OVSKernelSwitch, dpid=\u0026#39;0000000000000004\u0026#39;) info( \u0026#39;*** Add hosts\\n\u0026#39;) h1 = net.addHost(\u0026#39;h1\u0026#39;, mac=\u0026#39;00:00:00:00:00:01\u0026#39;, cls=Host, ip=\u0026#39;10.0.0.1\u0026#39;, defaultRoute=None) h2 = net.addHost(\u0026#39;h2\u0026#39;, mac=\u0026#39;00:00:00:00:00:02\u0026#39;, cls=Host, ip=\u0026#39;10.0.0.2\u0026#39;, defaultRoute=None) h3 = net.addHost(\u0026#39;h3\u0026#39;, mac=\u0026#39;00:00:00:00:00:03\u0026#39;, cls=Host, ip=\u0026#39;10.0.0.3\u0026#39;, defaultRoute=None) h4 = net.addHost(\u0026#39;h4\u0026#39;, mac=\u0026#39;00:00:00:00:00:04\u0026#39;, cls=Host, ip=\u0026#39;10.0.0.4\u0026#39;, defaultRoute=None) info( \u0026#39;*** Add links\\n\u0026#39;) net.addLink(s1, h1) net.addLink(s1, h2) net.addLink(s1, s3) net.addLink(s1, s4) net.addLink(s2, h3) net.addLink(s2, h4) net.addLink(s2, s3) net.addLink(s2, s4) info( \u0026#39;*** Starting network\\n\u0026#39;) net.build() info( \u0026#39;*** Starting controllers\\n\u0026#39;) for controller in net.controllers: controller.start() info( \u0026#39;*** Starting switches\\n\u0026#39;) net.get(\u0026#39;s1\u0026#39;).start([c0]) net.get(\u0026#39;s2\u0026#39;).start([c0]) net.get(\u0026#39;s3\u0026#39;).start([c0]) net.get(\u0026#39;s4\u0026#39;).start([c0]) info( \u0026#39;*** Post configure switches and hosts\\n\u0026#39;) os.system(\u0026#39;ovs-ofctl add-flow s1 in_port=1,dl_src=00:00:00:00:00:01,action=output:3\u0026#39;) os.system(\u0026#39;ovs-ofctl add-flow s1 in_port=2,dl_src=00:00:00:00:00:02,action=output:3\u0026#39;) os.system(\u0026#39;ovs-ofctl add-flow s1 in_port=3,dl_src=00:00:00:00:00:03,action=output:1\u0026#39;) os.system(\u0026#39;ovs-ofctl add-flow s1 in_port=3,dl_src=00:00:00:00:00:04,action=output:2\u0026#39;) os.system(\u0026#39;ovs-ofctl add-flow s2 in_port=1,dl_src=00:00:00:00:00:03,action=output:3\u0026#39;) os.system(\u0026#39;ovs-ofctl add-flow s2 in_port=2,dl_src=00:00:00:00:00:04,action=output:3\u0026#39;) os.system(\u0026#39;ovs-ofctl add-flow s2 in_port=3,dl_src=00:00:00:00:00:01,action=output:1\u0026#39;) os.system(\u0026#39;ovs-ofctl add-flow s2 in_port=3,dl_src=00:00:00:00:00:02,action=output:2\u0026#39;) \u0026#39;\u0026#39;\u0026#39; os.system(\u0026#39;ovs-ofctl add-flow s1 in_port=1,action=output:3\u0026#39;) os.system(\u0026#39;ovs-ofctl add-flow s1 in_port=3,action=output:1\u0026#39;) os.system(\u0026#39;ovs-ofctl add-flow s2 in_port=1,action=output:3\u0026#39;) os.system(\u0026#39;ovs-ofctl add-flow s2 in_port=3,action=output:1\u0026#39;) \u0026#39;\u0026#39;\u0026#39; os.system(\u0026#39;ovs-ofctl add-flow s3 in_port=1,action=output:2\u0026#39;) os.system(\u0026#39;ovs-ofctl add-flow s3 in_port=2,action=output:1\u0026#39;) os.system(\u0026#39;ovs-ofctl add-flow s4 in_port=1,action=output:2\u0026#39;) os.system(\u0026#39;ovs-ofctl add-flow s4 in_port=2,action=output:1\u0026#39;) CLI(net) #makeTerm(h1) net.stop() if __name__ == \u0026#39;__main__\u0026#39;: setLogLevel( \u0026#39;info\u0026#39; ) myNetwork() #term.makeTerm(h1)   (2)用sudo运行python脚本\n1  sudo python filename.py   2.1.3 利用miniedit构建 (1)进入mininet的examples目录，运行\nsudo ./miniedit.py\r(2)从左边图标拖动图标，构建网络拓扑，在对应元件上长按鼠标右键，滑到Properties可以设置原件属性\n图3 Properties:\r\r 图4 设置控制器:\r\r 图5 设置交换机:\r\r 图6 设置主机:\r\r (3)左上角Edit-\u0026gt;Preference可以进行全局配置，注意不能只勾选OpenFlow 1.3\n图7 全局配置:\r\r (4)勾选Start CLI，点击左下角的Run，可以在终端看到CLI。\n图8 Run:\r\r (5)File-\u0026gt;Export Level 2 Script，保存为Python脚本，然后下面命令即可创建网络拓扑\n1 2  chmod -R 777 test.py ./test.py   图9 保存为Python脚本:\r\r 2.1.4 清除配置信息 如果拓扑建立失败，提示已被占用，可以用下列命令清空配置\n1  mn -c   2.2连接控制器 (1)如果没有指定控制器，会使用mininet中默认的控制器。\n(2)下列命令可以 连接指定ip:port的控制器\n1  sudo mn --controller=remote, --ip=\u0026lt;controller_ip\u0026gt;,--port=[port]   (3)启动mininet，--controller=remote可以连上启动的RYU控制器。\n因为启动RYU控制器，启动在6653端口，remote默认连接6653端口，所以mininet的网络可以连接上RYU。\n","description":"mininet的安装与使用，以及踩过的坑","id":15,"section":"posts","tags":["sdn"],"title":"工具使用：mininet","uri":"https://yyyIce.github.io/zh/posts/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8mininet/"},{"content":"　RYU控制器是简单易上手的SDN控制器，易于使用和开发，由Python实现。\n1.安装 1 2 3 4  git clone https://github.com/osrg/ryu.git cd ryu python3.7 -m pip install ryu ryu --version   2.使用 　把编写好的控制器程序放到./ryu/ryu/app目录下，运行ryu-manager xxx.py启动控制器，加上--verbose显示调试信息。\n1 2 3  ryu-manager test.py ryu-manager test.py --verbose ryu-manager ./ryu/ryu/app/hub.py --verbose   3.控制器编写 4.和Mininet配合使用 ","description":"ryu控制器的简单使用","id":16,"section":"posts","tags":["sdn"],"title":"工具使用：ryu","uri":"https://yyyIce.github.io/zh/posts/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8ryu%E6%8E%A7%E5%88%B6%E5%99%A8/"},{"content":"1 协程 　协程是并发的一种实现方式。和多线程的抢占式不同，它是当前运行的协程A在需要等待第三方结果时，主动让出控制权，然后由其它空闲的就绪协程B继续执行，当B也需要等待结果时，再主动让出控制权，让其它协程继续执行。也就是说，协程的运行方式是一组协程轮流获得控制权，以充分利用等待时间，也就是小学学过的“时间统筹”，在电饭煲煮饭的同时可以切菜，在洗衣机洗衣服的同时可以炒菜。\n　所有协程运行在单进程的一个线程上，所以不需要对资源加锁，同一时刻仅会有一个进程访问资源，减少了锁的开销，也减少了程序的复杂度和奇怪的错误。但注意考虑控制权移交前后的同步资源问题。\n　由于协程的主要原理是在协程A等待的时间让出控制权让不需等待结果的协程B继续运行，所以等待时间较长的任务上更适合协程，即IO密集型任务，如发送网络请求（网络IO），文件读写等等。\n2 asyncio \rasyncio的官方文档地址\n\r \r　我们这里只讲基于原生协程（通过async def声明）的协程，不讲基于生成器的协程（即通过装饰器@asyncio.coroutine声明的协程），因为基于生成器的协程将在Python3.10中废弃。\n　第1节中提到，协程的运行方式是主动让出控制权，那么就需要有一个能够让出控制权和分配控制权给其它协程的机制。asyncio实现这种机制的方式是一个事件循环。它将所有协程放入一个事件循环中，按照某种顺序依次询问协程是否空闲，空闲的协程A获得控制权并开始运行，直到A开始等待，A主动交出控制权，事件循环再次询问协程是否空闲，直至询问到下一个空闲的协程，直至所有的协程都运行完毕。\n一个简单的协程示例 　用此程序来体会一下协程。\n 程序来源：https://realpython.com/async-io-python/ countasync.py\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # simple_asyncio.py import asyncio async def count(): print(\u0026#34;One\u0026#34;) await asyncio.sleep(1) print(\u0026#34;Two\u0026#34;) async def main(): await asyncio.gather(count(), count(), count()) if __name__ == \u0026#34;__main__\u0026#34;: import time s = time.perf_counter() asyncio.run(main()) elapsed = time.perf_counter() - s print(f\u0026#34;{__file__} executed in {elapsed:0.2f} seconds.\u0026#34;)   　运行结果：\n1 2 3 4 5 6 7 8  $ python3.7 simple_asyncio.py One One One Two Two Two simple_asyncio.py executed in 1.00 seconds.   　可以看到上面的程序运行了三次而实际用时却只用了1s。\n协程函数的定义 　协程通过async/await语法进行声明，需要使用Python3.7以上的版本，使用async/await语法的时候需要引用asyncio包：\n1  import asyncio   　声明一个协程函数在def前加上async关键字即可。其中的内容需要有能够主动让出主动权的语句，如await、return、yield，才能够有条件让其它函数在其等待期间运行，达到并发效果。但是请注意async def声明的协程函数内部不能有yield from。不再讲述return和yield。await后面必须是一个可等待对象，意思是等待这个协程运行完毕。\n　在下面这个程序中，asyncio.sleep(delay)可以替换成任意可等待对象：\n1 2 3  async def say_after(delay, what): await asyncio.sleep(delay) print(what)   \r\r 通过装饰器@asyncio.coroutine声明的协程内部的yield from就相当于async def声明的协程内部的await。 但是，async def声明的协程函数内部不能有yield from。  \r \r可等待对象 主要有三种类型，协程、任务、Future。\n 协程：协程函数（用async def定义的函数），协程对象（调用协程函数所返回的对象） 任务：用来放入调度槽，准备立即运行 Future：特殊的低层级可等待对象，表示一个异步操作的最终结果，一般不出现在应用层级代码中。  协程的运行 　运行协程通常会设定一个main()入口，在main()中安排、调用各个具体的协程任务，通过asyncio.run(main())进入协程。\n　在下面的示例（来自于官方文档）中，定义了协程函数say_after()和协程函数main()，其中main()作为协程入口，用asyncio.run(main())进入main()，在main()中调用两次协程函数say_after()。\n\r asyncio.run(coro, ***, debug=False)\n执行 coroutine coro 并返回结果。\n 此函数会运行传入的协程，负责管理 asyncio 事件循环，终结异步生成器，并关闭线程池。 当有其他 asyncio 事件循环在同一线程中运行时，此函数不能被调用。 如果 debug 为 True，事件循环将以调试模式运行。 此函数总是会创建一个新的事件循环并在结束时关闭。它应当被用作 asyncio 程序的主入口点，理想情况下应当只被调用一次。   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  # asyncio_no_concurrency.py import asyncio import time async def say_after(delay, what): await asyncio.sleep(delay) print(what) async def main(): print(f\u0026#34;started at {time.strftime(\u0026#39;%X\u0026#39;)}\u0026#34;) await say_after(1, \u0026#39;hello\u0026#39;) await say_after(2, \u0026#39;world\u0026#39;) print(f\u0026#34;finished at {time.strftime(\u0026#39;%X\u0026#39;)}\u0026#34;) asyncio.run(main())   \r　运行上面的示例我们会得到如下结果：\n1 2 3 4 5  $python3.7 asyncio_no_concurrency.py started at 11:31:11 hello world finished at 11:31:14   \r　可以发现虽然用了协程，但是并没有并发执行，运行的总时间还是3秒。如何并发运行协程呢？\n协程的并发运行 　并发运行协程需要把协程封装为Task对象（asyncio.create_task(\u0026lt;async def\u0026gt;)），此时协程已经开始运行，可以分别await这些Task对象以获取其执行结果；或者使用await asyncio.gather(\u0026lt;async def1\u0026gt;, \u0026lt;async def2\u0026gt;, ...)。asyncio.gather()会把协程当作任务，加入日程。\n　也就是说asyncio.create_task提交任务，此时任务在后台运行，不会输出结果，可以用await等待结果；await asyncio.gather()提交任务并等待结果。\n asyncio.create_task(coro, ***, name=None)\n将 coro 协程 打包为一个 Task 排入日程准备执行。返回 Task 对象。\n 　asyncio.create_task()返回一个Task对象，它的参数是协程。可以用await获取它运行时的一些结果；如果该Task对象已经运行结束了，仍会保留其结果，还可以通过await语句查看。\n awaitable asyncio.gather(*aws, loop=None, return_exceptions=False)\n并发运行aws序列中的可等待对象。\n 如果所有可等待对象都成功完成，结果将是一个由所有返回值聚合而成的列表。结果值的顺序与 aws 中可等待对象的顺序一致。 如果 aws 中的某个可等待对象为协程，它将自动作为一个任务加入日程。 loop在Python3.8中已经废弃，3.10中将被删除。 如果 return_exceptions 为 False (默认)，所引发的首个异常会立即传播给等待 gather() 的任务。aws 序列中的其他可等待对象 不会被取消 并将继续运行。  如果 return_exceptions 为 True，异常会和成功的结果一样处理，并聚合至结果列表。 如果 gather() 被取消，所有被提交 (尚未完成) 的可等待对象也会 被取消。     　asyncio.gather()的参数是可等待对象，所以可以将asyncio.create_task()返回的Task对象作为它的参数。\n　运行下面的程序：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # asyncio_concurrency_await.py import asyncio import time async def nested(): print(\u0026#34;Coro nested Started.\u0026#34;) await asyncio.sleep(3) print(\u0026#34;Coro nested Finished.\u0026#34;) async def main(): print(\u0026#34;Coro main Started.\u0026#34;) task = asyncio.create_task(nested()) print(\u0026#34;Coro main Finished.\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: print(f\u0026#34;started at {time.strftime(\u0026#39;%X\u0026#39;)}\u0026#34;) asyncio.run(main()) print(f\u0026#34;finished at {time.strftime(\u0026#39;%X\u0026#39;)}\u0026#34;)   　会得到这样的结果：\n1 2 3 4 5 6  $python3.7 asyncio_concurrency_await.py started at 15:11:25 Coro main Started. Coro main Finished. Coro nested Started. finished at 15:11:25   　可以看到是从协程main()进入的，并且由于没有await，main()在return前不会交出控制权，所以在输出Finieshed以后，nested()获得控制权，运行到sleep，交出控制权，回到___main__中，运行到最后一句，然后直接退出。如果想要看到nested()的结果，需要await nested()。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  # asyncio_concurrency_await.py import asyncio import time async def nested(): print(\u0026#34;Coro nested Started.\u0026#34;) await asyncio.sleep(3) print(\u0026#34;Coro nested Finished.\u0026#34;) async def main(): print(\u0026#34;Coro main Started.\u0026#34;) task = asyncio.create_task(nested()) await task #await asyncio.gather(nested()) print(\u0026#34;Coro main Finished.\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: print(f\u0026#34;started at {time.strftime(\u0026#39;%X\u0026#39;)}\u0026#34;) asyncio.run(main()) print(f\u0026#34;finished at {time.strftime(\u0026#39;%X\u0026#39;)}\u0026#34;)   　将得到下面的输出结果：\n1 2 3 4 5 6 7  $python3.7 asyncio_concurrency_await.py started at 15:17:53 Coro main Started. Coro nested Started. Coro nested Finished. Coro main Finished. finished at 15:17:56   　当然也可以直接将这两句替换为await asyncio.gather(nested())。\n　所以在有多个任务时，通常使用asyncio.create_task()并发启动任务，用await asyncio.gather()语句等待所有任务的执行结果。用asyncio.create_task()方便创建task list，因为直接创建在list中会顺序运行这些程序，而用推导式（列表生成式）和asyncio.create_task()可以使代码美观：\n1 2 3 4 5 6 7 8 9 10  #程序来自于附录[1]的asyncq.py ... producers = [asyncio.create_task(produce(n, q)) for n in range(nprod)] consumers = [asyncio.create_task(consume(n, q)) for n in range(ncon)] await asyncio.gather(*producers) ... #这样写会导致顺序运行produce(0,q)，produce(1,q)，然后一直等待，无法获得一个任务列表 producers = [produce(n, q) for n in range(nprod)] #如果不使用create_task()，就要写成下面的格式，这很糟糕 await asyncio.gather(produce(0,q), produce(1,q),...)   控制并发量 　一次并发太多可能会导致意外的结果，比如并发量为5000，但服务器可能检测到2000个请求就将你标记为可疑。可以通过asyncio.Semaphore(\u0026lt;num\u0026gt;)控制在事件循环中的最大任务数。用法如下：\n1 2 3 4 5 6  #最多并发10个任务，超过10个的任务将等待 sem = asyncio.Semaphore(10) # ... later async with sem: # work with shared resource   \r class asyncio.Semaphore(value=1, ***, loop=None)\nSemaphore会管理一个内部计数器，该计数器会随每次 acquire() 调用递减并随每次 release()调用递增。计数器的值永远不会降到零以下；当 acquire()发现其值为零时，它将保持阻塞直到有某个任务调用了 release()\nSource\n asyncio.Semaphore(\u0026lt;num\u0026gt;)推荐使用async with语句，上面的示例代码等价于：\n1 2 3 4 5 6 7 8  sem = asyncio.Semaphore(10) # ... later await sem.acquire() try: # work with shared resource finally: sem.release()   总结 　Python官方提供的异步IO包为asyncio，需要Python3.7以上版本。\n　对于单个协程来说，使用async def定义，同时协程函数体中应有交出控制权的关键词，如await、yield、return。\n　对于所有协程来说，需要一个协程的入口main()，也被称作包装器（wrapper），通过asyncio.run(main())启动事件循环，并执行main()。在main()中把要执行的协程用asyncio.create_task()封装为task()对象，并发执行，然后使用await asyncio.gather()获得他们的执行结果。\n　可以定义一个程序模板：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  import asyncio async def coro1(): await asyncio.sleep(5) async def coro2(): ... async def main(): task1 = asyncio.create_task(coro1()) ... await asyncio.gather(task1,...) if __name__ == \u0026#34;__main__\u0026#34;: asyncio.run(main())   \r\r 给定协程中的任何行(hang)都会阻塞其它协程，除非该行使用yield，await或return。所以写成更适用于IO密集型任务，把IO任务封装为协程函数，提高CPU利用率。 不是在所有函数前加上async它本身就能够异步运行了，需要该函数的实现支持异步，如发送HTTP请求需要aiohttp包。更多可以参考附录[1]的文末。 要并发的任务务必使用.create_task()，然后全部放入.gather()中等待，否则不会并发执行，仍是串行执行。  \r \r3 常见用法及注意事项 asyncio.Queue 　文档地址：https://docs.python.org/3.9/library/asyncio-queue.html?highlight=asyncio%20queue#asyncio.Queue\n class asyncio.Queue(maxsize=0, ***, loop=None)\n先入先出队列\nmaxsize：队列中最大元素个数，maxsize ≤ 0，队列大小是无限的，如果是大于0的正整数，当队列长度到达maxsize时，await put()将会被阻塞，直到其中一项被get()移出队列。\n和线程库中的queue不同，此队列的大小总是已知的，并且通过调用qsize()方法返回队列大小。\n  empty()：如果队列为空，返回True，否则返回false。 full()：如果队列中的元素个数达到了maxsize，则返回True，如果队列maxsize=0，则full()永远也不会返回True。 get_nowait()：如果有立即可获得的元素，则返回该元素，否则raise QueueEmpty。 coroutine get()：从队列中移除一个元素，并将返回该元素。如果队列为空，则等待到存在可用的元素。 put_nowait()：无阻塞地向队列中放入一个元素。如果没有可用的槽，则raise QueueFull。 coroutine put()：把元素放到队列中。如果队列满了，一直等待直到队列中有空的槽，然后将元素添加到队列。 task_done()：表示先前入队的任务已经完成。由队列消费者调用。对于每个获取任务的get()，后续都要调用task_done()来告诉队列，该任务的处理已完成。如果join()当前处于阻塞状态，则将在处理完所有项目后恢复运行（意味着已放入队列的每个项目都会接收到task_done()调用）。如果被调用的次数超过队列中放置的项目的次数，则引发ValueError。 coroutine join()：一直阻塞，直到队列中的所有元素被接收和处理完毕。每当将项目添加到队列时，未完成任务的数量就会增加。每当消费者协程调用task_done()表示已检索到该物品并且该物品的所有工作已完成时，该计数就会减少。当未完成的任务数降至零时，join()解除阻止。  　下面的程序展示了在有20个元素的队列中，使用3个协程共同消费队列中元素，程序源于官方文档\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50  import asyncio import random import time async def worker(name, queue): while True: # Get a \u0026#34;work item\u0026#34; out of the queue. sleep_for = await queue.get() # Sleep for the \u0026#34;sleep_for\u0026#34; seconds. await asyncio.sleep(sleep_for) # Notify the queue that the \u0026#34;work item\u0026#34; has been processed. queue.task_done() print(f\u0026#39;{name} has slept for {sleep_for:.2f} seconds\u0026#39;) async def main(): # Create a queue that we will use to store our \u0026#34;workload\u0026#34;. queue = asyncio.Queue() # Generate random timings and put them into the queue. total_sleep_time = 0 for _ in range(20): sleep_for = random.uniform(0.05, 1.0) total_sleep_time += sleep_for queue.put_nowait(sleep_for) # Create three worker tasks to process the queue concurrently. tasks = [] for i in range(3): task = asyncio.create_task(worker(f\u0026#39;worker-{i}\u0026#39;, queue)) tasks.append(task) # Wait until the queue is fully processed. started_at = time.monotonic() await queue.join() total_slept_for = time.monotonic() - started_at # Cancel our worker tasks. for task in tasks: task.cancel() # Wait until all worker tasks are cancelled. await asyncio.gather(*tasks, return_exceptions=True) print(\u0026#39;====\u0026#39;) print(f\u0026#39;3 workers slept in parallel for {total_slept_for:.2f} seconds\u0026#39;) print(f\u0026#39;total expected sleep time: {total_sleep_time:.2f} seconds\u0026#39;) asyncio.run(main())   　time.monotonic()用来测量准确的程序执行时间，它返回一个不会倒退的时间，不受系统时间同步更新影响。\n\r　报错：got Future attached to a different loop\n　Queue必须在loop中定义，即在运行asyncio.run()之后定义，否则Queue会创建一个新的事件循环，然后asyncio.run()也会创建一个新的循环，Queue和asyncio.run()中的函数就处于不同的循环中，导致报错。\n　参考：https://stackoverflow.com/questions/53724665/using-queues-results-in-asyncio-exception-got-future-future-pending-attachedhttps://docs.python.org/zh-cn/3/library/asyncio.html?highlight=asyncio#module-asyncio)\n\r Task.cancel() 　取消一个正在运行的Task对象，使该Task对象抛出一个CancelledError异常给打包的协程。如果取消期间协程正在等待一个Future对象，该Future对象也将被取消。\n　下面的程序中，如果不捕获异常，会报Traceback的错，因为取消任务发生在cancel_me()的await期间。程序源于官方文档。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  # asyncio_task_cancel.py async def cancel_me(): print(\u0026#39;cancel_me(): before sleep\u0026#39;) try: # Wait for 1 hour await asyncio.sleep(3600) except asyncio.CancelledError: print(\u0026#39;cancel_me(): cancel sleep\u0026#39;) raise finally: print(\u0026#39;cancel_me(): after sleep\u0026#39;) async def main(): # Create a \u0026#34;cancel_me\u0026#34; Task task = asyncio.create_task(cancel_me()) # Wait for 1 second await asyncio.sleep(1) task.cancel() try: await task except asyncio.CancelledError: print(\u0026#34;main(): cancel_me is cancelled now\u0026#34;) asyncio.run(main()) # Expected output: # # cancel_me(): before sleep # cancel_me(): cancel sleep # cancel_me(): after sleep # main(): cancel_me is cancelled now    exception asyncio.CancelledError\n该操作已被取消，取消asyncio任务时，可以捕获此异常以执行自定义操作。在几乎所有情况下，都必须重新引发异常。\n 　只有在await等待的任务没有执行完时才会抛出CancelledError异常，不然只会取消任务，所以.cancel()常用于取消处于无限循环状态的任务（比如第1节中的task.cancel()）。\nEvent Loop 　注：应用开发者应使用高层级的asyncio函数，如asyncio.run()，应尽量减少循环对象的使用。\n　官方文档：https://docs.python.org/zh-cn/3/library/asyncio-eventloop.html?highlight=loop%20run_until_complete#asyncio.loop.run_until_complete\n　asyncio.get_event_loop()：获取当前事件循环，如果没有，则创建一个新的事件循环并将其设置为当前事件循环；注意一般不在协程和回调中使用。\n　asyncio.get_running_loop()：返回当前系统线程正在运行的事件循环。在协程和回调中使用该函数获取事件循环。\n　asyncio.set_event_loop(loop)：将loop设置为当前系统线程的事件循环。\n　asyncio.new_event_loop()：创建一个新的事件循环。\n　loop.run_until_complete(future)：运行future实例，直到future实例被完成。如果参数是coroutine object，则将被隐式调度为asyncio.Task来运行。\nasyncio.run() 　源代码：https://github.com/python/cpython/blob/3.9/Lib/asyncio/runners.py\n　由于支持异步的第三方库会使用event_loop，较为底层，考虑替换为asyncio.run()，所以简单探究一下asyncio.run()和event_loop的关系。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67  __all__ = \u0026#39;run\u0026#39;, from . import coroutines from . import events from . import tasks def run(main, *, debug=None): \u0026#34;\u0026#34;\u0026#34;Execute the coroutine and return the result. This function runs the passed coroutine, taking care of managing the asyncio event loop and finalizing asynchronous generators. This function cannot be called when another asyncio event loop is running in the same thread. If debug is True, the event loop will be run in debug mode. This function always creates a new event loop and closes it at the end. It should be used as a main entry point for asyncio programs, and should ideally only be called once. Example: async def main(): await asyncio.sleep(1) print(\u0026#39;hello\u0026#39;) asyncio.run(main()) \u0026#34;\u0026#34;\u0026#34; if events._get_running_loop() is not None: raise RuntimeError( \u0026#34;asyncio.run() cannot be called from a running event loop\u0026#34;) if not coroutines.iscoroutine(main): raise ValueError(\u0026#34;a coroutine was expected, got {!r}\u0026#34;.format(main)) loop = events.new_event_loop() try: events.set_event_loop(loop) if debug is not None: loop.set_debug(debug) return loop.run_until_complete(main) finally: try: _cancel_all_tasks(loop) loop.run_until_complete(loop.shutdown_asyncgens()) loop.run_until_complete(loop.shutdown_default_executor()) finally: events.set_event_loop(None) loop.close() def _cancel_all_tasks(loop): to_cancel = tasks.all_tasks(loop) if not to_cancel: return for task in to_cancel: task.cancel() loop.run_until_complete( tasks.gather(*to_cancel, loop=loop, return_exceptions=True)) for task in to_cancel: if task.cancelled(): continue if task.exception() is not None: loop.call_exception_handler({ \u0026#39;message\u0026#39;: \u0026#39;unhandled exception during asyncio.run() shutdown\u0026#39;, \u0026#39;exception\u0026#39;: task.exception(), \u0026#39;task\u0026#39;: task, })   　根据源代码可以看出，asyncio.run()完成了创建事件循环，设置事件循环并运行main实例。\naiokafka  官方文档：https://aiokafka.readthedocs.io/en/stable/\n 　kafka的简易安装和使用可以参考另一篇安装及使用教程（暂时还没写）。\n消费者(Consumer) 　可以异步消费bootstrap_servers中的topic列表，即下面程序的test3和test4。\n　aiokafka给出的官方示例程序引用了asyncio.get_event_loop()，这是Python官方在应用程序中不建议使用的，所以我在asyncio.run()小节中对此句进行了修改。\n　官方示例程序：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  from aiokafka import AIOKafkaConsumer import asyncio loop = asyncio.get_event_loop() async def consume(): consumer = AIOKafkaConsumer( \u0026#39;test3\u0026#39;, \u0026#39;test4\u0026#39;, loop=loop, bootstrap_servers=\u0026#39;localhost:9092\u0026#39;, auto_offset_reset=\u0026#39;earliest\u0026#39;) # Get cluster layout and join group `my-group` await consumer.start() try: # Consume messages async for msg in consumer: print(\u0026#34;consumed: \u0026#34;, msg.topic, msg.partition, msg.offset, msg.key, msg.value, msg.timestamp) finally: # Will leave consumer group; perform autocommit if enabled. await consumer.stop() loop.run_until_complete(consume())   　上述代码使用底层API启动该任务，而consume()是协程，考虑使用应用级API进行修改。asyncio.get_event_loop()创建并设置当前事件循环，loop.run_until_complete(consume())运行协程直到它结束。\n 使用asyncio.run()创建事件循环并设置事件循环； 创建入口协程main()，用asyncio.run()启动； 由于consumer需要当前事件循环，所以在main()中使用asyncio.get_running_loop()获取当前事件循环（注意不要使用.get_event_loop()），然后将consume(loop)封装为task启动协程，并使用await等待运行。  　替换后的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  # aioconsumer.py from aiokafka import AIOKafkaConsumer import asyncio async def consume(loop): # loop 在此处获取也可以 consumer = AIOKafkaConsumer( \u0026#39;test3\u0026#39;, \u0026#39;test4\u0026#39;, loop=loop, bootstrap_servers=\u0026#39;localhost:9092\u0026#39;, auto_offset_reset=\u0026#39;earliest\u0026#39;) # Get cluster layout and join group `my-group` await consumer.start() try: # Consume messages async for msg in consumer: print(\u0026#34;consumed: \u0026#34;, msg.topic, msg.partition, msg.offset, msg.key, msg.value, msg.timestamp) finally: # Will leave consumer group; perform autocommit if enabled. await consumer.stop() async def main(): loop = asyncio.get_running_loop() task = asyncio.create_task(consume(loop)) await task asyncio.run(main())   生产者(Producer) 　允许生产消息到Topic时交出控制权。同样地，也对官方示例程序进行了修改，不再使用get_event_loop。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  # aioproducer.py from aiokafka import AIOKafkaProducer import asyncio import json async def produce(): loop = asyncio.get_running_loop() producer = AIOKafkaProducer( loop=loop, bootstrap_servers=\u0026#39;localhost:9092\u0026#39;, value_serializer=lambda v: json.dumps(v).encode(\u0026#39;utf-8\u0026#39;)) # Get cluster layout and initial topic/partition leadership information await producer.start() try: # Produce message pkt = { \u0026#34;type\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;url\u0026#34;:\u0026#34;http://test.com/\u0026#34; } await producer.send_and_wait(\u0026#34;test3\u0026#34;, pkt) finally: # Wait for all pending messages to be delivered or expire. await producer.stop() async def main(): task = asyncio.create_task(produce()) await task asyncio.run(main())   生产者消费者通过队列通信 　程序流程和第2节中总结部分的程序模板一致。运行程序时可使用上面的生产者先向kafka中生产一部分消息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65  # aiokafka_queue.py from aiokafka import AIOKafkaConsumer from aiokafka import AIOKafkaProducer import asyncio import json import time import base64 async def consume(consumer, queue): # Get cluster layout and join group `my-group` count = 0 await consumer.start() try: # Consume messages async for msg in consumer: count += 1 data = msg.value data.pop(\u0026#39;type\u0026#39;) data[\u0026#39;id\u0026#39;] = count await queue.put(data) finally: # Will leave consumer group; perform autocommit if enabled. await consumer.stop() async def produce(producer, queue): # Get cluster layout and initial topic/partition leadership information await producer.start() while True: try: # Produce message data = await queue.get() await producer.send_and_wait(\u0026#34;test7\u0026#34;, data) print(f\u0026#34;produed at {time.strftime(\u0026#39;%X\u0026#39;)}\u0026#34;) queue.task_done() except: # Wait for all pending messages to be delivered or expire. await producer.stop() async def main(): loop = asyncio.get_running_loop() queue = asyncio.Queue(5000) consumer = AIOKafkaConsumer( \u0026#39;test3\u0026#39;, loop=loop, bootstrap_servers=\u0026#39;localhost:9092\u0026#39;, auto_offset_reset=\u0026#39;earliest\u0026#39;, value_deserializer=lambda m: json.loads(m.decode(\u0026#39;ascii\u0026#39;))) producer = AIOKafkaProducer( loop=loop, bootstrap_servers=\u0026#39;localhost:9092\u0026#39;, value_serializer=lambda v: json.dumps(v).encode(\u0026#39;utf-8\u0026#39;)) consume_task = asyncio.create_task(consume(consumer, queue)) produce_task = asyncio.create_task(produce(producer, queue)) await queue.join() await asyncio.gather(consume_task, produce_task) if __name__ == \u0026#34;__main__\u0026#34;: print(f\u0026#34;started at {time.strftime(\u0026#39;%X\u0026#39;)}\u0026#34;) asyncio.run(main()) print(f\u0026#34;finished at {time.strftime(\u0026#39;%X\u0026#39;)}\u0026#34;)   消费的同时生产 　也可以将异步Kafka生产语句嵌入消费者中，但一定注意，要将await producer.start()语句移出消费者（不移出电脑会Boom）。在下面的程序示例中，不可以将await producer.start()放置在produce()协程函数中。\n　异步消费的同时生产也可以使用同步Kafka进行生产，减少交出控制权的次数（此处不再列出程序，可以参考第4节地址中的aiokafka_consume_and_synproduce.py）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58  # aiokafka_consume_and_produce.py from aiokafka import AIOKafkaConsumer from aiokafka import AIOKafkaProducer import asyncio import json import time import base64 async def consume(consumer, producer): # Get cluster layout and join group `my-group` count = 0 await consumer.start() try: # Consume messages async for msg in consumer: count += 1 data = msg.value data.pop(\u0026#39;type\u0026#39;) data[\u0026#39;id\u0026#39;] = count await produce(producer, data) finally: # Will leave consumer group; perform autocommit if enabled. await consumer.stop() async def produce(producer, msg): try: await producer.send_and_wait(\u0026#34;test7\u0026#34;, msg) print(f\u0026#34;{msg[\u0026#39;id\u0026#39;]} produced at {time.strftime(\u0026#39;%X\u0026#39;)}\u0026#34;) except: # Wait for all pending messages to be delivered or expire. await producer.stop() async def main(): loop = asyncio.get_running_loop() consumer = AIOKafkaConsumer( \u0026#39;test3\u0026#39;, loop=loop, bootstrap_servers=\u0026#39;localhost:9092\u0026#39;, auto_offset_reset=\u0026#39;earliest\u0026#39;, value_deserializer=lambda m: json.loads(m.decode(\u0026#39;ascii\u0026#39;))) producer = AIOKafkaProducer( loop=loop, bootstrap_servers=\u0026#39;localhost:9092\u0026#39;, value_serializer=lambda v: json.dumps(v).encode(\u0026#39;utf-8\u0026#39;)) # 此句一定不能在produce中 await producer.start() consume_task = asyncio.create_task(consume(consumer, producer)) await asyncio.gather(consume_task) if __name__ == \u0026#34;__main__\u0026#34;: print(f\u0026#34;started at {time.strftime(\u0026#39;%X\u0026#39;)}\u0026#34;) asyncio.run(main()) #print(f\u0026#34;finished at {time.strftime(\u0026#39;%X\u0026#39;)}\u0026#34;)   aiohttp  官方文档：https://docs.aiohttp.org/en/stable/\n 并发发送HTTP请求 　下面的代码是利用HTTP接口上传文件到S3服务，u可替换成S3服务地址。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50  # aiohttp_send_req.py import sys import time import aiohttp import asyncio from aiohttp import ClientSession async def put_pcapng(url,session,semaphore,data,headers): async with semaphore: async with session.put(url,data=data,headers=headers) as resp: if resp.status == 200: return await resp.read() else: print(f\u0026#34;ERROR: {time.strftime(\u0026#39;%X\u0026#39;)} {resp.status} {url}.\u0026#34;) async def main(urls, data, headers): #设置最大并发量，详细见第2节\u0026#34;控制并发量\u0026#34; semaphore =asyncio.Semaphore(500) async with ClientSession() as session: tasks = [] for url in urls: tasks.append( put_pcapng(url=url, session=session, semaphore=semaphore,data=data,headers=headers) ) await asyncio.gather(*tasks) if __name__ == \u0026#34;__main__\u0026#34;: assert sys.version_info \u0026gt;= (3, 7), \u0026#34;Script requires Python 3.7+.\u0026#34; with open(\u0026#39;test.pcapng\u0026#39;, \u0026#39;rb\u0026#39;) as f: data = f.read() headers = { \u0026#34;Content-Type\u0026#34;:\u0026#34;pcapng\u0026#34;, \u0026#34;token\u0026#34;:\u0026#34;xxxxxxxxxxxxxxxxxxxxxxxx\u0026#34; } u = \u0026#39;http://endpoint_url/\u0026lt;bucket_name\u0026gt;/\u0026lt;key\u0026gt;\u0026#39; urls = [] for i in range(1,4001): url = u + \u0026#39;test\u0026#39; + str(i) + \u0026#39;.pcapng\u0026#39; urls.append(url) print(f\u0026#34;started at {time.strftime(\u0026#39;%X\u0026#39;)}\u0026#34;) asyncio.run(main(urls,data,headers)) print(f\u0026#34;finished at {time.strftime(\u0026#39;%X\u0026#39;)}\u0026#34;)   并发发送HTTP请求并解析HTML页面 　可以参考附录1的areq.py，程序的详细解析可以看附录的1。为节省篇幅，此处不再放置此程序。\naiokafka、aiohttp、asyncio.queue综合应用 　协程1从kafka的consume_topic中消费数据，修改后放入队列，然后生产到produce_topic中；协程2(100个)从队列中取数据，上传到S3服务。\n　生产者用AIOKafkaProducer：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116  # aiokafka_to_s3.py import json import time from aiokafka import AIOKafkaConsumer, AIOKafkaProducer import asyncio import base64 import aiohttp from aiohttp import ClientSession headers = { \u0026#34;Content-Type\u0026#34;:\u0026#34;pcapng\u0026#34;, \u0026#34;token\u0026#34;:\u0026#34;xxxxxxxxxxxxxx\u0026#34; } endpoint_url = \u0026#39;http://\u0026lt;endpoint_url\u0026gt;/\u0026lt;bucket_name\u0026gt;/\u0026#39; with open(\u0026#39;test.pcapng\u0026#39;, \u0026#39;rb\u0026#39;) as f: pcapng_data = f.read() total_s3 = 0 total_prod = 0 async def produce(producer, msg): # Get cluster layout and initial topic/partition leadership information try: await producer.send_and_wait(\u0026#34;test6\u0026#34;, msg) #print(f\u0026#34;INFO: {time.strftime(\u0026#39;%X\u0026#39;)} {msg[\u0026#39;id\u0026#39;]} produced. \u0026#34;) except: # Wait for all pending messages to be delivered or expire. await producer.stop() async def consume(consumer, producer, msg_q): # Get cluster layout and join group `my-group` global total_prod await consumer.start() try: # Consume messages async for msg in consumer: data = msg.value data.pop(\u0026#39;type\u0026#39;) data[\u0026#39;id\u0026#39;] = total_prod data[\u0026#39;url\u0026#39;] = endpoint_url + str(data[\u0026#39;id\u0026#39;]) + \u0026#39;.pcapng\u0026#39; await produce(producer, data) # json中不能有byte类型 data[\u0026#39;pcapng\u0026#39;] = pcapng_data await msg_q.put(data) total_prod += 1 finally: # Will leave consumer group; perform autocommit if enabled. await consumer.stop() async def upload_to_s3(session,semaphore,queue): global total_s3 while True: data = await queue.get() url = data[\u0026#39;url\u0026#39;] async with semaphore: async with session.put(url,data=data[\u0026#39;pcapng\u0026#39;],headers=headers) as resp: if resp.status == 200: queue.task_done() total_s3 += 1 #print(f\u0026#34;INFO: {time.strftime(\u0026#39;%X\u0026#39;)} finish upload {data[\u0026#39;id\u0026#39;]} {url}. \u0026#34;) else: # 此处错误没有做重传处理，可以采用再放回队列的方式 print(f\u0026#34;ERROR: {time.strftime(\u0026#39;%X\u0026#39;)} {resp.status} {url}. Retried. \u0026#34;) async def print_metric(start_time): while True: t_time = time.time() - start_time s3_speed = total_s3/t_time prod_speed = total_prod/t_time print(f\u0026#34;upload to s3: {s3_speed}\u0026#34;) print(f\u0026#34;produce to kafka: {prod_speed}\u0026#34;) await asyncio.sleep(1) async def main(): #初始化工作 pcapng_q = asyncio.Queue(500) semaphore =asyncio.Semaphore(500) start_time = time.time() async with ClientSession() as session: loop = asyncio.get_running_loop() consumer = AIOKafkaConsumer( \u0026#39;test3\u0026#39;, loop=loop, bootstrap_servers=\u0026#39;localhost:9092\u0026#39;, auto_offset_reset=\u0026#39;earliest\u0026#39;, value_deserializer=lambda m: json.loads(m.decode(\u0026#39;ascii\u0026#39;))) producer = AIOKafkaProducer( loop=loop, bootstrap_servers=\u0026#39;localhost:9092\u0026#39;, value_serializer=lambda v: json.dumps(v).encode(\u0026#39;utf-8\u0026#39;)) await producer.start() consume_task = asyncio.create_task(consume(consumer, producer, pcapng_q)) speed_task = asyncio.create_task(print_metric(start_time)) print(f\u0026#34;started {time.strftime(\u0026#39;%X\u0026#39;)}\u0026#34;) tasks_s3 = [] for i in range(100): tasks_s3.append(asyncio.create_task(upload_to_s3(session,semaphore,pcapng_q))) await pcapng_q.join() await asyncio.gather(consume_task, speed_task, *tasks_s3) if __name__ == \u0026#34;__main__\u0026#34;: try: asyncio.run(main()) except KeyboardInterrupt: print(\u0026#34;Quit.\u0026#34;)   \n　生产者用KafkaProducer：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108  # aiokafka_to_s3_synp.py  import json import time from aiokafka import AIOKafkaConsumer from kafka import KafkaProducer import asyncio import base64 import aiohttp from aiohttp import ClientSession headers = { \u0026#34;Content-Type\u0026#34;:\u0026#34;pcapng\u0026#34;, \u0026#34;token\u0026#34;:\u0026#34;xxxxxxxxxxxxxxxxxx\u0026#34; } endpoint_url = \u0026#39;http://\u0026lt;endpoint_url\u0026gt;/\u0026lt;bucket_name\u0026gt;/\u0026#39; with open(\u0026#39;test.pcapng\u0026#39;, \u0026#39;rb\u0026#39;) as f: pcapng_data = f.read() total_s3 = 0 total_prod = 0 async def consume(consumer, producer, msg_q): # Get cluster layout and join group `my-group` global total_prod await consumer.start() try: # Consume messages async for msg in consumer: data = msg.value data.pop(\u0026#39;type\u0026#39;) data[\u0026#39;id\u0026#39;] = total_prod data[\u0026#39;url\u0026#39;] = endpoint_url + str(data[\u0026#39;id\u0026#39;]) + \u0026#39;.pcapng\u0026#39; producer.send(\u0026#39;test6\u0026#39;, data) # json中不能有byte类型 data[\u0026#39;pcapng\u0026#39;] = pcapng_data await msg_q.put(data) total_prod += 1 finally: # Will leave consumer group; perform autocommit if enabled. await consumer.stop() async def upload_to_s3(session,semaphore,queue): global total_s3 while True: data = await queue.get() url = data[\u0026#39;url\u0026#39;] async with semaphore: async with session.put(url,data=data[\u0026#39;pcapng\u0026#39;],headers=headers) as resp: if resp.status == 200: total_s3 += 1 queue.task_done() #print(f\u0026#34;INFO: {time.strftime(\u0026#39;%X\u0026#39;)} finish upload {data[\u0026#39;id\u0026#39;]} {url}. \u0026#34;) else: # 此处错误没有做重传处理，可以采用再放回队列的方式 print(f\u0026#34;ERROR: {time.strftime(\u0026#39;%X\u0026#39;)} {resp.status} {url}. Retried. \u0026#34;) async def print_metric(start_time): while True: t_time = time.time() - start_time s3_speed = total_s3/t_time prod_speed = total_prod/t_time print(f\u0026#34;upload to s3: {s3_speed}\u0026#34;) print(f\u0026#34;produce to kafka: {prod_speed}\u0026#34;) await asyncio.sleep(1) async def main(): #初始化工作 pcapng_q = asyncio.Queue(500) semaphore =asyncio.Semaphore(500) start_time = time.time() async with ClientSession() as session: loop = asyncio.get_running_loop() consumer = AIOKafkaConsumer( \u0026#39;test3\u0026#39;, loop=loop, bootstrap_servers=\u0026#39;localhost:9092\u0026#39;, auto_offset_reset=\u0026#39;earliest\u0026#39;, value_deserializer=lambda m: json.loads(m.decode(\u0026#39;ascii\u0026#39;))) producer = KafkaProducer( value_serializer=lambda v: json.dumps(v).encode(\u0026#39;utf-8\u0026#39;), bootstrap_servers=\u0026#39;localhost:9092\u0026#39; ) consume_task = asyncio.create_task(consume(consumer, producer, pcapng_q)) speed_task = asyncio.create_task(print_metric(start_time)) print(f\u0026#34;started {time.strftime(\u0026#39;%X\u0026#39;)}\u0026#34;) tasks_s3 = [] for i in range(100): tasks_s3.append(asyncio.create_task(upload_to_s3(session,semaphore,pcapng_q))) await pcapng_q.join() await asyncio.gather(consume_task, speed_task, *tasks_s3) if __name__ == \u0026#34;__main__\u0026#34;: try: asyncio.run(main()) except KeyboardInterrupt: print(\u0026#34;Quit.\u0026#34;)   　实际测试生产者用KafkaProducer速度更快，约是AIOKafkaProducer的2倍。\n4.参考代码 　地址：https://github.com/yyyIce/py_exercise/tree/main/asyncio\n　有帮助的话可以点个Star⭐哦~\n附录 　1.一篇asyncio教程，原文：https://realpython.com/async-io-python/\n　2.一篇关于asyncio.gather()的回答：https://stackoverflow.com/questions/62528272/what-does-asyncio-create-task-do\n","description":"对Python asyncio异步编程的理解和应用","id":17,"section":"posts","tags":["python"],"title":"Python：asyncio协程理解及用法","uri":"https://yyyIce.github.io/zh/posts/pythonasyncio%E5%8D%8F%E7%A8%8B%E7%90%86%E8%A7%A3%E5%8F%8A%E7%94%A8%E6%B3%95/"},{"content":"　网络空间测绘乍一听很像新闻联播里的句子，可以在这篇综述中得到能够让人理解的解释。\n阅读小贴士：本文内容主要摘抄于参考文献[1]，作为网络空间测绘背景的快速回顾，可以以文献[1]为线索，进行相关方面资料的查找。\n1.网络空间(Cyberspace) 　网络空间可以理解为看不见的意识空间、用户、网络中的信息流、网络链路、网络设备组成的空间。看不见的意识空间可以简单描述为空间中用户的操作、用户的想法以及链路、设备之间的逻辑结构。如下图所示。\n图1 网络空间:\r\r 　文献[1]中对网络空间要素进行了描述：\n　网络空间的组成要素分为4 种类型: 载体、信息、主体和操作。\n  　载体：网络空间的软硬件设施,是提供信息通信的系统层面的集合;\n  　信息：是在网络空间中流转的数据内容, 包括人类用户及机器用户能够理解、识别和处理的信号状态;\n  　主体：互联网用户, 包括传统互联网中的人类用户以及未来物联网中的机器和设备用户;\n  　操作：对信息的创造、存储、改变、使用、传输、展示等活动。\n  2.网络空间资源 　按文献[1]中的定义，可以将网络空间资源分为实体资源和虚拟资源，如下图所示。\n图2 网络空间资源:\r\r 　网络空间资源用属性来进行区分和识别，是指网络空间资源具备的所有共同性质或独有性质的总和。比如虚拟用户，拥有共同的属性为性别、用户名、年龄等，不同的用户类别可能有独有的属性，比如只允许18岁以上的用户可见部分内容。\n关于计算机网络方向的研究内容主要围绕资源分类图展开。\n3.网络空间资源测绘 3.1 网络空间资源测绘概念 　地理测绘较为容易理解：在(x,y)处，有一个湖泊，面积多大，有什么水产品，周围人如何如何，位置和占地面积记录在地图上，其余相关信息记录在信息库里。\n　网络空间资源测绘就是记录网络空间中各个元素的位置、属性，将整个空间绘制出来。\n　“最初的网络空间测绘的概念主要是采用一些技术方法，来探测全球互联网空间上的节点分布情况和网络关系索引，构建全球互联网图谱的一种方法。”\n　而现在网络空间资源测绘是全面掌握网络空间资源的属性和状态，绘制网络空间资源全息地图，即：\n　“对网络空间中的各类虚实资源及其属性进行探测、分析和绘制的全过程。”\n3.2 网络空间资源测绘方法 　网络空间资源测绘体系是一个“ 探测(Detecting)、分析(Analyzing)、绘制(Visualizing)、应用(Applying)”的循环过程(DAVA Loop)；\n  对各种网络空间资源进行协同探测, 获取探测数据, 对这些数据进行融合分析和多域映射, 形成网络空间资源知识库;\n  在此基础上, 通过多域叠加和综合绘制来构建网络空间资源全息地图;\n  最后, 根据不同的场景目标按需应用这一全息地图, 通过迭代演进使得测绘能力不断提升。\n\r  图3 网络空间资源测绘技术体系图:\r\r 　测绘技术主要分三大方面：协同探测、融合分析、全息绘制\n3.3 网络空间资源测绘应用 　一是区域资产发现、识别和风控，我暂时没有研究内容与其相关；二是服务测绘，服务测绘在平时研究过程中有所涉及。\n4.服务测绘 　“网络空间服务是指网络空间软件设施中的各种泛在应用，其中最典型的一种应用就是网站。”\n　网络空间服务包括属性(内在)，外延的关系。\n图4 网络空间服务结构图:\r\r 　网络空间服务测绘的目标：\n　就是利用主被动协同探测和智能分析手段, 发现动态、时变、隐匿的服务属性和关系, 通过“地图”的方式进行可视化展示,以支撑网络空间安全的各种应用。\n　服务画像：包括基础属性、网络属性、位置属性、通联属性等。例如：\n  基础属性包括企业法人、主办单位名称、网站备案/许可证号、网站名称、网站首页网址等;\n  网络属性包括网站IP、网站域名、AS 号码等; 位置属性包括国家、区域代码、所在地、经纬度、地址等;\n  通联属性包括外链网址, 服务使用者IP 等。\n  　服务信息在时空范围内可与其他资源信息等叠加,按需展示关注点。\n\r图5 基于DAVA Loop循环的服务测绘体系结构图:\r\r 　服务测绘应用场景：\n　(1) 特定服务发现和识别场景: 通过主动扫描、流量监控等多种探测方式, 获取特定服务的信息。对关注区域内的特定服务进行分析与统计, 便于安全监管部门。\n　(2) 区域服务状态评估场景: 绘制网络空间上服务影响范围状态图, 在网络攻防的实践中, 为网络靶场等应用提供精准的攻击效果评估。\n　(3) 特定服务的用户分析场景: 绘制网络空间上服务和用户的连接关系图, 对特定服务的用户以及潜在用户进行群体分析。\n　(4) 特定用户的服务推荐场景: 绘制网络空间上服务和服务的连接关系图, 对特定用户进行服务推荐。\n参考资料 　[1]郭莉, 曹亚男, 苏马婧, et al. 网络空间资源测绘:概念与技术[J]. 信息安全学报, 2018, 3(4).\n","description":"简单了解一下测绘方向，对网络空间有个整体模糊的认识","id":18,"section":"posts","tags":["网络测绘"],"title":"网络空间测绘概述","uri":"https://yyyIce.github.io/zh/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%BD%91%E7%BB%9C%E7%A9%BA%E9%97%B4%E6%B5%8B%E7%BB%98/"},{"content":"\r Python文档：https://realpython.com/async-io-python/ 可以先参看他人博客，大概了解以后看官方文档进行使用，不建议直接看文档进行学习。  \r \r1 yield 　yield在文档中的位置：https://docs.python.org/zh-cn/3/reference/expressions.html#yield-expressions\n 在一个函数体内使用 yield 表达式会使这个函数变成一个生成器，并且在一个 async def 定义的函数体内使用 yield 表达式会让协程函数变成异步生成器。\n 　即yield只能在函数内部使用，并且会使该函数变成生成器函数。如下面示例，含有yield语句的函数返回值是generator类型，不包含yield语句的函数其类型是return值的类型，如无返回值则为NoneType。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  \u0026gt;\u0026gt;\u0026gt; def foo(): ... for i in range(10): ... yield i ... \u0026gt;\u0026gt;\u0026gt; type(foo()) \u0026lt;class \u0026#39;generator\u0026#39;\u0026gt; \u0026gt;\u0026gt;\u0026gt; def boo(): ... for i in range(10): ... pass ... return i ... \u0026gt;\u0026gt;\u0026gt; type(boo()) \u0026lt;class \u0026#39;int\u0026#39;\u0026gt;   \r简单示例  当一个生成器函数被调用的时候，它返回一个迭代器，称为生成器。然后这个生成器来控制生成器函数的执行。\n当这个生成器的某一个方法被调用的时候，生成器函数开始执行。这时会一直执行到第一个 yield 表达式，在此执行再次被挂起，给生成器的调用者返回 expression_list 的值。\n挂起后，我们说所有局部状态都被保留下来，包括局部变量的当前绑定，指令指针，内部求值栈和任何异常处理的状态。\n通过调用生成器的某一个方法，生成器函数继续执行。\n此时函数的运行就和 yield 表达式只是一个外部函数调用的情况完全一致。恢复后 yield 表达式的值取决于调用的哪个方法来恢复执行。\n如果用的是 __next__() (通常通过语言内置的 for 或是 next() 来调用) 那么结果就是 None. 否则，如果用 send(), 那么结果就是传递给send方法的值。\n 　当生成器函数被调用时，它返回一个可迭代对象——生成器。生成器控制生成器函数的执行。即生成器是生成器函数的返回值。下面以一个例子说明yield函数的执行过程，解释一下Python文档的内容。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  #!/usr/bin python3 #yieldtest.py def foo(): for i in range(2,6): r = (yield i) print(f\u0026#34;i: {i}, r: {r}\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: generator_foo = foo() print(next(generator_foo)) print(next(generator_foo)) print(generator_foo.send(66)) print(generator_foo.send(88)) print(next(generator_foo))   　示例首先定义了一个生成器函数foo()（因为它包含yield语句），该函数内部有一个for循环，i的取值为2，3，4，5，用yield返回每个i的取值，并输出i和r的取值，来观察程序执行过程。\n　（1）在__main__中，先定义了一个生成器变量，获取foo()函数返回的生成器，然后用next(\u0026lt;generator\u0026gt;)启动生成器，控制foo()函数的执行。第一步next(generator_foo)，开始运行foo()，此时i=2，程序运行到yield i，从foo()中跳出，保存foo()的运行进度，返回2到__main__中，输出next(generator_foo)的值，即yield i的i值，当前i为2，这句会在屏幕上输出2。\n　如果此处要用.send()方法启动生成器，则send()中参数必须为None。\n1  print(generator_foo.send(None))   　（2）运行第二句next(generator_foo)，恢复foo()的运行进度，从上次停止处继续运行，即r=(yield i)处，上次运行到yield i，这次要对r进行赋值。r的值与调用foo()的方式有关，如果是用next(\u0026lt;generator\u0026gt;)，则r的值为None，如果是用\u0026lt;generator\u0026gt;.send(xxx)，则r的值是xxx。此处用next(\u0026lt;generator\u0026gt;)调用foo()，所以r的值为None。所以输出i: 2, r: None。之后for循环继续，i=3，程序再次运行到yield语句，流程与（1）相同，这一句在屏幕上输出3。\n　（3）运行到第三句generator_foo.send(66))，恢复foo()的运行进度，从上次停止处继续运行，这次与（2）中不同，这次是用.send(66)调用foo()，所以r的值为66。在屏幕输出i: 3, r: 66。之后for循环继续，i=4，程序再次运行到yield语句，流程与（1）相同，这一句在屏幕上输出4。\n　（4）运行到第四句generator_foo.send(88)，和（3）流程相同，r的值为88，在屏幕上输出i: 4, r: 88，然后继续，此时i=5，再次运行到yield i语句，跳出foo()，返回到__main__，输出5。\n　（5）运行到第五句next(generator_foo)，通过next调用foo()，r值为None，所以输出i: 5, r: None，此时生成器没有下一个值，引发StopIteration异常，该异常表示该迭代器不能产生下一项。\n　所以上面例子的输出为：\n1 2 3 4 5 6 7 8 9 10 11 12 13  $ python3.7 yieldtest.py 2 i: 2, r: None 3 i: 3, r: 66 4 i: 4, r: 88 5 i: 5, r: None Traceback (most recent call last): File \u0026#34;yieldtest.py\u0026#34;, line 15, in \u0026lt;module\u0026gt; print(next(generator_foo)) StopIteration   文档中的示例 generator.\u0026lt;method()\u0026gt;：\n generator.__next__() generator.send(value) generator.throw(type[, value[, traceback]])：在生成器暂停的位置引发 type 类型的异常，并返回该生成器函数所产生的下一个值（value和traceback是可选参数，通常就这么写）。 generator.close()：在生成器函数暂停的位置引发GeneratorExit。如果生成器不产生值，则正常退出，产生值引发 RuntimeError。  具体说明可以查阅文档6.2.9.1。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  \u0026gt;\u0026gt;\u0026gt; def echo(value=None): ... print(\u0026#34;Execution starts when \u0026#39;next()\u0026#39; is called for the first time.\u0026#34;) ... try: ... while True: ... try: ... value = (yield value) ... except Exception as e: ... value = e ... finally: ... print(\u0026#34;Don\u0026#39;t forget to clean up when \u0026#39;close()\u0026#39; is called.\u0026#34;) ... \u0026gt;\u0026gt;\u0026gt; generator = echo(1) \u0026gt;\u0026gt;\u0026gt; print(next(generator)) Execution starts when \u0026#39;next()\u0026#39; is called for the first time. 1 \u0026gt;\u0026gt;\u0026gt; print(next(generator)) None \u0026gt;\u0026gt;\u0026gt; print(generator.send(2)) 2 \u0026gt;\u0026gt;\u0026gt; generator.throw(TypeError, \u0026#34;spam\u0026#34;) TypeError(\u0026#39;spam\u0026#39;,) \u0026gt;\u0026gt;\u0026gt; generator.close() Don\u0026#39;t forget to clean up when \u0026#39;close()\u0026#39; is called.   2 yield from 　官方文档：https://docs.python.org/zh-cn/3/whatsnew/3.3.html#pep-380\n　PEP380添加了yield from表达式，允许生成器把它的部分操作委托给另一个生成器。这让一部分包含yield的代码分解出来并放入另一个生成器中。此外，子生成器可以有返回值，发出委托的生成器可以获取该值。\n　虽然主要用于委托给一个子生成器，yield from表达式实际上也允许委托给任意的子迭代器。\n　对于简单的迭代器，yield from iterable基本上仅仅是for item in iterable:yield item的缩写：\n1 2 3 4 5 6  \u0026gt;\u0026gt;\u0026gt; def g(x): ... yield from range(x, 0, -1) ... yield from range(x) ... \u0026gt;\u0026gt;\u0026gt; list(g(5)) [5, 4, 3, 2, 1, 0, 1, 2, 3, 4]   　然而，与普通循环不同，yield from允许子生成器直接从调用中接收发送的和抛出的值，然后返回一个最终的值给外部的生成器：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  \u0026gt;\u0026gt;\u0026gt; def accumulate(): ... tally = 0 ... while 1: ... next = yield ... if next is None: ... return tally ... tally += next ... \u0026gt;\u0026gt;\u0026gt; def gather_tallies(tallies): ... while 1: ... tally = yield from accumulate() ... tallies.append(tally) ... \u0026gt;\u0026gt;\u0026gt; tallies = [] \u0026gt;\u0026gt;\u0026gt; acc = gather_tallies(tallies) \u0026gt;\u0026gt;\u0026gt; next(acc) # Ensure the accumulator is ready to accept values \u0026gt;\u0026gt;\u0026gt; for i in range(4): ... acc.send(i) ... \u0026gt;\u0026gt;\u0026gt; acc.send(None) # Finish the first tally \u0026gt;\u0026gt;\u0026gt; for i in range(5): ... acc.send(i) ... \u0026gt;\u0026gt;\u0026gt; acc.send(None) # Finish the second tally \u0026gt;\u0026gt;\u0026gt; tallies [6, 10]   　accumulate()是子生成器函数，gather_tallies()是外部生成器函数。acc是gather_tallies()返回的生成器。通过next(acc)启动acc。执行到yield from accumulate()，执行到accumulate()中的yield返回；然后通过acc.send(i)控制函数执行，发送0给gather_tallies()，但函数执行到accumulate()的next = yield，所以发送的值由next变量接收，因为子生成器可以直接接收发送的值。\n　发送到3以后，发送None，accumulate()中的next变量收到None，执行到return tally，tally的值为1+2+3=6，返回到gather_tallies()，tally的值为6，然后tallies.append(tally)将6加入到tallies列表中，此时tallies=[6,]。\n　然后再调用acc.send()，仍由accumulate()的next变量接收，发送到4以后，发送None，accumulate()中的next变量收到None，执行到return tally，tally的值为1+2+3+4=10，返回到gather_tallies()，tally的值为10，然后tallies.append(tally)将10加入到tallies列表中，此时tallies=[6, 10]。\n\ryield from语句其实就是表明后面是一个生成器，使代码看起来更整洁。\n\r \r　做出这种改变的主要原理是允许生成器分割成多个子生成器和把大的函数分解成多个子函数一样简单，通过send和throw来实现分割。\n","description":"对Python yield的理解和应用","id":19,"section":"posts","tags":["python"],"title":"Python：yield 用法和理解","uri":"https://yyyIce.github.io/zh/posts/pythonyield%E7%94%A8%E6%B3%95%E5%92%8C%E7%90%86%E8%A7%A3/"},{"content":"\r Python文档：https://docs.python.org/zh-cn/3/library/threading.html 可以先参看他人博客，大概了解以后看官方文档进行使用，不建议直接看文档进行学习。  \r \r1 threading  线程类表示在单独的控制线程中运行的活动。有两种指定活动的方法：\n 传递一个可调用对象给构造器； 在子类中重写run()方法。  子类中不应该覆盖其他方法（构造函数除外）。换句话说，只允许重写这个类的__init__()和run()\n 　可调用对象：可以被调用执行的对象，并且可以传入参数，如函数、类、类中的函数、实现了__call__方法的实例对象。\n线程对象Thread  class threading.Thread(group=None, target=None, name=None, args=(), kwargs={}, ***, daemon=None)\n  group：不必管，为了扩展ThreadGroup类实现而保留 target：run()方法调用的可调用对象 name：线程名称，默认格式为Thread-N args：调用目标函数的参数元组 kwargs：用于调用目标函数的关键字参数字典 daemon：设置线程是否是守护模式，不建议使用setDaemon()  创建一个线程：\n1 2  from threading import Thread t = Thread(target=\u0026lt;可调用对象\u0026gt;,args=(\u0026lt;可调用对象的参数\u0026gt;),...)   启动一个线程：\u0026lt;thread_instance\u0026gt;.start()\nt.start()\r开始线程活动：\u0026lt;thread_instance\u0026gt;.run()\n　在不重写线程run()方法的情况下，就是普通地运行一下target（可调用对象），一般指定target就行，需要人为控制暂停、恢复和退出的需要自定义线程类。\n　__init__()和.run()方法的源代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55  #Lib/threading.py def __init__(self, group=None, target=None, name=None, args=(), kwargs=None, *, daemon=None): \u0026#34;\u0026#34;\u0026#34;This constructor should always be called with keyword arguments. Arguments are: *group* should be None; reserved for future extension when a ThreadGroup class is implemented. *target* is the callable object to be invoked by the run() method. Defaults to None, meaning nothing is called. *name* is the thread name. By default, a unique name is constructed of the form \u0026#34;Thread-N\u0026#34; where N is a small decimal number. *args* is the argument tuple for the target invocation. Defaults to (). *kwargs* is a dictionary of keyword arguments for the target invocation. Defaults to {}. If a subclass overrides the constructor, it must make sure to invoke the base class constructor (Thread.__init__()) before doing anything else to the thread. \u0026#34;\u0026#34;\u0026#34; assert group is None, \u0026#34;group argument must be None for now\u0026#34; if kwargs is None: kwargs = {} self._target = target self._name = str(name or _newname()) self._args = args self._kwargs = kwargs if daemon is not None: self._daemonic = daemon else: self._daemonic = current_thread().daemon self._ident = None if _HAVE_THREAD_NATIVE_ID: self._native_id = None self._tstate_lock = None self._started = Event() self._is_stopped = False self._initialized = True # Copy of sys.stderr used by self._invoke_excepthook() self._stderr = _sys.stderr self._invoke_excepthook = _make_invoke_excepthook() # For debugging and _after_fork() _dangling.add(self) def run(self): \u0026#34;\u0026#34;\u0026#34;Method representing the thread\u0026#39;s activity. You may override this method in a subclass. The standard run() method invokes the callable object passed to the object\u0026#39;s constructor as the target argument, if any, with sequential and keyword arguments taken from the args and kwargs arguments, respectively. \u0026#34;\u0026#34;\u0026#34; try: if self._target: self._target(*self._args, **self._kwargs) finally: # Avoid a refcycle if the thread is running a function with # an argument that has a member that points to the thread. del self._target, self._args, self._kwargs   线程使用示例：\n 程序来源于https://python3-cookbook.readthedocs.io/zh_CN/latest/c12/p01_start_stop_thread.html\n 1 2 3 4 5 6 7 8 9 10 11 12  #simple_thread.py import time from threading import Thread def countdown(n): while n \u0026gt; 0: print(\u0026#39;T-minus\u0026#39;, n) n -= 1 time.sleep(5) #注意args=(10,)的逗号不能省，不然不是tuple是int t = Thread(target=countdown, args=(10,)) t.start()   等待线程.join()\n　在A线程中调用B.join()，则A线程在B.join()之后的语句直到B线程执行完毕之后才会执行，例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  # thread_join.py import time from threading import Thread def countdown(n, id): while n \u0026gt; 0: print(f\u0026#39;T{id}-minus {n}\u0026#39;) n -= 1 time.sleep(5) #注意args=(10,)的逗号不能省，不然不是tuple是int t1 = Thread(target=countdown, args=(3,1)) t2 = Thread(target=countdown, args=(3,2)) t1.start() t2.start() t1.join() print(\u0026#34;after join.\u0026#34;) #输出 T1-minus 3 T2-minus 3 T1-minus 2 T2-minus 2 T1-minus 1 T2-minus 1 after join.   注释掉t1.join()后的输出如下，主线程无需等待线程1运行完毕再向后执行。\n1 2 3 4 5 6 7  T1-minus 3 T2-minus 3 after join. T1-minus 2 T2-minus 2 T1-minus 1 T2-minus 1   守护模式daemon\n 参考：https://blog.csdn.net/dongfuguo/article/details/53899426\n 　默认值为False。\n　如果在主线程中创建了子线程，当主线程结束时根据子线程daemon属性值的不同可能会发生下面的两种情况之一：\n 如果某个子线程的daemon属性为False，主线程结束时会检测该子线程是否结束，如果该子线程还在运行，则主线程会等待它完成后再退出； 如果某个子线程的daemon属性为True，主线程运行结束时不对这个子线程进行检查而直接退出，同时所有daemon值为True的子线程将随主线程一起结束，而不论是否运行完成。  　需要注意的是现在已经不提倡使用t.setDaemon(True)来设置，而是直接在初始化时设置线程是否是守护模式，设置方法：\n1 2 3 4  from threading import Thread t = Thread(target=\u0026lt;可调用对象\u0026gt;,args=(\u0026lt;可调用对象的参数\u0026gt;),daemon=True) #或下面这种方式，注意要在start()之前设置 t.daemon=True   　daemon使用效果示例如下，t1线程是守护线程，主线程运行完毕后不用理会t1。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  # thread_daemon.py import time from threading import Thread def countdown(n, id): while n \u0026gt; 0: print(f\u0026#39;T{id}-minus {n}\u0026#39;) n -= 1 time.sleep(5) #t1 = Thread(target=countdown, args=(3,1), daemon=False) t1 = Thread(target=countdown, args=(3,1), daemon=True) t1.start() print(\u0026#34;Main Thread End.\u0026#34;) #输出 T1-minus 3 Main Thread End.   　如果daemon值为False，则应该输出下面的内容，程序会在t1线程运行完毕再退出。\n1 2 3 4  T1-minus 3 Main Thread End. T1-minus 2 T1-minus 1   2.自定义线程类 　自定义的线程可以控制线程的暂停、恢复、退出，Thread()方法定义的线程如果是while True的消费者就没法结束它了。\n　第1节中提到，继承只允许修改__init__方法和run()方法，所以自定义线程类中仅需要重写这两项，个人感觉初学情况下重写的类还不如原生的。\n　自定义线程类示例，实现的功能和上面的功能相同：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  # thread_custom.py import threading import time #继承Thread类，创建自定义线程类 class mythread(threading.Thread): def __init__(self, num, threadname): #super会将后面的方法委托给父类，等价于threading.Thread.__init__(self, name=threadname) super().__init__(self, name=threadname) self.num = num #重写run()方法 def run(self): while self.num \u0026gt; 0: print(f\u0026#39;{self.name}-minus {self.num}\u0026#39;) self.num -= 1 time.sleep(5) t1 = mythread(3, \u0026#39;t1\u0026#39;) t1.start() #输出 t1-minus 3 t1-minus 2 t1-minus 1   自定义线程控制线程暂停、恢复、退出  参考：https://www.cnblogs.com/scolia/p/6132950.html\n 　利用线程的事件对象threading.Event。\n 是线程间通信的机制：一个线程发出时间信号，其他线程等待信号。一个事件（Event）对象管理一个内部标识。\nset()：将此事件的内部标识置为True，所有等待这个事件的线程会被唤醒。\nclear()：将此事件的内部标识置为False，之后调用wait()的线程会被阻塞。\nwait(timeout=None)：如果此事件的内部标识为True，立即返回；否则阻塞线程，直到标识为True。\nis_set()：当且仅当内部标识为True时返回True。\n 　线程暂停与恢复：可以将事件理解为一个信号，在线程内部设置一个事件，在暂停时调用clear()，设置内部标识为False，恢复时设置内部标识为True。在run()函数中调用wait()让事件的阻塞效果生效。\n　线程退出：在线程内部设置另一个事件，在run()中设置while \u0026lt;stop_event\u0026gt;.is_set():循环，将目标函数放在循环内，初始化时将该事件set()，退出时将该事件clear()，此时由于不满足while循环条件，run()函数执行完毕，线程结束。\n　程序示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  # thread_pause.py import threading import time class myThread(threading.Thread): def __init__(self, *args, **kwargs): super().__init__(*args, **kwargs) self.__flag = threading.Event() # 用于暂停线程的标识 self.__flag.set() self.__running = threading.Event() # 用于结束线程的标识 self.__running.set() def run(self): while self.__running.isSet(): self.__flag.wait() # 如果__flag=False则阻塞 print(time.time()) time.sleep(1) def pause(self): self.__flag.clear() # 设置为False, 让线程阻塞 def resume(self): self.__flag.set() # 设置为True, 唤醒线程 def stop(self): self.__flag.set() # 如果线程暂停则先恢复 self.__running.clear() # 设置为False a = myThread() a.start() time.sleep(3) a.pause() time.sleep(5) a.resume() time.sleep(3) a.pause() time.sleep(2) a.stop()   　**为什么选用这种方法：**这种方法虽然比较慢但是比较安全，让run()方法的自然执行完毕退出，强行杀死线程可能会遇到数据丢失等离谱的错误。\n3.多线程 　Python中多线程直接创建多个线程实例然后用.start()方法启动就行了。由于实际应用中没用到过这部分，所以仅作简单介绍，以后有深刻理解再补充。而且由于Python有全局锁，其中多线程会强制在单核上运行，所以Python的多线程是并发而不是并行，我更推荐使用协程和多进程。\n3.1 线程调度　  来源：https://my.oschina.net/u/240562/blog/137040\n线程切换由Python决定，内部维护着一个数值，这个数值是python的内部时钟，默认值是100，也就是说python在执行完100条语句之后，开始进行线程调度。也使用这个数值检查是否有异步事件发生。需要处理。\npython控制着什么时候进行线程调度，当一个线程获得访问python解释器的所必需的GIL并进入解释器后，即当这个线程执行了100条语句后，python解释器将强制挂起当前线程，开始切换到下一个处于等待的线程。\n究竟哪个线程会被执行，在这个问题上python是不会插手的，而是交给底层的操作系统来解决，python借用底层的操作系统的线程调度机制来决定下一个进入python解释器的线程究竟是谁。\n所以python的线程实际就是操作系统所支持的原生线程，python的多线程机制建立在操作系统的原生线程机制之上，不同的操作系统有不同的实现。\n然而最终，在不同的操作系统的原生线程之上，python提供了一套统一的抽象机制，给python的使用者一个多线程的工具箱，就是python的Thread和Threading。\n 　总结一下，就是Python多线程的切换由操作系统控制，可以简单理解为分时，每个线程占据一定的时间片，时间片运行完的线程被操作系统切换掉。　　线程调度由Python控制，且一般情况下在单核上执行。Python实现了跨平台的多线程机制，但本质上激活等待线程与操作系统有关，不同操作系统可能由不同的结果。线程切换的开销小于进程切换。\n3.2 锁对象 　class threading.Lock是实现原始锁对象的类，用于同步。一旦一个线程获得一个锁，会阻塞随后尝试获得锁的线程，直到它被释放；任何线程都可以释放它。\n   acquire(blocking=True, timeout=-1)\n可以阻塞或非阻塞地获得锁。\nblocking：当调用时参数 blocking 设置为 True （缺省值），阻塞直到锁被释放，然后将锁锁定并返回 True 。在参数 blocking 被设置为 False 的情况下调用，将不会发生阻塞。如果调用时 blocking 设为 True 会阻塞，并立即返回 False ；否则，将锁锁定并返回 True。\ntimeout：当浮点型 timeout 参数被设置为正值调用时，只要无法获得锁，将最多阻塞 timeout 设定的秒数。timeout 参数被设置为 -1 时将无限等待。当 blocking 为 false 时，timeout 指定的值将被忽略。如果成功获得锁，则返回 True，否则返回 False (例如发生 超时 的时候)。\n  release()\n释放一个锁。这个方法可以在任何线程中调用，不单指获得锁的线程。当锁被锁定，将它重置为未锁定，并返回。如果其他线程正在等待这个锁解锁而被阻塞，只允许其中一个重置。在未锁定的锁调用时，会引发 RuntimeError 异常。没有返回值。\n  locked()\n如果获得了锁则返回真值。\n   创建一个锁对象：\n1 2  import threading my_lock = threading.Lock()   获得锁和释放锁：\n1 2 3 4  #获得锁 my_lock.acquire() #释放锁 my_lock.release()   　当操作共享的数据时，需要保证原子操作，否则可能会得到意想不到的结果，锁用来保证原子操作。下面的示例代码展示了当没有锁保证原子性操作时可能得到的错误结果。\n　下面的代码预期的结果是0，但不加锁的情况下会导致出现意外的输出。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  # -*- coding: utf-8 -*- #thread_lock.py #来源：https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/chapter2/06_Thread_synchronization_with_Lock_and_Rlock.html import threading shared_resource_with_lock = 0 shared_resource_with_no_lock = 0 COUNT = 100000 shared_resource_lock = threading.Lock() # 有锁的情况 def increment_with_lock(): global shared_resource_with_lock for i in range(COUNT): shared_resource_lock.acquire() shared_resource_with_lock += 1 shared_resource_lock.release() def decrement_with_lock(): global shared_resource_with_lock for i in range(COUNT): shared_resource_lock.acquire() shared_resource_with_lock -= 1 shared_resource_lock.release() # 没有锁的情况 def increment_without_lock(): global shared_resource_with_no_lock for i in range(COUNT): shared_resource_with_no_lock += 1 def decrement_without_lock(): global shared_resource_with_no_lock for i in range(COUNT): shared_resource_with_no_lock -= 1 if __name__ == \u0026#34;__main__\u0026#34;: t1 = threading.Thread(target=increment_with_lock) t2 = threading.Thread(target=decrement_with_lock) t3 = threading.Thread(target=increment_without_lock) t4 = threading.Thread(target=decrement_without_lock) t1.start() t2.start() t3.start() t4.start() t1.join() t2.join() t3.join() t4.join() print (\u0026#34;the value of shared variable with lock management is %s\u0026#34; % shared_resource_with_lock) print (\u0026#34;the value of shared variable with race condition is %s\u0026#34; % shared_resource_with_no_lock)   上述代码的几次输出结果：\n1 2 3 4 5 6 7 8 9  #1 the value of shared variable with lock management is 0 the value of shared variable with race condition is 32622 #2 \u0026amp; 3 \u0026amp; 4 the value of shared variable with lock management is 0 the value of shared variable with race condition is 0 #5 the value of shared variable with lock management is 0 the value of shared variable with race condition is -8627   　产生这种输出的原因是，在没有锁的情况下，线程的切换是由Python控制的，不一定执行到什么时候就切换线程了，导致线程切换前后共享变量的值不一致。\n　举例来说，可能执行到时刻A时，t4运行到shared_resource_with_no_lock -= 1时切换到了t3，运行shared_resource_with_no_lock += 1，执行了很多次shared_resource_with_no_lock += 1，运行到时刻B切换回t4,但此时shared_resource_with_no_lock -= 1中的shared_resource_with_no_lock已经不是时刻A的shared_resource_with_no_lock，导致被减数增大了，结果就会与预期不符，产生第一次输出的结果。\n　但t4加上锁之后，即使切换到t3，由于锁已经被获得，t3会被阻塞，又会切回到t4，从而保证了在线程切换时shared_resource_with_lock的值不变。\n3.3 信号量对象 　用于保护数量有限的资源，在资源数量固定的任何情况下，都应该使用有界信号量。在生成任何工作线程前，应该在主线程中初始化信号量。还没用过，暂时不介绍了，用法和锁相似，只不过信号量计数。\n3.4 队列 　注意进程、线程、协程都有队列，且定义在不同的文件里，这里指线程队列。\n　线程用的队列就是queue模块的Queue对象。\n 文档：https://docs.python.org/zh-cn/3/library/queue.html\nqueue.Queue（先入先出，还有LifoQueue和PriorityQueue）\n qsize()：返回队列的大致大小。 empty()：队列为空返回True。 full()：队列满返回True。 put(item, block=True, timeout=None)：将item放入队列。  如果可选参数 block 是 true 并且 timeout 是 None (默认)，则在必要时阻塞至有空闲插槽可用。如果 timeout 是个正数，将最多阻塞 timeout 秒，如果在这段时间没有可用的空闲插槽，将引发 Full 异常。 如果可选参数 block 是 false，如果空闲插槽立即可用，则把 item 放入队列，否则引发 Full 异常 ( 在这种情况下，timeout 将被忽略)。   put_nowait(item)：相当于put(item, False)。 get(block=True,timeout=None)：从队列中移除并返回一个项目。  如果可选参数 block 是 true 并且 timeout 是 None (默认值)，则在必要时阻塞至项目可获得。如果 timeout 是个正数，将最多阻塞 timeout 秒，如果在这段时间内项目不能得到，将引发 Empty 异常。 如果可选参数 block 是 false , 如果一个项目立即可得到，则返回一个项目，否则引发 Empty 异常 (这种情况下，timeout 将被忽略)。   get_nowait()：相当于get(False)。 task_done()：表示前面排队的任务已经被完成。被队列的消费者线程使用。每个 get() 被用于获取一个任务， 后续调用 task_done() 告诉队列，该任务的处理已经完成。如果 join() 当前正在阻塞，在所有条目都被处理后，将解除阻塞(意味着每个 put() 进队列的条目的 task_done() 都被收到)。如果被调用的次数多于放入队列中的项目数量，将引发 ValueError 异常 。 join()：阻塞至队列中所有的元素都被接收和处理完毕。   创建一个队列：\n1 2  import queue q = queue.Queue()   线程间使用队列通信：\n 来源：https://www.cnblogs.com/Keep-Ambition/p/7597664.html\n 　修改了来源中consumer中count+1的位置，因为会出现队列为空的情况，会导致执行了else语句，没有消费到东西，却对count+1了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  # thread_queue.py import time,random import queue,threading q = queue.Queue() def producer(name): count = 0 while count \u0026lt; 20: time.sleep(random.randrange(3)) q.put(count) # 生产item到队列 print(\u0026#39;Producer %shas produced %sitem..\u0026#39; % (name, count)) count += 1 def consumer(name): count = 0 while count \u0026lt; 20: time.sleep(random.randrange(4)) if not q.empty(): # 如果还有item data = q.get() # 就继续获取item #\u0026#39;\\033[显示方式;前景色;背景色m\u0026lt;输出内容\u0026gt;\\033[0m\u0026#39;输出有文字颜色和背景色的内容，其中\u0026#39;\\033[0m\u0026#39;表示该颜色结束 print(\u0026#39;\\033[32;1mConsumer %shas eat %sitem...\\033[0m\u0026#39; % (name, data)) count += 1 q.task_done() else: print(\u0026#34;waiting...\u0026#34;) p1 = threading.Thread(target=producer, args=(\u0026#39;A\u0026#39;,)) c1 = threading.Thread(target=consumer, args=(\u0026#39;B\u0026#39;,)) p1.start() c1.start() q.join()   　输出：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  Producer A has produced 0 item.. Producer A has produced 1 item.. Producer A has produced 2 item.. Consumer B has eat 0 item... Producer A has produced 3 item.. Producer A has produced 4 item.. Consumer B has eat 1 item... Producer A has produced 5 item.. Consumer B has eat 2 item... Producer A has produced 6 item.. Producer A has produced 7 item.. Producer A has produced 8 item.. Producer A has produced 9 item.. Producer A has produced 10 item.. Producer A has produced 11 item.. Producer A has produced 12 item.. Consumer B has eat 3 item... Producer A has produced 13 item.. Consumer B has eat 4 item... Producer A has produced 14 item.. Producer A has produced 15 item.. Producer A has produced 16 item.. Consumer B has eat 5 item... Consumer B has eat 6 item... Producer A has produced 17 item.. Producer A has produced 18 item.. Producer A has produced 19 item.. Consumer B has eat 7 item... Consumer B has eat 8 item... Consumer B has eat 9 item... Consumer B has eat 10 item... Consumer B has eat 11 item... Consumer B has eat 12 item... Consumer B has eat 13 item... Consumer B has eat 14 item... Consumer B has eat 15 item... Consumer B has eat 16 item... Consumer B has eat 17 item... Consumer B has eat 18 item... Consumer B has eat 19 item...   4.参考代码 　地址：https://github.com/yyyIce/py_exercise/tree/main/threading\n　有帮助的话可以点个Star⭐哦~\n参考资料 1.管道和队列的选择：https://qastack.cn/programming/8463008/multiprocessing-pipe-vs-queue\n2.可调用对象：https://zhuanlan.zhihu.com/p/101792911\n3.线程调度机制：https://my.oschina.net/u/240562/blog/137040\n4.Python输出有颜色和背景色的文字：https://o-u-u.com/?p=2940\n","description":"Python多线程编程的理解与应用","id":20,"section":"posts","tags":["python"],"title":"Python：多线程编程","uri":"https://yyyIce.github.io/zh/posts/python%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B/"},{"content":"\r 本文是多进程和协程的综合使用示例，至少2个核才能充分达到速度要求，实际工程中这么用好不好暂时不清楚。 这里仅给出简要代码，可以自行添加日志、配置文件等功能。  \r \r整体设计 进程1：从kafka的CONSUME_TOPIC中消费消息放入进程队列msg_q，然后修改消息内容生产到PRODUCE_TOPIC中。通过一个协程打印消费生产速度。\n进程2：从进程队列msg_q中取出消息，根据消息内容异步发送HTTP请求，对于失败的请求，将消息重新放回队列。通过一个协程打印获取响应的速度。\n【图】\n代码编写 需要注意的问题 队列为空时进程将阻塞，需要进行检查和处理\n同步问题，修改偏移量需要在同一次控制权中修改\n参考代码 　地址：\n","description":"综合进程和协程进行使用","id":21,"section":"posts","tags":["python"],"title":"Python：多进程+协程编程示例","uri":"https://yyyIce.github.io/zh/posts/python%E5%A4%9A%E8%BF%9B%E7%A8%8B+%E5%8D%8F%E7%A8%8B%E7%BC%96%E7%A8%8B%E7%A4%BA%E4%BE%8B/"},{"content":"\r Python文档：https://docs.python.org/zh-cn/3/library/multiprocessing.html 可以先参看他人博客，大概了解以后看官方文档进行使用，不建议直接看文档进行学习。  \r \r1 multiprocessing  multiprocessing可以并发操作，通过子进程有效地绕过了全局解释器锁，允许程序员充分利用给定机器上的多个处理器，在Unix和Windows上均可运行。\n源代码：https://github.com/python/cpython/tree/3.9/Lib/multiprocessing/\n其中Process类在process.py文件中。\n 　Process和threading.Thread的API相同。\n class multiprocessing.Process(group=None, target=None, name=None, args=(), kwargs={}, ***, daemon=None)\n  group：不用管，保留 target：run()方法调用的可调用对象 name：线程名称，默认格式为Thread-N args：调用目标函数的参数元组 kwargs：用于调用目标函数的关键字参数字典 daemon：设置线程是否是守护模式，不建议使用setDaemon()  　创建一个进程：\n1 2 3  from multiprocessing import Process if __name__ == \u0026#39;__main__\u0026#39;: p = Process(target=\u0026lt;可调用对象\u0026gt;,args=(\u0026lt;可调用对象的参数\u0026gt;),...)   　启动一个进程：\n1 2 3 4  from multiprocessing import Process if __name__ == \u0026#39;__main__\u0026#39;: p = Process(target=\u0026lt;可调用对象\u0026gt;,args=(\u0026lt;可调用对象的参数\u0026gt;),...) p.start()   　开始进程活动：\n\u0026lt;Process\u0026gt;.run()，.run()方法代码如下，和线程相似，把活动写成函数在初始化时赋值给target即可。\n1 2 3 4 5 6 7  #Lib/multiprocessing/process.py def run(self): \u0026#39;\u0026#39;\u0026#39; Method to be run in sub-process; can be overridden in sub-class \u0026#39;\u0026#39;\u0026#39; if self._target: self._target(*self._args, **self._kwargs)   　启动进程的方法\n spawn：只继承运行run()方法所必要的资源，比fork和forkserver慢。Windows和Unix上都可用。 fork：父进程使用os.fork()，只能在Unix上用。 forkserver：需要新进程时，父进程连接服务器，请求它分出一个新进程。可在Unix上使用。  　使用方法：在if __name__ == '__main__':中调用set_start_method()，这个方法不应该被多次调用。\n1 2 3 4 5 6 7 8 9 10 11 12  import multiprocessing as mp def foo(q): q.put(\u0026#39;hello\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: mp.set_start_method(\u0026#39;fork\u0026#39;) q = mp.Queue() p = mp.Process(target=foo, args=(q,)) p.start() print(q.get()) p.join()   　进程调度\n　进程优先在不同的核（CPU）上运行，比如有CPU1，CPU2，CPU3和进程1-6，则进程可能是1、4在CPU1上运行，2、5在CPU2上运行，3、6在CPU3上运行（不一定是按这种顺序分布，但会在不同的核上，也可能1和6在同一个核上）。multiprocessing.cpu_count()查看当前核数。\n1 2  import multiprocessing print(multiprocessing.cpu_count())   　可以使用psutil查看进程信息，这里利用pstutil的cpu_num()方法查看当前进程运行在哪个CPU上，编号从0开始，使用方法参考下面的代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  import psutil import os import multiprocessing from multiprocessing import Process def producer(name): //... pass if __name__ == \u0026#39;__main__\u0026#39;: p1 = Process(target=producer, args=(\u0026#39;A\u0026#39;,)) p1.start() parent = psutil.Process(os.getpid()) print(\u0026#34;main: %d\u0026#34; % parent.cpu_num())   2 进程间通信 　multiprocessing支持进程间两种通信通道：队列（multiprocessing.Queue和multiprocessing.Pipe）和管道。\n　并发编程尽量避免使用共享状态，使用队列和管道进行通信，本次学习进程的目的本身就是为了并发编程，所以这里不介绍共享状态。\n2.1 队列和管道的选择   Pipe只能有两个端点，Queue可以有多个生产者和消费者\n  如果需要两个以上的交流点，使用Queue；需要缓冲数据时，队列是比管道更好的选择。\n  如果想要绝对的性能，选用Pipe()，因为Queue()建立在Pipe()之上。\n  2.2 进程队列 　multiprocessing.Queue和queue.Queue近似，但进程Queue没有join()和task_done()方法，但它有join_thread()方法。\n 文档：https://docs.python.org/zh-cn/3/library/multiprocessing.html?highlight=queue#pipes-and-queues\nqueue.Queue（先入先出，还有LifoQueue和PriorityQueue）\n qsize()：返回队列的大致大小。 empty()：队列为空返回True。 full()：队列满返回True。 put(obj[, block[, timeout]])：将obj放入队列。  如果可选参数 block 是 true 并且 timeout 是 None (默认)，则在必要时阻塞至有空闲插槽可用。如果 timeout 是个正数，将最多阻塞 timeout 秒，如果在这段时间没有可用的空闲插槽，将引发 queue.Full 异常。 如果可选参数 block 是 false，如果空闲插槽立即可用，则把 item 放入队列，否则引发 Full 异常 ( 在这种情况下，timeout 将被忽略)。   put_nowait(item)：相当于put(item, False)。 get([block[, timeout]])：从队列中移除并返回一个项目。  如果可选参数 block 是 true 并且 timeout 是 None (默认值)，则在必要时阻塞至项目可获得。如果 timeout 是个正数，将最多阻塞 timeout 秒，如果在这段时间内项目不能得到，将引发 Empty 异常。 如果可选参数 block 是 false , 如果一个项目立即可得到，则返回一个项目，否则引发 Empty 异常 (这种情况下，timeout 将被忽略)。   get_nowait()：相当于get(False)。 close()：指示当前进程将不会再往队列中放入对象。 join_thread()：等待后台线程，仅在调用了close()方法后可用。阻塞当前进程，直到后台线程退出，确保所有缓冲区的数据都被写入管道中。 cancel_join_thread()：防止join_thread()方法阻塞当前进程。如果该进程不是队列的创建者，不需要等待队列的后台线程退出，此时调用这个方法可以让join_thread()方法什么都不做直接跳过。   　队列的简单使用：\n1 2 3 4 5 6 7 8 9 10 11 12  # multiprocess_queue.py from multiprocessing import Process, Queue def f(q): q.put([42, None, \u0026#39;hello\u0026#39;]) if __name__ == \u0026#39;__main__\u0026#39;: q = Queue() p = Process(target=f, args=(q,)) p.start() print(q.get()) # prints \u0026#34;[42, None, \u0026#39;hello\u0026#39;]\u0026#34; p.join()   　生产者消费者模型：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  # multiprocess_queue_pc.py import time,random from multiprocessing import Process, Queue def producer(name): count = 0 while count \u0026lt; 20: time.sleep(random.randrange(3)) q.put(count) # 生产item到队列 print(\u0026#39;Producer %shas produced %sitem..\u0026#39; % (name, count)) count += 1 def consumer(name): count = 0 while count \u0026lt; 20: time.sleep(random.randrange(4)) if not q.empty(): # 如果还有item data = q.get() # 就继续获取item #\u0026#39;\\033[显示方式;前景色;背景色m\u0026lt;输出内容\u0026gt;\\033[0m\u0026#39;输出有文字颜色和背景色的内容，其中\u0026#39;\\033[0m\u0026#39;表示该颜色结束 print(\u0026#39;\\033[32;1mConsumer %shas eat %sitem...\\033[0m\u0026#39; % (name, data)) count += 1 else: print(\u0026#34;waiting...\u0026#34;) q = Queue() p1 = Process(target=producer, args=(\u0026#39;A\u0026#39;,)) c1 = Process(target=consumer, args=(\u0026#39;B\u0026#39;,)) p1.start() c1.start()   JoinableQueue 　Queue队列没有join()和task_done()方法，在JoinableQueue中有这两个方法，JoinableQueue是Queue的子类。\n　经使用发现，Queue队列会出现队列中还有未处理元素却退出的情况，这时需要使用JoinableQueue()。\n  task_done：对于每次调用get()获取的任务，执行完成后调用task_done()告诉队列该任务已经处理完成。\n  join()：阻塞至队列中所有的元素都被接收和处理完毕。\n  3 进程池 　暂时用不到，不整理了，参考：https://blog.csdn.net/SeeTheWorld518/article/details/49639651\n4 参考代码 　地址：https://github.com/yyyIce/py_exercise/tree/main/multiprocessing\n　有帮助的话可以点个Star⭐哦~\n参考资料 　管道和队列的选择：https://qastack.cn/programming/8463008/multiprocessing-pipe-vs-queue\n","description":"对Python多进程的理解与应用","id":22,"section":"posts","tags":["python"],"title":"Python：多进程编程","uri":"https://yyyIce.github.io/zh/posts/python%E5%A4%9A%E8%BF%9B%E7%A8%8B%E7%BC%96%E7%A8%8B/"},{"content":"\r 原文：https://realpython.com/async-io-python/ 这个看原英文挺容易看懂的，在看的同时顺便翻译出来供英语属实不行的人使用。  \r \r　异步IO（Async IO）是并发编程设计，它在Python中的到支持，在Python3.4-3.7以及以后的版本中快速发展。你可能会对“并发，并行，线程，多进程”感到迷惑，需要掌握太多知识，异步IO属于哪个？\n　这个教程可以帮助你解答这个问题，并帮助你掌握Python中异步IO的用法。\n　你将学到：\n 异步IO：与语言无关的范式（模型），具有跨多种编程语言的实现 async/await：两种新的Python关键字，用于定义协程（coroutines） asyncio：提供运行和管理协程的基础和API的Python包  　协程**（特殊的生成器函数**）是异步IO的核心，我们稍后会深入探讨它们。\n　注意：在这篇文章中，我使用术语async IO表示异步IO的语言无关设计，而asyncio指的是Python包。\n　在开始之前，你应该确认你已经安装了asyncio和这篇教程中的其它库。\n安装环境 　你需要Python3.7或更高版本、aiohttp包和aiofiles包才能完整地完成教程。\n1 2 3  $python3.7 -m venv ./py37async $source ./py37async/bin/activate # Windows: .\\py37async\\Scripts\\activate.bat $pip install --upgrade pip aiohttp aiofiles # Optional: aiodns   　安装Python3.7和虚拟环境，访问：https://realpython.com/installing-python/或https://realpython.com/python-virtual-environments-a-primer/\n　下面就让我们开始吧。\n10000英尺的异步IO视图 　异步IO没有它的兄弟多进程和线程知名。本节将为您提供更全面的了解异步IO是什么以及它如何适应周围的环境。\n异步IO适用于什么场景？ 　并发和并行是不容易涉足的扩展主题。但这篇文章专注于异步IO及其在Python中的实现，值得花一点时间将异步IO与相似的概念进行比较，以了解异步IO如何适应更大、有时令人困惑的难题。\n　并行（Parallelism）由同时执行的多个操作组成。多进程（Multiprocessing）是一种实现并行的方法，并且它需要把任务分散到CPU的中央处理单元上（CPU或核）。多进程适合CPU密集任务：紧绑定循环和数学计算通常属于此类。\n　并发（Concurrency）是比并行边界更松弛的术语。它表明多个任务可以以重叠的方式运行。（有一种说法是并发不一定是并行）\n　线程（Threading）是并发执行的模型，多个线程轮流执行任务。一个进程可以包含多个线程。Python由于它的全局锁（GIL）具有复杂的线程关系，但是那超过了这篇文章的范围。\n　关于线程需要了解的是它更适合IO密集型任务。CPU密集型任务的特征是计算机内核从头到尾不断地努力工作，而IO密集型工作主要由大量等待输入/输出来完成。\n　回顾上面描述的，并发包含多进程（CPU密集型任务）和多线程（IO密集型任务）。多进程是并行的一种形式，并行是并发的特殊类型（子集）。Python标准库通过它的multiprocessing，threading和concurrent.futures包为他们提供了长久的支持。\n　现在是时候带来一个新成员了。在过去的几年中，单独的设计已更全面地内置到CPython中：异步IO，通过标准库的asyncio包和新的async和await语言关键字启动。进一步说，异步IO不是新提出的概念，它已经存在并构建到了其它语言和运行时环境中，比如Go，C#，或Scala。\n　asyncio包被Python文档记为用于编写并发代码的库。然而，异步IO不是多线程也不是多进程。它不属于上述的任何一个。\n　事实上，异步IO是单线程，单进程设计：它使用多任务协作模式，你会在文章结尾时完全了解这个术语。换句话来说异步IO尽管使用单进程中的单线程，仍然给人一种并发的感觉。协程（Coroutines，异步IO的核心功能）能够并发调度，但它们内部不是并发。\n　重申一次，异步IO是并发编程的一种风格，但它不是并行。与多进程相比，它与线程处理的关系更紧密，但两者截然不同，并且是并发技巧中的独立成员。\n还剩下一个术语。异步是什么意思？这不是一个严格的定义，但在我们的语境中，我认为它有两种属性：\n 异步例程能够在等待他们最终结果的时候“暂停”，并且同时让其他例程运行。 通过以上机制，异步代码有助于并发执行。换句话说，异步代码给出了并发的视觉效果。  　下面是一张把他们放在一起的图。白色的术语代表概念，绿色的术语代表他们的实现方式：\n图1 并行\u0026amp;并发:\r\r 　我将在这里停止并发编程模型之间的比较，这篇教程专注于它的子成分——异步IO的子组件，如何使用异步IO，和围绕它兴起的API。要全面了解线程，多处理和异步IO，请在此处暂停并查看Jim Anderson的Python并发概述。Jim比我有趣得多，也比我参加了更多的会议。\n异步IO解释 　异步IO似乎是违反直觉且矛盾的。如何使用单线程和单核实现并发代码？我从来都不擅长编造例子，所以我从Miguel Grinberg 2017年PyCon的演讲中取一个例子，他将所有的事情都解释得很漂亮。\n 国际象棋大师朱迪特·波尔加（Judit Polgár）举办国际象棋展览，她在展览中与多个业余玩家对战。她有两种进行展览得方式：同步和异步。\n假设条件：\n 24位对手 Judit每次在5秒内落子 对手每次在55秒内落子 每局游戏平局30对落子（一方移动棋子30次）  同步版本：Judit一次只玩一局，绝不同时进行两局，直至游戏完成。每局游戏花费(55 + 5) * 30 = 1800 秒，即30分钟。整个展览需要花费24 * 30 = 720 分钟，即12小时。\n异步版本：每张桌子代表一局游戏，Judit在每张桌子上落子一次，然后从一张桌子移动到另一张。她离开桌子并让对手在等待的时间进行下一次落子。在全部24局游戏中落子1次花费Judit 24 * 5 = 120 秒，或2分钟。总共的展览时间现在被缩减到12 * 30 = 3600秒，即一小时。\n来源：https://youtu.be/iG6fr81xHKA?t=4m29s\n 　上述例子中Judit只有一位，她只有两只手，并且同一时刻只能在一局游戏上落子一次。但是异步对局将展览时间从12小时缩短至了1小时。所以，协作式多任务是一种优雅的方式，即程序的事件循环（稍后将详细描述）和多任务进行通信，让每个任务可以在最优时间轮流运行。\n　异步IO需要较长的等待时间，在该时间内函数将被阻塞，并允许其他功能在停机期间运行。（有效阻塞的函数从开始到返回为止一直禁止其他人运行）\n异步IO并不简单 　我听说，“当你有选择的时候使用异步IO；当你必须使用的时候选择线程。”事实就是构建耐用的多线程代码是困难且易出错的。异步IO避免了一些在线程设计中会遇到的潜在的速度颠簸。\n　但这并不是说Python中的异步IO很简单。请注意：当你试图进入接口层以下时，异步编程也会很困难！Python的异步模型构建在回调（callbacks），事件（events），传输（transports），协议（protocols）和期货（futures）的基础上（仅仅是术语就令人困惑），实际上由于它持续变化的API让它更不简单。\n　幸运的是，asyncio已经到了一个成熟的地步，它的大多数功能都不再是临时的，而它的文档进行了大幅度的修改，一些关于它的优质资源也开始出现。\nasyncio包和async/await 　现在你已经对异步IO的背景有了一定的了解，让我们探索一下Python的实现。Python的asyncio包（在Python 3.4中介绍）并且它有两个关键词，async和await，具有不同的功能，但它们一起帮你声明、构建、执行并管理异步代码。\nasync/await语法和原生协程 　告诫：请您注意在互联网上阅读的内容。Python的异步IO API从Python 3.4到 Python3.7迅速变化。一些老的模式不再使用，并且在新的文档中旧的一些将被禁止。据我所知，这篇教程很快也成为过时大军的一员。\n　异步IO的核心是协程。协程是Python生成器函数的特殊版本。让我们从基础定义开始，然后在它的基础上构建一个程序：协程是一个函数，它能够在到达return之前暂停它的执行，并且它可以在一段时间内将控制权间接传递给其它协程。\n　稍后，你会更深入地了解到传统生成器是怎么重新定义为协程的。但现在，最简单的了解协程工作方式的方法就是创建一些协程。\n　让我们用沉浸式方法并编写一些异步IO代码。这个程序相当于异步IO的Hello World，但距离说明它的核心功能还有很长的路要走：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  #!/usr/bin/env python3 # countasync.py import asyncio async def count(): print(\u0026#34;One\u0026#34;) await asyncio.sleep(1) print(\u0026#34;Two\u0026#34;) async def main(): await asyncio.gather(count(), count(), count()) if __name__ == \u0026#34;__main__\u0026#34;: import time s = time.perf_counter() asyncio.run(main()) elapsed = time.perf_counter() - s print(f\u0026#34;{__file__} executed in {elapsed:0.2f} seconds.\u0026#34;)   　当你执行这个文件，注意和你用def和time.sleep()定义的函数有哪些不同：\n1 2 3 4 5 6 7 8  $ python3.7 countasync.py One One One Two Two Two countasync.py executed in 1.01 seconds.   　输出的顺序就是异步IO的核心。与count()的每个调用进行交流的是一个事件循环或协调器。当每个任务到达await asyncio.sleep(1)，函数会大喊通知事件循环并归还控制权给它，并说“我将睡眠1秒，请让其它有意义的事情在这个时间段执行。”\n　将它和同步版本比较：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  #!/usr/bin/env python3 # countsync.py import time def count(): print(\u0026#34;One\u0026#34;) time.sleep(1) print(\u0026#34;Two\u0026#34;) def main(): for _ in range(3): count() if __name__ == \u0026#34;__main__\u0026#34;: s = time.perf_counter() main() elapsed = time.perf_counter() - s print(f\u0026#34;{__file__} executed in {elapsed:0.2f} seconds.\u0026#34;)   　当执行时，在执行顺序和时间上有轻微但关键的不同：\n1 2 3 4 5 6 7 8  $ python3.7 countsync.py One Two One Two One Two countsync.py executed in 3.01 seconds.　  　虽然使用time.sleep()和asyncio.sleep()看似平庸，但它们可以用作涉及等待时间的所有耗时的过程的替身。（你可以进行等待的最平凡的事情就是调用sleep()，因为它什么都不做。）也就是说，time.sleep()可以代表任何耗时的阻塞函数调用，而asyncio.sleep()可以用来代表非阻塞调用（但是仍需要花费一些时间去完成）。\n　你在下一节将看到awaiting一些事情的好处，包括asyncio.sleep()，即周围的函数可以暂时地将控制权交给其他函数（这些函数已经就绪，能立即开始做某些事情）。相对地，time.sleep()或任何其它阻塞调用在Python中是和异步代码不兼容的，因为它会在睡眠期间停止执行过程中的任何事情。\n异步IO的规则 　在这一段中，会依次介绍async，await，和协程函数的正式定义。这一节有一点枯燥，但对于掌握async/await是有帮助的，所以如果需要的话请回顾这一节：\n async def的语法介绍了原生协程（native coroutine）或者叫异步生成器（asynchronous generator）。表达式async with和async for也是合法的，稍后你将看到它们。 关键字await将函数控制权交还给事件循环（它暂停当前协程的执行状态）。如果Python在g()范围内遇到了一个await f()表达式，await就会这样告诉事件循环，“停止g()的执行，直到我等到了f()的执行结果，即f()返回。在等待期间，请让其他的事情运行。”  　第二点用代码大概像下面这样表示：\n1 2 3 4  async def g(): # Pause here and come back to g() when f() is ready r = await f() return r   　关于何时、如何、以及不能使用async/await有一套严格的规则，无论你在学习语法或已经有使用async/await的经验，这些都非常有用。\n 你用async def定义的函数就是一个协程。它可能会使用await，return，或是yield，这些都是可选的。声明async def noop():pass也是有效的：  使用await和/或return创建一个协程函数。为调用协程函数，你必须使用await来获得需要等待的结果。 比较少见的是在async def函数体中使用yield（只有最近才在Python中合法）。这创建了一个异步生成器，你会使用async for迭代它。暂时忘记异步生成器，并专注于获取协程函数的语法，使用await和/或return。   就像在def函数外使用yield是一个SyntaxError一样，在async def协程外使用await也是一个SyntaxError。你只能在协程内部使用await。  　下面是一些总结上面几条规则的简洁示例。\n1 2 3 4 5 6 7 8 9 10 11 12 13  async def f(x): y = await z(x) # OK - `await` and `return` allowed in coroutines return y async def g(x): yield x # OK - this is an async generator async def m(x): yield from gen(x) # No - SyntaxError def m(x): y = await z(x) # Still no - SyntaxError (no `async def` here) return y   　最后，当你使用await f()时，它需要f()是一个可等待的对象。听起来好像并不是十分有用。你仅需要知道一个可等待对象是（1）另一个协程，或（2）一个定义了.__await__()方法的对象，该方法返回一个迭代器。如果你编写了一个程序，对于大多数目的来说，你应该只需要考虑case#1。\n　这带给我们另一个你需要理解的技术上的区别：以前标识一个协程的方法是使用装饰器，即在标准def函数定义前用@asyncio.coroutine装饰。这个定义结果是基于生成器的协程（generator-based coroutine）。在Python3.5中提出async/await以后，这种用法已经过时了。\n　这两种协程基本上是等效的（都是可等待的），但是第一个是基于生成器的，第二个是原生协程（native coroutine）。\n1 2 3 4 5 6 7 8 9 10  import asyncio @asyncio.coroutine def py34_coro(): \u0026#34;\u0026#34;\u0026#34;Generator-based coroutine, older syntax\u0026#34;\u0026#34;\u0026#34; yield from stuff() async def py35_coro(): \u0026#34;\u0026#34;\u0026#34;Native coroutine, modern syntax\u0026#34;\u0026#34;\u0026#34; await stuff()   　如果你自己正在写任何代码，最好使用原生协程，因为显式比隐式更好。基于生成器的协程将在Python3.10中被移除。\n　在本篇教程的后半部分，我们会使用基于生成器的协程，仅仅是用于解释。引入async/await的原因是为了使协程称为Python的独立功能，从而很容易地将它和普通的生成器函数区分开，从而减少了歧义。\n　不要在基于生成器的协程上越陷越深，他已经被async/await淘汰了。它们有它们自己的一组小规则（例如，await不能被使用在基于协程的生成器中），如果您坚持使用async/await语法，很大程度上是和它们无关的。\n　事不宜迟，让我们举更多的例子。\n　这有一个异步IO是怎样缩减等待时间的例子：给定一个协程makerandom()，它持续生产范围为（0，10）的随机数，直到其中一个超过阈值为止，你要让此协程的多个调用不需要彼此等待依次完成。你可以大部分遵循上述两种脚本模式，并进行一些更改：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  #!/usr/bin/env python3 # rand.py import asyncio import random # ANSI colors c = ( \u0026#34;\\033[0m\u0026#34;, # End of color \u0026#34;\\033[36m\u0026#34;, # Cyan \u0026#34;\\033[91m\u0026#34;, # Red \u0026#34;\\033[35m\u0026#34;, # Magenta ) async def makerandom(idx: int, threshold: int = 6) -\u0026gt; int: print(c[idx + 1] + f\u0026#34;Initiated makerandom({idx}).\u0026#34;) i = random.randint(0, 10) while i \u0026lt;= threshold: print(c[idx + 1] + f\u0026#34;makerandom({idx}) == {i} too low; retrying.\u0026#34;) await asyncio.sleep(idx + 1) i = random.randint(0, 10) print(c[idx + 1] + f\u0026#34;---\u0026gt; Finished: makerandom({idx}) == {i}\u0026#34; + c[0]) return i async def main(): #*args,将参数打包为一个元组 res = await asyncio.gather(*(makerandom(i, 10 - i - 1) for i in range(3))) return res if __name__ == \u0026#34;__main__\u0026#34;: random.seed(444) r1, r2, r3 = asyncio.run(main()) print() print(f\u0026#34;r1: {r1}, r2: {r2}, r3: {r3}\u0026#34;)   　彩色输出的内容比我说的要多得多，使你对如何执行此脚本有一定的了解。\n图2 rand.py运行结果:\r\r 　程序使用一个主协程，makerandom()，并以三种不同的输入同时运行它。大多数程序会包含小型模块化协程和一个包装函数，该包装函数能够把每个小协程链在一起。main()通过把中心协程映射到一些迭代器或池中来收集任务（futures）。\n　在这个微型示例中，池是range(3)。稍后我们会展示一个更完整的示例，它需要并发处理请求、解析一组URL，并且main()为每个URL封装了整个例程。\n　尽管“生产随机数（主要受限于CPU）”使用asyncio不是一个最佳选择，该示例中存在asyncio.sleep()的目的是模仿一个IO受限进程，其中涉及不确定的等待时间。例如，asyncio.sleep()调用可能代表消息应用中发送和接收两个客户端之间的非随机整数。\n异步IO设计模式 　异步IO有它自己的一组脚本设计，将在这一节为你介绍。\n链式协程 　协程的关键功能是它们能够被链接在一起。（记住，协程对象是可等待的，所以另一个协程可以await它。）这让你能够将程序分割成更小的、可管理的、易于回收的协程：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  #!/usr/bin/env python3 # chained.py import asyncio import random import time \u0026#39;\u0026#39;\u0026#39; n:int，n是传入参数，int是注释，注释参数n应该是一个整型，但传入的n不是整型也不会报错， -\u0026gt;str，是返回值的注释，表示返回值是字符串 \u0026#39;\u0026#39;\u0026#39; async def part1(n: int) -\u0026gt; str: i = random.randint(0, 10) #以f开头表示在字符串内支持大括号内的python表达式 print(f\u0026#34;part1({n}) sleeping for {i} seconds.\u0026#34;) await asyncio.sleep(i) result = f\u0026#34;result{n}-1\u0026#34; print(f\u0026#34;Returning part1({n}) == {result}.\u0026#34;) return result async def part2(n: int, arg: str) -\u0026gt; str: i = random.randint(0, 10) print(f\u0026#34;part2{n, arg} sleeping for {i} seconds.\u0026#34;) await asyncio.sleep(i) result = f\u0026#34;result{n}-2 derived from {arg}\u0026#34; print(f\u0026#34;Returning part2{n, arg} == {result}.\u0026#34;) return result async def chain(n: int) -\u0026gt; None: start = time.perf_counter() p1 = await part1(n) p2 = await part2(n, p1) end = time.perf_counter() - start print(f\u0026#34;--\u0026gt;Chained result{n} =\u0026gt; {p2} (took {end:0.2f} seconds).\u0026#34;) async def main(*args): await asyncio.gather(*(chain(n) for n in args)) if __name__ == \u0026#34;__main__\u0026#34;: import sys random.seed(444) args = [1, 2, 3] if len(sys.argv) == 1 else map(int, sys.argv[1:]) start = time.perf_counter() asyncio.run(main(*args)) end = time.perf_counter() - start print(f\u0026#34;Program finished in {end:0.2f} seconds.\u0026#34;)   　注意输出，part1()睡眠可变时间，并且part2()开始处理可用的结果。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  $ python3.7 chained.py 9 6 3 part1(9) sleeping for 4 seconds. part1(6) sleeping for 4 seconds. part1(3) sleeping for 0 seconds. Returning part1(3) == result3-1. part2(3, \u0026#39;result3-1\u0026#39;) sleeping for 4 seconds. Returning part1(9) == result9-1. part2(9, \u0026#39;result9-1\u0026#39;) sleeping for 7 seconds. Returning part1(6) == result6-1. part2(6, \u0026#39;result6-1\u0026#39;) sleeping for 4 seconds. Returning part2(3, \u0026#39;result3-1\u0026#39;) == result3-2 derived from result3-1. --\u0026gt;Chained result3 =\u0026gt; result3-2 derived from result3-1 (took 4.00 seconds). Returning part2(6, \u0026#39;result6-1\u0026#39;) == result6-2 derived from result6-1. --\u0026gt;Chained result6 =\u0026gt; result6-2 derived from result6-1 (took 8.01 seconds). Returning part2(9, \u0026#39;result9-1\u0026#39;) == result9-2 derived from result9-1. --\u0026gt;Chained result9 =\u0026gt; result9-2 derived from result9-1 (took 11.01 seconds). Program finished in 11.01 seconds.   　在这个设置中，main()的运行时间和它收集在一起并调度的运行时间最长的任务相同。\n使用队列 　asyncio包提供队列类，该类的涉及和queue模块中的类很相似。在我们目前的例子里，我们实际上并不需要队列结构。在chained.py中，每个任务（future）都有一组协程组成，每个协程都在彼此等待，并且每条链传递一个单独的输入。\n　有一个能够和异步IO共同工作的可选结构：有一定数量的生产者（它们彼此之间没有联系），向一个队列里添加事项。每个生产者在交错、随机、未通知的时间里可能向队列里添加多个事项。一组消费者在它们出现时贪婪地从队列中拉取事项，无需等待任何信号。\n　在这个设计中，没有任何单个消费者和生产者之间的链。消费者不知道生产者的数量，甚至也不会提前知道添加到队列中的事项的累积数量。\n　每个生产者或消费者花费可变的时间分别从队列中放入和提取事项。队列作为吞吐量，可以让生产者和消费者之间通信而无需他们彼此之间直接交流。\n\r\r尽管由于queue.Queue()的线程安全性，队列通常在线程程序中使用，但当涉及异步IO时，你不需要担心线程安全。（除了你试图结合这两者时，但在此篇教程中并未实现。）\n\r \r　一种队列的使用情形（如此处的情况）是队列作为生产者和消费者之间的传输者（transmitter），而不是将他们彼此相联系或直接链接起来。\n　这个程序的同步版本看起来相当惨淡：一组阻塞生产者串行将事项添加到队列，一次运行一个生产者。只有所有的生产者都完成生产，一次才能有一个消费者逐项处理队列。这个设计中有过多的延迟。事项可能闲置地放置在队列中，耳不是立即拿起并处理。\n　一个异步版本，asyncq.py，写在下面。这项工作的挑战部分是需要给消费者一个生产者已经完成生产的信号。否则await q.get()会无限期的挂起，因为队列已经被充分处理，但是消费者完全不知道生产已经完成。\n　（特别感谢来自StackOverflow用户在理清main()上的帮助：关键是await q.join()，直到队列中的所有事项都被接收和处理之前都会阻塞，然后取消消费者任务，否则它会挂起并无限等待额外的队列事项出现。）\n　下面是完整的脚本：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56  #!/usr/bin/env python3 # asyncq.py import asyncio import itertools as it import os import random import time async def makeitem(size: int = 5) -\u0026gt; str: return os.urandom(size).hex() async def randsleep(a: int = 1, b: int = 5, caller=None) -\u0026gt; None: i = random.randint(0, 10) if caller: print(f\u0026#34;{caller} sleeping for {i} seconds.\u0026#34;) await asyncio.sleep(i) async def produce(name: int, q: asyncio.Queue) -\u0026gt; None: n = random.randint(0, 10) for _ in it.repeat(None, n): # Synchronous loop for each single producer await randsleep(caller=f\u0026#34;Producer {name}\u0026#34;) i = await makeitem() t = time.perf_counter() await q.put((i, t)) print(f\u0026#34;Producer {name} added \u0026lt;{i}\u0026gt; to queue.\u0026#34;) async def consume(name: int, q: asyncio.Queue) -\u0026gt; None: while True: await randsleep(caller=f\u0026#34;Consumer {name}\u0026#34;) i, t = await q.get() now = time.perf_counter() print(f\u0026#34;Consumer {name} got element \u0026lt;{i}\u0026gt;\u0026#34; f\u0026#34; in {now-t:0.5f} seconds.\u0026#34;) q.task_done() async def main(nprod: int, ncon: int): q = asyncio.Queue() producers = [asyncio.create_task(produce(n, q)) for n in range(nprod)] consumers = [asyncio.create_task(consume(n, q)) for n in range(ncon)] await asyncio.gather(*producers) await q.join() # Implicitly awaits consumers, too for c in consumers: c.cancel() if __name__ == \u0026#34;__main__\u0026#34;: import argparse random.seed(444) parser = argparse.ArgumentParser() parser.add_argument(\u0026#34;-p\u0026#34;, \u0026#34;--nprod\u0026#34;, type=int, default=5) parser.add_argument(\u0026#34;-c\u0026#34;, \u0026#34;--ncon\u0026#34;, type=int, default=10) ns = parser.parse_args() start = time.perf_counter() asyncio.run(main(**ns.__dict__)) elapsed = time.perf_counter() - start print(f\u0026#34;Program completed in {elapsed:0.5f} seconds.\u0026#34;)   　前几个协程是辅助函数，返回一个随机字符串，一个分秒性能计数器和一个随机整数。生产者向队列中从1放到5个事项。每个事项是(i,t)元组，i是随机字符串，t是生产者试图将元组放入队列的时间。\n　当消费者拉取一个事项时，它仅使用事项放入队列时的时间戳计算事项放入队列中存在的时间。\n　记住asyncio.sleep()用来模仿其它更复杂的协程，如果这是常规的阻塞函数，会消耗时间并阻塞其他所有的执行。\n　这是用两个生产者和五个消费者的测试结果：（我实际运行的时候发现没有Producer 1，太奇怪了，有生产者1，生产者2，生产者3，就是没有1）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  $ python3.7 asyncq.py -p 2 -c 5 Producer 0 sleeping for 3 seconds. Producer 1 sleeping for 3 seconds. Consumer 0 sleeping for 4 seconds. Consumer 1 sleeping for 3 seconds. Consumer 2 sleeping for 3 seconds. Consumer 3 sleeping for 5 seconds. Consumer 4 sleeping for 4 seconds. Producer 0 added \u0026lt;377b1e8f82\u0026gt; to queue. Producer 0 sleeping for 5 seconds. Producer 1 added \u0026lt;413b8802f8\u0026gt; to queue. Consumer 1 got element \u0026lt;377b1e8f82\u0026gt; in 0.00013 seconds. Consumer 1 sleeping for 3 seconds. Consumer 2 got element \u0026lt;413b8802f8\u0026gt; in 0.00009 seconds. Consumer 2 sleeping for 4 seconds. Producer 0 added \u0026lt;06c055b3ab\u0026gt; to queue. Producer 0 sleeping for 1 seconds. Consumer 0 got element \u0026lt;06c055b3ab\u0026gt; in 0.00021 seconds. Consumer 0 sleeping for 4 seconds. Producer 0 added \u0026lt;17a8613276\u0026gt; to queue. Consumer 4 got element \u0026lt;17a8613276\u0026gt; in 0.00022 seconds. Consumer 4 sleeping for 5 seconds. Program completed in 9.00954 seconds.   　在这种情况下，事项在几秒钟就被处理完毕。延迟可能有两点原因：\n 标准的、很大程度上不可避免的开销 当队列中出现一项时，所有消费者都在睡眠的情况  　关于第二个理由，幸运的是，扩展到成百上千个消费者是完全正常的。在执行python3.7 asyncq.py -p 5 -c 100时应该不会出现问题。这里需要注意的是，理论上，你在不同的系统上会有不同的用户控制消费者和生产者的管理，队列作为中央吞吐量。\n　到目前为止，你已经陷入困境，并看到了三个相关的asyncio调用async和await协程的示例。如果你没有完全跟上或者仅仅想加深一下Python中现代协程机制的了解，你可以从下一章重新开始。\n异步IO在生成器中的根 　先前你已经看到了旧风格的基于生成器的协程，已经被更显式的原生协程淘汰。该示例值得稍作调整重新展示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  import asyncio @asyncio.coroutine def py34_coro(): \u0026#34;\u0026#34;\u0026#34;Generator-based coroutine\u0026#34;\u0026#34;\u0026#34; # No need to build these yourself, but be aware of what they are s = yield from stuff() return s async def py35_coro(): \u0026#34;\u0026#34;\u0026#34;Native coroutine, modern syntax\u0026#34;\u0026#34;\u0026#34; s = await stuff() return s async def stuff(): return 0x10, 0x20, 0x30   　作为实验，没有await，或没有任何对asyncio.run()的调用，或其他asyncio有关的函数的情况下，单独调用py34_coro()或py35_coro()会发生什么？独立调用一个协程会返回一个协程对象：\n1 2  \u0026gt;\u0026gt;\u0026gt; py35_coro() \u0026lt;coroutine object py35_coro at 0x10126dcc8\u0026gt;   　表面上这不是十分有趣，调用一个协程的结果是一个可等待的协程对象（coroutine object）。\n　提问时间：Python的其他功能是什么样子？（单独调用Python的哪个功能实际上并没有做什么？）\n　这个问题的其中一个答案是生成器（generator），因为协程是引擎强化版的生成器。在这方面它的行为是相似的：\n1 2 3 4 5 6 7 8  \u0026gt;\u0026gt;\u0026gt; def gen(): ... yield 0x10, 0x20, 0x30 ... \u0026gt;\u0026gt;\u0026gt; g = gen() \u0026gt;\u0026gt;\u0026gt; g # Nothing much happens - need to iterate with `.__next__()` \u0026lt;generator object gen at 0x1012705e8\u0026gt; \u0026gt;\u0026gt;\u0026gt; next(g) (16, 32, 48)   　生成器函数，正如它发生的那样，是异步IO的基础（不管你是否使用async def声明协程还是使用旧版本的@asyncio.coroutine装饰器）。技术上，await和yield from比yield更相似。（但是请记住，yield from x()仅是在替代for i in x():yield i 的语法糖。）\n　和异步IO有关的生成器的一个关键特点是它能够有效地按意愿停止和重启。例如，你可以break正在迭代的生成器对象，然后稍后恢复对剩余值得迭代。当生成器函数到达yield，它会生成该值，随后处于空闲状态，直至被告知要生成后续值。\n　可以通过一个示例具体说明：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  \u0026gt;\u0026gt;\u0026gt; from itertools import cycle \u0026gt;\u0026gt;\u0026gt; def endless(): ... \u0026#34;\u0026#34;\u0026#34;Yields 9, 8, 7, 6, 9, 8, 7, 6, ... forever\u0026#34;\u0026#34;\u0026#34; ... yield from cycle((9, 8, 7, 6)) \u0026gt;\u0026gt;\u0026gt; e = endless() \u0026gt;\u0026gt;\u0026gt; total = 0 \u0026gt;\u0026gt;\u0026gt; for i in e: ... if total \u0026lt; 30: ... print(i, end=\u0026#34; \u0026#34;) ... total += i ... else: ... print() ... # Pause execution. We can resume later. ... break 9 8 7 6 9 8 7 6 9 8 7 6 9 8 \u0026gt;\u0026gt;\u0026gt; # Resume \u0026gt;\u0026gt;\u0026gt; next(e), next(e), next(e) (6, 9, 8)   　await关键字表现相似，标记一个断点，协程会暂停然后让其它协程工作。“暂停”，在这种情况下是说协程暂时交出了控制权，但没有完全退出或完成。请记住yield，和它的扩展yield from和await，相当于在生成器执行时标记断点。\n　这是函数和生成器之间的基本不同。函数是全做或不做。一旦它启动，它在遇到return之前不会停止，然后将值返回给调用者（调用它的函数）。生成器，在每次遇到yield的时候暂停，不再继续运行。它不仅可以将值压入调用栈，还能通过调用next()恢复它时保留它的局部变量。\n　还有第二个鲜为人知但同样重要的生成器特点。你可以通过.send()方法发送一个值到生成器。这允许生成器（和协程）调用（await）彼此而无需阻塞。我不会更深的介绍这一点，因为它主要和协程本身的实现有关，但是你自己不需要直接使用它。\n　如果你想要了解更多，可以从PEP 342开始，是协程的正式介绍。Brett Cannon的How the Heck Does Async-Await in Python和PYMOTW writeup on asyncio也是不错的读物。最后，还有David Beazley的Curious Course on Coroutines and Concurrency，深入介绍了协程运行。\n　让我们试着把上述文章总结为几句话：这些协程实际上是通过一种特别非常规的机制运行的。他们的结果是异常对象的属性，该异常对象在调用其.send()方法时被抛出。所有这些还有更多细节，但是它可能对你实际使用语言没有帮助，让我们继续吧。\n　将所有事情总结一下，以下是协程作为生成器的一些关键点：\n 协程是改装的生成器（repurposed generators），具有生成器方法的优点。 旧的基于生成器的协程使用yield from等待协程结果。现代Python语法的原生协程用await替换掉yield from来等待协程结果。await和yield from相似，通常可以看作等价。 await的使用是标记断点的信号。它让协程暂时停止执行，并且允许程序稍后回来继续执行。  其他功能：async for和异步生成器、推导式（Comprehension） 　除了普通的async/await，Python还允许使用async for对**异步迭代器（asynchronous iterator）**进行迭代。异步迭代器的目的是能够在迭代时在每个阶段调用异步代码。\n　这个概念的自然扩展是异步生成器（asynchronous generator）。回顾在原生协程中你可以使用await，return或yield。从Python3.6（PEP 525）起，可以在协程内使用yield，他引入了异步生成器，目的是允许在同一个协程函数体中使用await和yield。\n1 2 3 4 5 6 7  \u0026gt;\u0026gt;\u0026gt; async def mygen(u: int = 10): ... \u0026#34;\u0026#34;\u0026#34;Yield powers of 2.\u0026#34;\u0026#34;\u0026#34; ... i = 0 ... while i \u0026lt; u: ... yield 2 ** i ... i += 1 ... await asyncio.sleep(0.1)   　最后但同样重要的是，Python用async for启用异步推导式（asynchronous comprehension）。像它的同步兄弟，这主要是语法糖：\n1 2 3 4 5 6 7 8 9 10 11 12  \u0026gt;\u0026gt;\u0026gt; async def main(): ... # This does *not* introduce concurrent execution ... # It is meant to show syntax only ... g = [i async for i in mygen()] ... f = [j async for j in mygen() if not (j // 3 % 5)] ... return g, f ... \u0026gt;\u0026gt;\u0026gt; g, f = asyncio.run(main()) \u0026gt;\u0026gt;\u0026gt; g [1, 2, 4, 8, 16, 32, 64, 128, 256, 512] \u0026gt;\u0026gt;\u0026gt; f [1, 2, 16, 32, 256, 512]   　这里有一个关键的区别：异步生成器和异步理解都不会使迭代并发。它们只提供和它们同步写法相对应的感觉，但是具有使相关循环放弃对事件循环的控制权以便使其他协程运行的能力。\n　换句话说，异步迭代器和异步生成器并非旨在序列或迭代器上并发映射某些函数。它们仅仅是让封闭的协程允许其他任务轮流运行。仅在使用普通的for和with会“破坏”写成中的await性质的情况下，才需要async for和async with。异步和并发的区别是要把握的关键。\n\r Comprehension：这里取Python文档中简体中文版的翻译，即翻译为”推导式“，其它地方也译为列表生成式等。  \r \r事件循环（Event loop）和asyncio.run() 　你可以认为事件循环就像while True循环一样，它监视协程，反馈空闲状态信息，寻找在此时可以执行的地十五。当协程正在等待的东西可用时，它能够唤醒该空闲协程。\n　因此，事件循环的整个管理已经隐式地通过一个函数调用处理：\n1  asyncio.run(main()) # Python 3.7+   　asyncio.run()，在Python3.7引入，负责获取事件循环，在标记完成前一直运行任务，然后关闭事件循环。\n　使用get_event_loop()可以更广泛地管理asyncio事件循环，典型的模式看起来像这样：\n1 2 3 4 5  loop = asyncio.get_event_loop() try: loop.run_until_complete(main()) finally: loop.close()   　你可能在一些旧的示例中看到loop.get_event_loop()，但是除非你特别需要微调对事件循环管理的控制，否则asyncio.run()对大多数程序来说应该足够了。\n　如果你需要在Python程序内部和事件循环交互，loop是一个老式的Python对象，它通过loop.is_running()和loop.is_closed()支持自省。\n　如果你需要更精细的控制，比如把循环作为参数进行调度回调，你可以操纵它们。\n　更关键的是要对事件循环的机制有一定了解。关于事件循环这里有几点值得强调。\n　**#1：**协同程序只有在与事件循环相关联的情况下，才能自行完成很多工作。\n　这点你在之前对生成器的解释中看到过，但值得重述一遍。如果你有一个await其它协程的主协程，仅仅独立地调用它是无效的：\n1 2 3 4 5 6 7 8 9 10  \u0026gt;\u0026gt;\u0026gt; import asyncio \u0026gt;\u0026gt;\u0026gt; async def main(): ... print(\u0026#34;Hello ...\u0026#34;) ... await asyncio.sleep(1) ... print(\u0026#34;World!\u0026#34;) \u0026gt;\u0026gt;\u0026gt; routine = main() \u0026gt;\u0026gt;\u0026gt; routine \u0026lt;coroutine object main at 0x1027a6150\u0026gt;   　记住使用asyncio.run()通过调度main()协程在事件循环上执行来强制执行。\n1 2 3  \u0026gt;\u0026gt;\u0026gt; asyncio.run(routine) Hello ... World!   　（其它协程可以通过await来执行。通常只将main()包装在asyncio.run()中，然后从那里调用带有await的链式协程。\n　**#2：**异步IO循环默认运行在单核单个线程上。通常，在一个CPU核上运行一个单线程事件循环绰绰有余。它可能通过多个核运行事件循环。可以参考talk by John Reese了解更多，但你的笔记本电脑可能会自燃。\n　**#3：**事件循环是可插入的。也就是说，如果你真的想的话，你可以自己实现你自己的事件循环，并让它以相同方式运行任务。这在uvloop包中被充分地介绍，是CPython中的事件循环实现。\n　“可插入的事件循环”的意思是：你可以使用任何事件循环的工作实现，核协程他们本身的结构无关。asyncio包本身涉及两种不同的事件循环实现，默认情况下基于selectors模块。（第二种实现仅为Windows构建）\n完整的程序：异步请求 　到目前为止你已经看了大部分了，是时候进行有趣而无痛的工作了。在本节中，你会构建一个网页抓取网址收集器，areq.py，使用aiohttp，快速的异步HTTP客户端/服务器框架。（我们仅需要客户端部分）这这样的工具可用于映射站点集群之间的连接，链接形成有向图。\n\r\r你可能会好奇为什么Python的requests包和异步IO不兼容。requests在urllib3的上层构建，实际上使用的是Python的http包和socket模块。\n\r \r　默认情况下，套接字操作是阻塞的。这意味着Python不会await requests.get(url)，因为.get()不是可等待的。相对地，几乎所有的事情在aiohttp中都是可等待的协程，如session.request()和response.text()。它虽然是一个很棒的包，但是在异步代码中使用requests会对自己造成损害。\n　高级程序结构像这样：\n 从本地文件urls.txt读取URL序列。 发送对URL的GET请求并解析结果内容。如果失败，则在此处停止输入URL。 在URL响应的HTML中寻找href标签。 将结果写入foundurls.txt。 尽可能异步和同时执行上述所有操作。（使用aiohttp发送请求，和aiofiles追加文件。这两个是非常适合异步IO模型的IO主要示例）。  　这是urls.txt的内容，它并不大，但包含了大部分流量大的网站\n1 2 3 4 5 6 7 8 9  $ cat urls.txt https://regex101.com/ https://docs.python.org/3/this-url-will-404.html https://www.nytimes.com/guides/ https://www.mediamatters.org/ https://1.1.1.1/ https://www.politico.com/tipsheets/morning-money https://www.bloomberg.com/markets/economics https://www.ietf.org/rfc/rfc2616.txt   　列表中的第二个URL会返回一个404响应，你需要优雅地处理。如果你运行这个程序的扩展版本，你需要处理更棘手的问题，比如连不上服务器和无休止的重定向。\n　请求本身应该使用单个的会话发出，以充分利用会话内部的连接池。\n　让我们看一眼整个程序。我们一步一步地浏览：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108  #!/usr/bin/env python3 # areq.py \u0026#34;\u0026#34;\u0026#34;Asynchronously get links embedded in multiple pages\u0026#39; HMTL.\u0026#34;\u0026#34;\u0026#34; import asyncio import logging import re import sys from typing import IO import urllib.error import urllib.parse import aiofiles import aiohttp from aiohttp import ClientSession logging.basicConfig( format=\u0026#34;%(asctime)s%(levelname)s:%(name)s: %(message)s\u0026#34;, level=logging.DEBUG, datefmt=\u0026#34;%H:%M:%S\u0026#34;, stream=sys.stderr, ) logger = logging.getLogger(\u0026#34;areq\u0026#34;) logging.getLogger(\u0026#34;chardet.charsetprober\u0026#34;).disabled = True HREF_RE = re.compile(r\u0026#39;href=\u0026#34;(.*?)\u0026#34;\u0026#39;) async def fetch_html(url: str, session: ClientSession, **kwargs) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;GET request wrapper to fetch page HTML. kwargs are passed to `session.request()`. \u0026#34;\u0026#34;\u0026#34; resp = await session.request(method=\u0026#34;GET\u0026#34;, url=url, **kwargs) resp.raise_for_status() logger.info(\u0026#34;Got response [%s] for URL: %s\u0026#34;, resp.status, url) html = await resp.text() return html async def parse(url: str, session: ClientSession, **kwargs) -\u0026gt; set: \u0026#34;\u0026#34;\u0026#34;Find HREFs in the HTML of `url`.\u0026#34;\u0026#34;\u0026#34; found = set() try: html = await fetch_html(url=url, session=session, **kwargs) except ( aiohttp.ClientError, aiohttp.http_exceptions.HttpProcessingError, ) as e: logger.error( \u0026#34;aiohttp exception for %s[%s]: %s\u0026#34;, url, getattr(e, \u0026#34;status\u0026#34;, None), getattr(e, \u0026#34;message\u0026#34;, None), ) return found except Exception as e: logger.exception( \u0026#34;Non-aiohttp exception occured: %s\u0026#34;, getattr(e, \u0026#34;__dict__\u0026#34;, {}) ) return found else: for link in HREF_RE.findall(html): try: abslink = urllib.parse.urljoin(url, link) except (urllib.error.URLError, ValueError): logger.exception(\u0026#34;Error parsing URL: %s\u0026#34;, link) pass else: found.add(abslink) logger.info(\u0026#34;Found %dlinks for %s\u0026#34;, len(found), url) return found async def write_one(file: IO, url: str, **kwargs) -\u0026gt; None: \u0026#34;\u0026#34;\u0026#34;Write the found HREFs from `url` to `file`.\u0026#34;\u0026#34;\u0026#34; res = await parse(url=url, **kwargs) if not res: return None async with aiofiles.open(file, \u0026#34;a\u0026#34;) as f: for p in res: await f.write(f\u0026#34;{url}\\t{p}\\n\u0026#34;) logger.info(\u0026#34;Wrote results for source URL: %s\u0026#34;, url) async def bulk_crawl_and_write(file: IO, urls: set, **kwargs) -\u0026gt; None: \u0026#34;\u0026#34;\u0026#34;Crawl \u0026amp; write concurrently to `file` for multiple `urls`.\u0026#34;\u0026#34;\u0026#34; async with ClientSession() as session: tasks = [] for url in urls: tasks.append( write_one(file=file, url=url, session=session, **kwargs) ) await asyncio.gather(*tasks) if __name__ == \u0026#34;__main__\u0026#34;: import pathlib import sys assert sys.version_info \u0026gt;= (3, 7), \u0026#34;Script requires Python 3.7+.\u0026#34; here = pathlib.Path(__file__).parent with open(here.joinpath(\u0026#34;urls.txt\u0026#34;)) as infile: urls = set(map(str.strip, infile)) outpath = here.joinpath(\u0026#34;foundurls.txt\u0026#34;) with open(outpath, \u0026#34;w\u0026#34;) as outfile: outfile.write(\u0026#34;source_url\\tparsed_url\\n\u0026#34;) asyncio.run(bulk_crawl_and_write(file=outpath, urls=urls))   　这个脚本比我们的程序长多了，所以我们分解它。\n　常量HREF_RE是一个常规表达式，用来提取我们最终查找的HTML中的href标签：\n1 2  \u0026gt;\u0026gt;\u0026gt; HREF_RE.search(\u0026#39;Go to \u0026lt;a href=\u0026#34;https://realpython.com/\u0026#34;\u0026gt;Real Python\u0026lt;/a\u0026gt;\u0026#39;) \u0026lt;re.Match object; span=(15, 45), match=\u0026#39;href=\u0026#34;https://realpython.com/\u0026#34;\u0026#39;\u0026gt;   　协程fetch_html()是一个GET请求的装饰器，用来创建请求并对HTML页面解码。它创建请求，await响应，并用正确的方式处理非200的状态码。\n1 2  resp = await session.request(method=\u0026#34;GET\u0026#34;, url=url, **kwargs) resp.raise_for_status()   　如果状态是OK，fetch_html()返回HTML页面（一个字符串）。注意，这个函数中没有异常处理。逻辑是将该异常传播给调用方，并在那里进行处理。\n1  html = await resp.text()   　我们await session.request()和resp.text()是因为他们是可等待的协程。请求/响应循环是应用延迟高且耗时的部分，但是使用异步IO，fetch_html()让事件循环工作在其它就绪可用的工作上，比如解析和写入已经获取的URL。\n　协程链的下一步是parse()，在fetch_html()中等待给定的URL，然后提取那个HTML页面的所有href标签，保证每个都有效并且将它格式化为绝对路径。\n　诚然，parse()的第二部分是阻塞的，但是它由快速的正则表达式匹配组成，并确保发现的连接设置为绝对路径。\n　在这种具体情形下，同步代码需要是快速且不显眼的。但是请记住，给定协程中的任何行都会阻塞其它协程，除非该行使用yield，await或return。如果解析，你可能需要考虑使用loop.run_in_executor()在它自己的程序中运行这部分。\n　接下来，协程write()接收一个文件对象和一个URL，等待parse()返回一组解析的URL，通过aiofiles（异步文件IO包）根据源URL把每一个异步地写入文件。\n　最后，bulk_crawl_and_write()作为进入脚本协程链的主要入口点。它使用一个会话，并为每个从url.txt中读取的URL创建一个任务。\n　这里有额外的几点需要注意：\n 默认的ClientSession最大具有100个开放连接的适配器。需要更改此设置，请传递一个asyncio.connector.TCPConnector实例给ClientSession。你也可以基于每个主机指定限制。 你可以为整个会话和单个请求指定最大超时。 这个脚本也使用了await with，用作异步上下文管理器（asynchronous context manager）。我没有为此开设一节讲述这个概念，因为从同步上下文管理器到异步上下文管理器的转变比较直接。后者定义了.__aenter__()和.__aexit__()而不是.__exit__()和.__enter__()。和你想的一样，async with也只能用在声明为async def的协程函数内部。  　如果你想了解更多，Github上本教程的配套文件也附带了注释和文档。\n　这是全部执行过程，areq.py在1秒钟获取、解析并保存了9个URL的结果。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  $ python3.7 areq.py 21:33:22 DEBUG:asyncio: Using selector: KqueueSelector 21:33:22 INFO:areq: Got response [200] for URL: https://www.mediamatters.org/ 21:33:22 INFO:areq: Found 115 links for https://www.mediamatters.org/ 21:33:22 INFO:areq: Got response [200] for URL: https://www.nytimes.com/guides/ 21:33:22 INFO:areq: Got response [200] for URL: https://www.politico.com/tipsheets/morning-money 21:33:22 INFO:areq: Got response [200] for URL: https://www.ietf.org/rfc/rfc2616.txt 21:33:22 ERROR:areq: aiohttp exception for https://docs.python.org/3/this-url-will-404.html [404]: Not Found 21:33:22 INFO:areq: Found 120 links for https://www.nytimes.com/guides/ 21:33:22 INFO:areq: Found 143 links for https://www.politico.com/tipsheets/morning-money 21:33:22 INFO:areq: Wrote results for source URL: https://www.mediamatters.org/ 21:33:22 INFO:areq: Found 0 links for https://www.ietf.org/rfc/rfc2616.txt 21:33:22 INFO:areq: Got response [200] for URL: https://1.1.1.1/ 21:33:22 INFO:areq: Wrote results for source URL: https://www.nytimes.com/guides/ 21:33:22 INFO:areq: Wrote results for source URL: https://www.politico.com/tipsheets/morning-money 21:33:22 INFO:areq: Got response [200] for URL: https://www.bloomberg.com/markets/economics 21:33:22 INFO:areq: Found 3 links for https://www.bloomberg.com/markets/economics 21:33:22 INFO:areq: Wrote results for source URL: https://www.bloomberg.com/markets/economics 21:33:23 INFO:areq: Found 36 links for https://1.1.1.1/ 21:33:23 INFO:areq: Got response [200] for URL: https://regex101.com/ 21:33:23 INFO:areq: Found 23 links for https://regex101.com/ 21:33:23 INFO:areq: Wrote results for source URL: https://regex101.com/ 21:33:23 INFO:areq: Wrote results for source URL: https://1.1.1.1/   　这样不严谨，对于健全的检查，你可以检查输出行数，我是626，但这可能会有所波动：\n1 2 3 4 5 6 7  $ wc -l foundurls.txt 626 foundurls.txt $ head -n 3 foundurls.txt source_url parsed_url https://www.bloomberg.com/markets/economics https://www.bloomberg.com/feedback https://www.bloomberg.com/markets/economics https://www.bloomberg.com/notices/tos   　下一步：如果你想要提高底注，请使用这个网络爬虫递归。你可以使用aio-redis追踪哪个URL已经被抓取了，从而避免请求他们两次，并用Python的networkx库和链接相连。\n　记住要友好。发送1000个并发请求给一个小型、毫无防御的网站是非常糟糕的。有一些方法可以限制你一次发出的并发请求，例如使用asyncio的sempahore对象或使用和它相似的模板。如果你不注意此警告，可能会受到大量的TimeoutError异常，最终只会损害您自己的程序。\n异步IO的使用场景 　现在你已经了解了健康的代码，让我们退一步思考一下异步IO什么时候是一个理想的选择，以及你怎样做出比较得出结论或是否选择其他的并发模型。\n异步IO什么时候是一个正确的选择？为什么？ 　本教程并没有对异步IO、线程、多进程进行扩展论述。但是，了解异步IO何时是三者间的最佳选择很有用。\n　异步和多进程之间的斗争根本不存在。实际上，它们可以被正确地使用。如果你有多个公平统一的CPU受限任务，（一个很好的例子是库内网格查找（grid search），比如scikit-learn或keras）多进程是不错的选择。\n　如果所有的函数都是阻塞调用，而仅仅是将async放到每个函数前面是糟糕的想法。（实际上还可能会减速你的代码）但是像先前提到的那样，异步IO和多进程在很多地方可以和谐共存。\n　异步IO和线程之间的竞争更直接，我在引言中提到了“线程是困难的”。完整的说法是，即使某些情形下线程看起来很容易实现，由于竞争条件和内存使用等原因，它仍然可能导致那些臭名昭著、无法跟踪的错误。\n　和异步IO相比，线程扩展的趋势也不太好。因为线程是具有有限可用性的系统资源。创建几千个线程在大多数机器上都会失败，因此我不建议你首先进行尝试。创建数千异步IO任务完全可行。\n　在你有多个IO受限任务时异步IO闪闪发光，否则这些任务的时常会被阻塞的IO等待时间占据，例如：\n 网络IO，无论你的程序是服务端还是客户端。 无服务器设计，例如像聊天室多用户网络或P2P网络。 模仿“即写即忘”风格的读/写操作，而不担心读写时锁定的东西时。  　不使用异步IO的最大原因是await仅支持一组由特定方法定义的特定对象。如果你想要对DBMS进行异步读操作，你需要找到的不仅是DBMS的Python装饰器，还需要支持async/await的语法。包含同步调用的协程会阻止其它协程和任务的运行。\n　支持async/await的清单，可以在教程的尾部查看。\n应该选择异步IO的哪个包？ 　这篇教程专注于异步IO，async/await语法，使用asyncio进行事件循环管理和指定任务。asyncio并不是唯一的异步IO库。Nathaniel J. Smith发现了很多：\n 在未来的几年，asyncio可能会沦落为精明的开发人员避免使用的标准库之一，如urllib2。\n\u0026hellip;\n实际上，我要说的是asyncio是其自身成功的受害者：设计时，它使用了可能的最佳方法；但是从那时起，异步的启发下的工作（例如添加异步/等待）已经改变了现状，以便我们可以做得更好，现在异步已被其早期的承诺所束缚。（Source）\n 　尽管如此，可以替代asyncio的著名替代品是curio和trio，它们使用不同的API和方法。从个人来讲，我认为如果你要构建大小适中，简单明了的程序，仅使用asyncio就足够且能够理解了，并且让你避免添加Python标准库以外的大型依赖。\n　但是无论如何，检查curio和trio，你会发现它们以相同的方式完成了对用户而言更直观的操作。这里介绍的与包无关的概念也应该渗透到其它异步IO包中。\n其他零碎的内容 　在接下来的几节，你会了解到asyncio和async/await的其它各部分，这些部分目前不太匹配本教程，但对于构建和理解完整的程序很重要。\n其它顶级asyncio函数 　除了asyncio.run()以外，你会看到几个其它包级别的函数，比如asyncio.create_task()和asyncio.gather()。\n　你可以使用create_task()调度协程对象的执行，然后使用asyncio.run()：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  \u0026gt;\u0026gt;\u0026gt; import asyncio \u0026gt;\u0026gt;\u0026gt; async def coro(seq) -\u0026gt; list: ... \u0026#34;\u0026#34;\u0026#34;\u0026#39;IO\u0026#39; wait time is proportional to the max element.\u0026#34;\u0026#34;\u0026#34; ... await asyncio.sleep(max(seq)) ... return list(reversed(seq)) ... \u0026gt;\u0026gt;\u0026gt; async def main(): ... # This is a bit redundant in the case of one task ... # We could use `await coro([3, 2, 1])` on its own ... t = asyncio.create_task(coro([3, 2, 1])) # Python 3.7+ ... await t ... print(f\u0026#39;t: type {type(t)}\u0026#39;) ... print(f\u0026#39;t done: {t.done()}\u0026#39;) ... \u0026gt;\u0026gt;\u0026gt; t = asyncio.run(main()) t: type \u0026lt;class \u0026#39;_asyncio.Task\u0026#39;\u0026gt; t done: True   　这里有一个细节：如果你不在main()中使用await()，它会在main()发送完成信号之前完成。因为asyncio.run(main())调用loop.run_until_complete(main())，事件循环仅关心（没有await t）main()是否完成，并不关心在main()内部创建的任务是否完成。没有await t，循环其他的任务可能在它们完成之前取消。如果你需要获取当前待处理的任务列表，可以使用asyncio.Task.all_tasks()。\n\r\rasyncio.create_task()是在Python3.7中提出的。在Python3.6或更低版本，使用asyncio.ensure_future()替换create_task()。\n\r \r　另外，还有asyncio.gather()。尽管他没做什么特别的事，gather()意思是把协程（future）的集合整齐地放入一个单个的future中。它返回一个future对象作为结果，如果你await asyncio.gather()并指定多个任务或协程，你需要等待它们全部完成。（这个有点类似于先前例子中queue.join()的并行版）gather()的结果是输入的结果列表：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  \u0026gt;\u0026gt;\u0026gt; import time \u0026gt;\u0026gt;\u0026gt; async def main(): ... t = asyncio.create_task(coro([3, 2, 1])) ... t2 = asyncio.create_task(coro([10, 5, 0])) # Python 3.7+ ... print(\u0026#39;Start:\u0026#39;, time.strftime(\u0026#39;%X\u0026#39;)) ... a = await asyncio.gather(t, t2) ... print(\u0026#39;End:\u0026#39;, time.strftime(\u0026#39;%X\u0026#39;)) # Should be 10 seconds ... print(f\u0026#39;Both tasks done: {all((t.done(), t2.done()))}\u0026#39;) ... return a ... \u0026gt;\u0026gt;\u0026gt; a = asyncio.run(main()) Start: 16:20:11 End: 16:20:21 Both tasks done: True \u0026gt;\u0026gt;\u0026gt; a [[1, 2, 3], [0, 5, 10]]   　你可能注意到了gather()等待Future或你传递的协程的全部结果。或者，你可以遍历asyncio.as_completed()来按顺序获取完成的任务。函数返回一个在完成任务时产生任务的迭代器。在下面的例子中，在coro([10,5,0])完成之前可以使用coro([3,2,1])的结果，在gather()中则不行：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  \u0026gt;\u0026gt;\u0026gt; async def main(): ... t = asyncio.create_task(coro([3, 2, 1])) ... t2 = asyncio.create_task(coro([10, 5, 0])) ... print(\u0026#39;Start:\u0026#39;, time.strftime(\u0026#39;%X\u0026#39;)) ... for res in asyncio.as_completed((t, t2)): ... compl = await res ... print(f\u0026#39;res: {compl} completed at {time.strftime(\u0026#34;%X\u0026#34;)}\u0026#39;) ... print(\u0026#39;End:\u0026#39;, time.strftime(\u0026#39;%X\u0026#39;)) ... print(f\u0026#39;Both tasks done: {all((t.done(), t2.done()))}\u0026#39;) ... \u0026gt;\u0026gt;\u0026gt; a = asyncio.run(main()) Start: 09:49:07 res: [1, 2, 3] completed at 09:49:10 res: [0, 5, 10] completed at 09:49:17 End: 09:49:17 Both tasks done: True   　最后，你可能会看到asyncio.ensure_future()。你应该很少需要它，因为它是较低级的管道API，并且大多数情况都能被create_task()替代，稍后会介绍它。\nawait优先 　尽管它们有点相似，但await关键字比yield有更高的优先级。这意味着，由于界限紧密，因此在许多情况下，你需要在yield from语句中使用括号，而在类似的await语句中则不需要。详情参考PEP 492关于await表达式的示例。\n结论 　现在你已经可以使用async/await和由此构建的库了。这是本篇教程内容的回顾：\n 异步IO是一种语言无关模型和一种通过让协程之间间接交流实现有效并发的方式。 Python的新关键字async和await，用来标记和定义协程。 asyncio，Python提供运行和管理协程的包。  资源 Python版本细节 　Python中的异步IO发展迅速，很难追踪何时发生了什么。以下是与asyncio相关的Python版本变更列表：\n 3.3：生成器中允许使用yield from 3.4：在Python标准库中以临时API状态引入asyncio 3.5：async和await称为Python语法的一部分，用来标识和等待协程。它们仍不是保留字。（你仍然可以定义名为await和async的函数或变量） 3.6：引入异步生成器和异步理解（生产列表的工具）。asyncio的API被声明为稳定的，而不是临时的。 3.7：async和await称为保留字。（他们不能被用作标识符）它们替代了asyncio.coroutine()装饰器。``asyncio包引入了asyncio.run()`，其中包括许多其它功能。  　如果你想要稳一点（并且能够使用asyncio.run()），请使用Pyhton3.7或更高版本获取完整的功能。\n文章 　这是额外的资源清单：\n Real Python: Speed up your Python Program with Concurrency Real Python: What is the Python Global Interpreter Lock? CPython: The asyncio package source Python docs: Data model \u0026gt; Coroutines TalkPython: Async Techniques and Examples in Python Brett Cannon: How the Heck Does Async-Await Work in Python 3.5? PYMOTW: asyncio A. Jesse Jiryu Davis and Guido van Rossum: A Web Crawler With asyncio Coroutines Andy Pearce: The State of Python Coroutines: yield from Nathaniel J. Smith: Some Thoughts on Asynchronous API Design in a Post-async/await World Armin Ronacher: I don’t understand Python’s Asyncio Andy Balaam: series on asyncio (4 posts) Stack Overflow: Python asyncio.semaphore in async-await function Yeray Diaz:  AsyncIO for the Working Python Developer Asyncio Coroutine Patterns: Beyond await    A few Python What’s New sections explain the motivation behind language changes in more detail:\n What’s New in Python 3.3 (yield from and PEP 380) What’s New in Python 3.6 (PEP 525 \u0026amp; 530)  From David Beazley:\n Generator: Tricks for Systems Programmers A Curious Course on Coroutines and Concurrency Generators: The Final Frontier  YouTube talks:\n John Reese - Thinking Outside the GIL with AsyncIO and Multiprocessing - PyCon 2018 Keynote David Beazley - Topics of Interest (Python Asyncio) David Beazley - Python Concurrency From the Ground Up: LIVE! - PyCon 2015 Raymond Hettinger, Keynote on Concurrency, PyBay 2017 Thinking about Concurrency, Raymond Hettinger, Python core developer Miguel Grinberg Asynchronous Python for the Complete Beginner PyCon 2017 Yury Selivanov asyncawait and asyncio in Python 3 6 and beyond PyCon 2017 Fear and Awaiting in Async: A Savage Journey to the Heart of the Coroutine Dream What Is Async, How Does It Work, and When Should I Use It? (PyCon APAC 2014)  相关的PEP    PEP Date Created     PEP 342 – Coroutines via Enhanced Generators 2005-05   PEP 380 – Syntax for Delegating to a Subgenerator 2009-02   PEP 3153 – Asynchronous IO support 2011-05   PEP 3156 – Asynchronous IO Support Rebooted: the “asyncio” Module 2012-12   PEP 492 – Coroutines with async and await syntax 2015-04   PEP 525 – Asynchronous Generators 2016-07   PEP 530 – Asynchronous Comprehensions 2016-09    支持async/await的库 　From aio-libs:\n aiohttp: Asynchronous HTTP client/server framework aioredis: Async IO Redis support aiopg: Async IO PostgreSQL support aiomcache: Async IO memcached client aiokafka: Async IO Kafka client aiozmq: Async IO ZeroMQ support aiojobs: Jobs scheduler for managing background tasks async_lru: Simple LRU cache for async IO  From magicstack:\n uvloop: Ultra fast async IO event loop asyncpg: (Also very fast) async IO PostgreSQL support  From other hosts:\n trio: Friendlier asyncio intended to showcase a radically simpler design aiofiles: Async file IO asks: Async requests-like http library asyncio-redis: Async IO Redis support aioprocessing: Integrates multiprocessing module with asyncio umongo: Async IO MongoDB client unsync: Unsynchronize asyncio aiostream: Like itertools, but async  ","description":"一篇讲解Python异步IO博客的译文，内容很清晰","id":23,"section":"posts","tags":["python"],"title":"Python：完整地了解异步IO（译）","uri":"https://yyyIce.github.io/zh/posts/pythonasync-io-in-python-a-complete-walkthrough%E8%AF%91/"},{"content":"　主要是为了回调函数的编写和阅读，顺带了一点指针的基础内容。\n0.理解前提 　指针的定义和运算不再赘述，需要理解指针和地址的关系。\n　在编写代码的过程中，认为变量名表示的是数据本身，函数名、字符串名、数组名表示代码块或数据块的首地址。\n　变量都对应一块内存空间，整型变量5，对应的内存空间中存储的内容就是5，赋值时应赋给这块内容一个整型值；指针对应的这块内存空间存储的内容是它指向的数据的地址，所以在赋值时应将一个地址赋值给指针，也就是常说的指针就是地址。\n printf函数族中对于%p一般以十六进制整数方式输出指针的值）\n 　例如：指针p存储的内容是整型变量c的地址，对p存储的内容进行取值运算（*），即对地址取值，p存储c的地址，c中存储的是5，所以*p=5。\n1 2 3 4 5 6 7 8 9 10 11 12  int main() { int c = 5; int * p = \u0026amp;c; printf(\u0026#34;c:%d\t\u0026amp;c:%p\\n\u0026#34;, c, \u0026amp;c); printf(\u0026#34;\u0026amp;p:%p\tp:%p *p:%d\\n\u0026#34;, \u0026amp;p, p, *p); return 0; } 预计输出： c:5 \u0026amp;c:000000000062FE1C \u0026amp;p:000000000062FE10 p:000000000062FE1C *p:5   \r　下图左侧一列为地址，右侧一列为地址单元中存储的值。\n图1 \u0026amp;p，p，*p，c，\u0026amp;c的存储位置:\r\r 1.void * 　void *，void *表示这是一个指针，但是没有指定指针的类型（整型、字符型等等），即该指针可以被指向任意类型的变量。\n　(void *) \u0026amp;a， 把变量a的地址转换为任意类型的指针变量。\n　void *类型的变量给别的变量赋值应对其进行强制类型转换，例：\n1 2  void * p1 = NULL; int * p2 = (int *)p1;   2.二维数组和指针 　先明确指针的加（减）运算，是加上（减去）该指针指向的数据类型大小的整数倍。例如下面的代码中，指针p是int类型，将他指向a，则p + 1是将p，即a[0]的地址值加上一个整型数据的大小，即指向了a[0]的下一个元素，a[2]。\n1 2 3 4 5 6  int a[4] = {1,2,3,4}; int * p = a; for(int i = 0; i \u0026lt; 4; i++) { printf(\u0026#34;%d \u0026#34;,*(p+i)); }   　二维数组在内存中的分布是线性的（a[行][列]），整个数组占用一块连续的内存：\nint a[3][4] = {{0,1,2,3}, {4,5,6,7}, {8,9,10,11}};\r\r图2 a[3][4]内存分布图:\r\r 　即只是为了人类理解、编程方便，才将数组在逻辑上分成二维数组，在内存中仍是一维数组。\n　所以处理二维数组时可以把二维数组分解成多个一维数组来处理。a[3][4]可以分为a[0]，a[1]，a[2]，每个一维数组中有4个元素。\n　下面的代码声明了一个数组指针变量p，并将它指向了二维数组a，此时p等价于a[0]的首地址，p+1则是a[1]的首地址，因为此时p的指向类型是int [4]，所以+1指针会向后移动4个int大小，即指针值加上4个int大小，其值就是a[1]的地址。可以从输出看出，p+1的地址值比p多了0x10，即16，为4个int的大小。\n1 2 3 4 5 6 7 8  int b[3][4] = {{0,1,2,3}, {4,5,6,7}, {8,9,10,11}}; int (*p)[4] = b; printf(\u0026#34;sizeof(int): %d\\n\u0026#34;,sizeof(int)); printf(\u0026#34;p:%p , p+1:\u0026#34;,p , p+1); //输出 \u0026gt;\u0026gt;\u0026gt;sizeof(int): 4 \u0026gt;\u0026gt;\u0026gt;p:000000000062FDC0 , p+1:000000000062FDD0   　用二维数组指针访问二维数组元素：\n　根据上面所说，p+1是a[1]的首地址，所以p+1对应的内存单元中存储的是\u0026amp;a[1][0]，即a[1]的首地址，即*(p+1)，要访问a[1][1]，需要把a[1][0]的地址加上一个int大小，然后对这个地址做取值运算（*运算），\u0026amp;a[1][1]即*(p+1) + 1（也可以写成a[1]+1，因为a[1]代表首地址），是a[1][1]的地址，对它做取值运算，a[1][1] = *(*(p+1) + 1)=*(a[1]+1)，访问其他行列的元素同理。\n1 2 3 4 5 6 7 8  int b[3][4] = {{0,1,2,3}, {4,5,6,7}, {8,9,10,11}}; int (*p)[4] = b; printf(\u0026#34;\u0026amp;b[1][0]:%p\\tb[1]:%p\\t*(p+1):%p\\n\u0026#34;,\u0026amp;b[1][0],b[1],*(p+1)); printf(\u0026#34;b[1][0]:%d\\t*(b[1]+1):%d\\t*(*(p+1)+1):%d\\n\u0026#34;,b[1][0],*(b[1]+1),*(*(p+1)+1) ); //输出 \u0026gt;\u0026gt;\u0026gt;\u0026amp;b[1][0]:000000000062FDD0 b[1]:000000000062FDD0 *(p+1):000000000062FDD0 \u0026gt;\u0026gt;\u0026gt;b[1][0]:4 *(b[1]+1):5 *(*(p+1)+1):5   　指针数组和数组指针声明时的区别：括号位置\n1 2  int (*p1)[4]; //括号一定在*p1外，(*p) int *(p2[5]); //这是一个指针数组，该数组有5个元素，每个元素都是int类型的指针   3.函数指针 　函数指针即指向函数的指针，这种指针定义可以用一个标识符表示参数和返回值类型相同的任意函数，方便修改函数内容而引用函数的部分无需变动。\n　函数指针的定义形式：\n1  returnType (*pointerName)(param list); //括号不能省略，省略括号会变成返回值是指针的函数   　例：\n1 2 3 4 5 6 7 8 9 10 11  void haaa(int a, char c) { printf(\u0026#34;a:%d, c:%c\\n\u0026#34;,a,c); } int main() { int (*fun_pointer)(int, char) = NULL; //如果未指定初值记得指向NULL，养成良好习惯  fun_pointer = haaa; //函数名的值是函数的首地址，所以可以直接把haaa赋值给fun_pointer  fun_pointer(1,\u0026#39;x\u0026#39;); return 0; }   　其中对于函数指针的赋值，由于\u0026amp;haaa和haaa等价，所以(* fun_pointer)就是fun_pointer，所以使用函数指针的方法有很多种，即调用时加不加*都一样。\n1 2 3 4 5  printf(\u0026#34;\u0026amp;haaa:%p, haaa:%p\\n\u0026#34;, \u0026amp;haaa, haaa); \u0026gt;\u0026gt;\u0026gt;\u0026amp;haaa:0000000000401530, haaa:0000000000401530 printf(\u0026#34;fun_pointer:%p, *fun_pointer:%p\\n\u0026#34;, fun_pointer, *fun_pointer); \u0026gt;\u0026gt;\u0026gt;fun_pointer:0000000000401530, *fun_pointer:0000000000401530   1 2 3 4 5 6 7 8 9  //给指针函数赋值 fun_pointer = haaa; //或 fun_pointer = \u0026amp;haaa; //调用指针函数 fun_pointer(1,\u0026#39;x\u0026#39;); //或 (* fun_pointer)(1,\u0026#39;x\u0026#39;);   4.回调函数 　回调函数就是某函数的参数含有该函数的指针，则这个指针指向的函数被称为回调函数。\n　回调：没有直接调用这个函数，而是作为参数被别的函数调用。\n　在下面的代码中，test通过参数传递的方式调用了传入的函数，可以用一个函数灵活地调用不同的函数，当函数指针指向max时，把该指针作为参数传入test，会在test内执行max；指向min时同理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  #include \u0026lt;stdio.h\u0026gt;int test(int a, int b, int (* callback)(int,int)) { return callback(a,b); } int max(int a, int b) { return a \u0026gt; b ? a : b; } int min(int a, int b) { return a \u0026gt; b ? b : a; } int main() { int ret = 0; ret = test(4, 8, max); printf(\u0026#34;result:%d\\n\u0026#34;, ret); ret = test(4, 8, min); printf(\u0026#34;result:%d\\n\u0026#34;, ret); return 0; } \u0026gt;\u0026gt;\u0026gt;result:8 \u0026gt;\u0026gt;\u0026gt;result:4   　注：\n　在C中还可以向下面这样写，即不写指针的参数个数和类型，此时文件后缀必须为.c，.cpp会报错。可能是不规范但能执行的写法，不建议使用，但应该了解以便于程序的阅读。\n1 2 3 4  int test(int a, int b, int (* callback)()) { return callback(a,b); }   　回调函数的作用：可以作为接口，由应用实现test函数，第三方开发者实现callback函数，应用就可以帮助第三方开发者执行callback函数，从而达到开放性和可扩展性。这样应用只需要向第三方开发者提供头文件和动态链接库而无需提供源代码。第三方开发者通过头文件中的回调函数接口，编写需要应用执行的函数即可。\n5.分析练习 　试分析下列代码片段的逻辑：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  #include \u0026lt;stdio.h\u0026gt;#include \u0026lt;stdlib.h\u0026gt; typedef unsigned long (*bf_hash_handler_type)(void *element); struct bloom_filter { bf_hash_handler_type *handlers; unsigned char *bitmap; unsigned long k, m; }; typedef struct bloom_filter *bf_core_type; bf_core_type bf_create(bf_hash_handler_type handlers[], unsigned long k, unsigned long m) { bf_core_type bf; bf=(bf_core_type)malloc(sizeof(struct bloom_filter)); bf-\u0026gt;k=k; bf-\u0026gt;m=m; bf-\u0026gt;handlers=handlers; bf-\u0026gt;bitmap=(unsigned char *)malloc((m+7)\u0026gt;\u0026gt;3); return bf; } static inline unsigned char bitget(unsigned char *bitmap, unsigned long index) { return 1\u0026amp;(bitmap[index\u0026gt;\u0026gt;3]\u0026gt;\u0026gt;(index\u0026amp;7)); } int bf_has(bf_core_type bf, void *element) { int i; for(i=0; i\u0026lt;bf-\u0026gt;k; i++) { if(!bitget(bf-\u0026gt;bitmap, bf-\u0026gt;handlers[i](element)%bf-\u0026gt;m)) { return 0; } } return 1; } unsigned long simple_hash(void *element) { return *(unsigned long*)element; } //...  int main() { bf_core_type bf; bf_hash_handler_type handlers[]= {simple_hash}; unsigned long handlers_len=sizeof(handlers)/sizeof(bf_hash_handler_type); bf=bf_create(handlers, handlers_len, 100); //....  return 0; }   　　解析：\n　直接看main函数，一共四行。\n 第一行声明了一个bf_core_type类型的变量，bf_core_type是struct bloom_filter类型的指针的别名。 第二行初始化了一个bf_hash_handler_type类型的数组，该数组有一个元素simple_hash，bf_hash_handler_type是一个参数为void *类型、返回值为unsigned long类型的函数指针，并且该指针的别名为bf_hash_handler_type，定义函数指针时可直接：  \r1 2 3  bf_hash_handler_type fun_name; //等价于  unsigned long fun_name(void *);    第三行计算的是handlers中有几个元素，此行的计算结果应该为1，handlers的类型是指针数组，只有一个元素，指针类型是unsigned long，所以handlers的大小应该和bf_hash_handler_type的大小相同，也和unsigned long *的大小相同。  \r1 2 3 4 5 6 7 8 9  printf(\u0026#34;sizeof unsigned long:%d\\n\u0026#34;,sizeof(unsigned long)); printf(\u0026#34;sizeof unsigned long *:%d\\n\u0026#34;,sizeof(unsigned long *)); printf(\u0026#34;sizeof handlers:%d\\n\u0026#34;,sizeof(handlers)); printf(\u0026#34;sizeof bf_hash_handler_type:%d\\n\u0026#34;,sizeof(bf_hash_handler_type)); //输出  \u0026gt;\u0026gt;\u0026gt;sizeof unsigned long:4 \u0026gt;\u0026gt;\u0026gt;sizeof unsigned long *:8 \u0026gt;\u0026gt;\u0026gt;sizeof handlers:8 \u0026gt;\u0026gt;\u0026gt;sizeof bf_hash_handler_type:8   \r 第四行调用了bf_create函数，传入了函数指针数组，和两个值。 在bf_create函数中，为main中的bf申请了内存空间，并对bf进行初始化，没有调用simple_hash。 在bf_hash函数中，传入了含有回调函数的结构体bf，在bf-\u0026gt;handlers[i](element)%bf-\u0026gt;m这句所在的for循环中调用了handlers中的所有指针指向的函数。  6.参考代码 　地址：https://github.com/yyyIce/c_exercise/tree/main/pointer_test\n　有帮助的话可以点个Star⭐哦~\n参考资料 　1.二维数组指针：http://c.biancheng.net/view/2022.html\n　2.回调函数：https://cloud.tencent.com/developer/article/1457059\n","description":"C语言指针的用法和示例","id":24,"section":"posts","tags":["c"],"title":"C语言：指针","uri":"https://yyyIce.github.io/zh/posts/c%E8%AF%AD%E8%A8%80%E6%8C%87%E9%92%88/"},{"content":"　注意题目：C语言，不是C+。\n　本文适合对C语言有一定理解，只存在部分概念模糊的人群阅读，不适合初学者，参考资料列在文章最后。\n　本文的目标是彻底理解结构体，在需要使用结构体时，光速且正确地写完相关代码，做明明白白的工具人。\n0.变量的定义、声明、初始化 　变量的声明，是向程序表明变量的类型和名字。如结构体类型声明、函数声明等，在仅声明时，不分配内存空间。\n　定义也是声明，但在定义时，为变量分配内存空间。\n1 2  int a; //是定义，也是声明，未初始化 extern int a; //是声明，不是定义，未初始化   　声明主要是为了(提前)使用声明的内容，声明的作用举例：\n 不声明结构体类型，则无法在后来需要时才定义结构体类型的变量。 如果有一个函数fun_1，在文件的代码顺序中它定义在调用它的函数fun_2后面，此时如果不更改定义顺序，则必须在文件开始处声明fun_1。  　变量初始化就是赋予变量一个初始值：\n1 2 3 4  int a; //定义变量 a = 5; //初始化 //或 int b = 10; //在变量定义的同时初始化   1.结构体类型的定义和声明 (1)struct \u0026lt;结构体名\u0026gt;{\n​ 类型 \u0026lt;成员名\u0026gt; ;\n​ 类型 \u0026lt;成员名\u0026gt; ;\n​ \u0026hellip;\n}；\n1 2 3 4 5 6 7  //例如： struct student_t { char name[128]; int sex; int age; };   (2)可在声明结构体的同时定义变量，如下文代码，在声明类型struct student_t的同时，还定义了2个变量， student1 和 student2 ，它们的类型是struct student_t。\n1 2 3 4 5 6  struct student_t { char name[128]; int sex; int age; }student1,student2;   (3)也可以不写结构体名，直接定义结构体变量：\n1 2 3 4 5 6  struct { char name[128]; int sex; int age; }student;   2.结构体的初始化和内存空间分配 (1)定义时赋值 1  struct student_t s1 = { \u0026#34;Sarah\u0026#34;, 0, 18};   (2)定义后逐个赋值 理论上应该如下所示：\n1 2 3 4  struct student_t s2; s2.name = \u0026#34;Sam\u0026#34;; //此句报错 s2.sex = 1; s2.age = 19;   解释：不能在定义以外的地方把字符串赋值给一个字符数组。\n1 2 3  char a[10] = \u0026#34;hello\u0026#34;; //这样可以，这种情况是c语言初始化所支持的，此时\u0026#34;hello\u0026#34;没有存储在常量区 char b[10]; b = \u0026#34;hello\u0026#34;; //这样不行，不能把字符串赋值给一个数组，此时\u0026#34;hello\u0026#34;存储在常量区   　双引号\u0026quot;\u0026quot;在常量区申请内存空间并存放字符串hello，并在字符串尾加入\\0，最后返回申请的内存空间的地址，b是数组的首地址，但是它是一个常量，编译器不允许更改存储在常量区的内容，即它不是一个左值。左值就是指在程序中占用内存空间、可以被修改的量,比如各种变量。\n　更改：将name的类型改为字符指针char *，此时再进行赋值则不会出现问题。s2.name是一个字符指针，指针的本质就是地址，即指针这块内存空间存储着其指向内容的内存地址，假设Sam这个字符串的地址为addr，则s2.name申请的空间中存储着addr，在寻址时取出addr，即可找到存储的内容Sam。\n1 2 3 4 5 6 7 8 9 10  struct student_t { char * name; int sex; int age; }; struct student_t s2; s2.name = \u0026#34;Sam\u0026#34;; //不报错 s2.sex = 1; s2.age = 19;   　这时候可能有人要提问了，既然s2.name中存储的是addr，那么为什么我输出s2.name，会输出Sam而不是addr呢？这是printf的实现机制决定的，如果我们选用%p格式，则会输出存储数值的地址，如果用%d，%c，则会输出地址中存储的数值，如果使用%s，则会输出首地址及其余地址存储的字符串内容。测试代码及结果如下：\n1 2 3 4 5 6 7 8 9 10 11 12  struct student_t s4; char a[10] = \u0026#34;Sally\u0026#34;; s4.name = a; //a是数组首地址 s4.sex = 1; s4.age = 19; printf(\u0026#34;%p\\n\u0026#34;, a); //%p可以输出变量存储的地址，000000000062FD50 printf(\u0026#34;%s\\n\u0026#34;, a); //%s寻址，输出地址内存储的内容，Sally printf(\u0026#34;%p\\n\u0026#34;, s4.name); //输出s4.name存储(指向)的地址，000000000062FD50，可以发现与a的地址相同 printf(\u0026#34;%p\\n\u0026#34;, \u0026amp;s4.name); //输出s4.name本身的地址，000000000062FD60 printf(\u0026#34;%c\\n\u0026#34;, *s4.name); //注意使用%c，\u0026#39;*\u0026#39;为取地址中存储的数值，s4.name中存储的内容是第一个字母\u0026#39;S\u0026#39; printf(\u0026#34;%s\\n\u0026#34;, s4.name); //%s，输出s4.name这一串地址存储的内容，Sally printf(\u0026#34;%p\\n\u0026#34;, \u0026amp;*s4.name); //输出s4.name存储内容\u0026#39;S\u0026#39;的地址， 000000000062FD50   　我们可以看出实质上a和s4.name的地址是相同的。在实际程序调试过程中可以使用gdb等调试工具查看内存地址，不建议使用输出的方式。\n(3)定义时乱序赋值\n1 2 3 4 5 6  struct student_t s5 = { .name = \u0026#34;Tom\u0026#34;, .sex = 1, .age = 10 }; printf(\u0026#34;%s, %d, %d\\n\u0026#34;, s5.name, s5.sex, s5.age);   (4)内存空间占用\n　C语言不是内存安全的，需要编程人员自己管理内存，所以应对内存空间的分配有清晰的认识。现在感觉没什么用，等用到就懵了。基本类型的内存空间占用（单位：字节）如下：\n1 2 3 4 5 6 7  printf(\u0026#34;void:%d\\n\u0026#34;,sizeof(void)); //1 printf(\u0026#34;char:%d\\n\u0026#34;,sizeof(char)); //1 printf(\u0026#34;short:%d\\n\u0026#34;,sizeof(short)); //2 printf(\u0026#34;int:%d\\n\u0026#34;,sizeof(int)); //4 printf(\u0026#34;long:%d\\n\u0026#34;,sizeof(long)); //4(win64),8(ubuntu18) printf(\u0026#34;float:%d\\n\u0026#34;,sizeof(float)); //4 printf(\u0026#34;double:%d\\n\u0026#34;,sizeof(double)); //8   　指针类型的空间占用，和指针的基本类型无关，和计算机一次能够处理的操作数大小有关，俗称字长（关于字和字长可参考《汇编语言》-王爽），在64位操作系统中，能够处理的操作数大小为64bit，所以指针类型的大小为8字节，如char *，int *， struct example1_t *，其大小都是8字节。32位操作系统指针的大小就为4字节。\n1 2 3 4 5 6  char * c; int * d; struct example1_t * e; printf(\u0026#34;char * c:%d\\n\u0026#34;,sizeof(c)); printf(\u0026#34;int * d:%d\\n\u0026#34;,sizeof(d)); printf(\u0026#34;example1 * e:%d\\n\u0026#34;,sizeof(e));   　结构体的内存空间占用不能单纯的将结构体中的所有类型大小相加，以下面两个结构体为例，这两个结构体内的变量和变量类型完全相同， 但占用的内存空间大小不同。\n1 2 3 4 5 6 7 8 9 10 11 12  struct example1_t { char a; int b; short c; }; struct example2_t { char a; short c; int b; }; printf(\u0026#34;example1: %d\\n\u0026#34;,sizeof(struct example1_t)); //12B printf(\u0026#34;example2: %d\\n\u0026#34;,sizeof(struct example2_t)); //8B   　这是因为结构体在存储时，以结构体中占用空间最大的基本变量类型为一个单元，按结构体中的变量定义顺序开辟一个又一个单元的空间。\n　在example1_t中，占用空间最大的变量类型为int，所以以4字节为一个单元开辟空间。第一个单元存放char类型的a后，还剩3个字节，不够继续存放b，所以开辟第二个大小为4字节的单元，存放b，b的类型为int，第二个单元被放满，所以开辟第三个大小为4字节的单元，存放c。一共开辟了三个4字节的单元，所以example1_t的占用的空间大小为3 * 4 = 12 字节。\n　在example2_t中，仍是以int的大小作为单元大小，与example1_t不同的是，第二个定义的是c，c是2字节的short类型，可以和a放在同一内存单元中，此时第一个单元剩1字节，不够存放b，于是开辟第二个4字节内存单元。一共开辟了2个4字节的单元，所以example2_t占用的空间大小为2 * 4 = 8 字节。\n　在结构体中有数组时，数组就相当于若干个该类型的元素，如下面的example3_t，其中的char b[4]就相当于4个char b，则第一个4字节内存单元存放a，b[0]，b[1]，b[2]；第二个单元存放b[3]和c；最后一个单元存放d，所以example3_t的大小为3 * 4 = 12 字节。\n1 2 3 4 5 6  struct example3_t { char a; char b[4]; short c; int d; };   　example1_t、example2_t、example3_t的空间占用图示：\n图1 example1_t、example2_t、example3_t的空间占用:\r\r 　所以结构体占用的空间大小应是结构体中占用空间最大的基本变量类型的整数倍，并且我们可以准确地计算出来。基本变量类型包括整型、浮点型、字符型、指针、无值型(void)。\n　那如果结构体中含有结构体时，占用空间是什么样的呢？当结构体中含有结构体时，以其中的所有基本变量类型中占用空间最大的为单元大小。以下列两个结构体为例：\n1 2 3 4 5 6 7 8 9  struct example4_t { char a; int b; double c; }; struct example5_t { char a; struct example4_t c; };   　结构体example_4的大小为16字节，结构体example5_t的大小为24字节。\n3.typedef与结构体结合使用 　我们经常在声明结构体的时候看到与typedef连用，于是就又懵了，那么这里的typedef又是什么意思呢？\n　typedef是一个关键字，常用作给类型起一个别名，使用形式为\n1  typedef \u0026lt;旧变量名\u0026gt; \u0026lt;新变量名\u0026gt;;   　下列代码给int类型起了别名ios_int，在定义变量b时，就可以使用ios_int来定义b，其含义与int b相同。\n1 2 3  typedef int ios_int; int a; ios_int b;   　如何使用typedef给结构体类型起别名呢？\n1 2 3 4 5 6  typedef struct student_t { char name[128]; int sex; int age; }student;   　此时相当于typedef struct student_t{} student，即student是struct stutent_t的别名，此时student不再是定义的一个变量，而是别名，要注意与前边struct student_t {...} student;进行区分。在变量定义时：\n1 2 3  student a; //等价于 struct student_t a;   4.结构体指针 　结构体指针需要申请内存空间后才可以对元素赋值（不然指针只有8字节，存储地址，赋予的这些值没有位置存放），或者直接将结构体指针直接指向已有结构体。\n1 2 3 4 5 6 7 8 9  struct student_t { char name[128]; int sex; int age; }student; student b = {\u0026#34;Lee\u0026#34;, 1, 19}; student * a; a = \u0026amp;b;   　使用malloc函数申请内存空间，该函数包含在头文件\u0026lt;stdlib.h\u0026gt;中。注意申请的空间大小不可以带星号，'*\u0026lsquo;表示指针，指针大小不等于结构体大小，我们申请空间是用来来存放结构体中的数据的。\n1 2 3 4  void* malloc (size_t size); //(申请空间的变量类型)malloc(申请的空间大小) //例： student * a = (student *)malloc(sizeof(student)); a-\u0026gt;age = 19;   5.分析练习 　如果对以上5点都熟悉了以后可以来看这样一个结构体(代码来自于不知道哪位)进行练习：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  typedef struct _p_data_analysis { char p_type[8]; //包类型  int time[6]; //时间戳  int len; //长度  struct _ethernet_h *eth_hdr; //以太网帧头  struct _arp_h *arp_hdr; //arp包头  struct _ip_h *ip_hdr; //ip包头  struct _icmp_h *icmp_hdr; //icmp包头  struct _udp_h *udp_hdr; //udp包头  struct _tcp_h *tcp_hdr; //tcp包头  }p_data_analysis;   　请完成以下练习：\n　（1）定义一个该类型的变量\n（2）计算该类型占用的空间大小(win64系统)\n（3）定义一个该类型的指针变量，其申请内存空间，并用memset清0\n（4）根据（3）中定义的指针变量，为.eth_hdr申请内存空间\n参考答案：\n　（1）typedef给struct _p_data_analysis定义别名p_data_analysis，所以可以用两种方式定义：\n1 2 3  struct _p_data_analysis a; //或 p_data_analysis a;   　（2）win64系统的指针大小为8字节，该结构体以8字节为一个单元进行存储，p_type占用1个单元，time占用3个单元，len占用1个单元，6个指针占用6个单元，一共需要1 + 3 + 1 + 6 = 11个单元，每个单元8字节，最终占用的空间大小为11 * 8 = 88 字节。\n　（3）\n1 2 3 4 5 6 7 8  p_data_analysis * data = (p_data_analysis *)malloc(sizeof(p_data_analysis)); //或 struct _p_data_analysis * data = (struct _p_data_analysis *)malloc(sizeof(struct _p_data_analysis)); memset(data, 0, sizeof(p_data_analysis)); //或 memset(data, 0, sizeof(struct _p_data_analysis));   　（4）\n1  data-\u0026gt;eth_hdr = (struct _ethernet_h *)malloc(sizeof(struct _ethernet_h));   参考代码 　地址：https://github.com/yyyIce/c_exercise/tree/main/struct_test\n　有帮助的话可以点个Star⭐哦~\n参考资料 　结构体内存空间的占用：https://blog.csdn.net/fb2058/article/details/15502071\n","description":"C语言结构体的用法和示例","id":25,"section":"posts","tags":["c"],"title":"C语言：结构体的使用","uri":"https://yyyIce.github.io/zh/posts/c%E8%AF%AD%E8%A8%80%E7%BB%93%E6%9E%84%E4%BD%93/"},{"content":"1.快速了解 typedef用来为数据类型起别名，这样在阅读时能够更清晰地理解程序，同时也可以让变量名变短。\n例如下面的代码中，struct student很长(但是可以表明这是一个结构体类型的变量)。\n1 2 3 4 5  struct student{ char * name; int sex; } struct student a;   我们可以用typedef来将struct student缩短\n1  typedef struct student stu;   而我们更常见的形式是下面这样，在声明的同时定义别名：\n1 2 3 4 5 6 7  typedef struct student{ char * name; int sex; }stu; struct student a; //等价于 stu a;   2.typedef用法 关键字typedef可以为类型起一个新的别名，用法一般为：\n1  typedef \u0026lt;old_type_name\u0026gt; \u0026lt;new_type_name\u0026gt;;   1.易读别名：给基础类型起别名\n1 2 3 4  typedef int ICE_INT; int a; //等价于 ICE_INT a;   2.不太易读的别名：给数组起别名，为结构体起别名(可见引言)\n1 2 3 4  typedef char ICE_ARRAY15[15]; //ICE_ARRAY15是char [15]的别名 char a[15]; //等价于 ICE_ARRAY15 a;   3.看不太懂的别名\n(1)为指针起别名(注意，*必须和new_type_name用括号括起来)\n1 2 3 4  typedef char (* ICE_PTR_ARR)[10]; //ICE_PTR_ARR是char * [10]的别名 char (* p)[10]; //等价于 ICE_PTR_ARR p; //引用时也是p[0],p[1],...   (2)为函数指针定义别名\n1 2 3 4  typedef int (* ICE_FUNC)(int, int); //别名是ICE_FUNC，类型是参数为(int,int)返回值位int的函数指针 int (* p_func)(int, int); //等价于 ICE_FUNC p_func;   （3）为结构体指针起别名\n1 2 3 4 5  //其中ice_t是struct ice_struct *类型，即一个struct ice_struct类型的指针 typedef struct ice_struct * ice_t; //写成下面这种形式容易看不懂，容易将ice_t和*读到一起，和struct ice_struct分开 typedef struct ice_struct *ice_t;   3.参考代码 链接：https://github.com/yyyIce/c_exercise/blob/main/typedef_test.c\n有帮助的话可以点个Star⭐哦~\n参考资料 [1]http://c.biancheng.net/view/2040.html\n","description":"C语言Typedef的使用方法","id":26,"section":"posts","tags":["c"],"title":"C语言：Typedef","uri":"https://yyyIce.github.io/zh/posts/c%E8%AF%AD%E8%A8%80typedef/"},{"content":"　是一款强大的数据包分析软件\n　官网地址：https://www.wireshark.org/\n1.安装 　（1）进入官网\n图1 官方界面:\r\r 　（2）点击“Download”进入下载界面，选择合适的版本，一路下一步即可。\n　Download地址：https://www.wireshark.org/#download\n图2 选择合适的wireshark版本:\r\r 2.简单使用 　详细的使用可以从图1的“Learn”点进去，包括使用文档和开发文档\n　Learn地址：https://www.wireshark.org/#learnWS\n2.1 抓包 　（1）打开wireshark，双击选择网卡，后面的线有波动即为该网卡有数据包\n图3 选择网络适配器（网卡）:\r\r 　（2）开始捕包的界面如下，点击“文件”下面的红色方块即可停止。\n图4 开始捕包（网卡）:\r\r 2.2 过滤 　在应用显示过滤器中输入过滤规则可以过滤出符合条件的数据包，一般用于筛选特定协议、端口的数据包，提取它们的特征。\n　过滤规则：\n图5 过滤规则为http:\r\r 　常用追踪TCP流分析会话，调试纠错，可以看到完整的TCP握手分手过程\n图6 选中某数据包右键追踪TCP流:\r\r 图7 追踪TCP流的结果:\r\r 　可以看到客户端先发送SYN，seq=0，然后服务端发送SYN，ACK，seq=0，ack=1，客户端发送ACK，seq=1，ack=1，握手结束，建立连接。\n图8 追踪TCP流的数据包结果:\r\r 2.3 导出分组 　（1）文件-\u0026gt;导出特定分组\n图9 导出特定分组:\r\r 　（2）根据“PacketRange内的选项导出数据包，比如可以先将想要过滤的数据包在应用显示过滤器中过滤出来，然后选择\u0026quot;displayed\u0026quot;，导出过滤后的分组\n图10 在导出界面进行选择:\r\r 3.高级用法 　暂时没用到，用到再说吧\n","description":"wireshark的使用","id":27,"section":"posts","tags":["basic"],"title":"工具使用：wireshark","uri":"https://yyyIce.github.io/zh/posts/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8wireshark/"},{"content":"　论文名称：SilkRoad: Making Stateful Layer-4 Load Balancing Fast and Cheap Using Switching ASICs\n　会议信息：SIGCOMM ’17, August 21–25, 2017, Los Angeles, CA, USA\n　成果：在switch.p4的基础上编写400行P4代码，在一台可编程ASIC交换机上实现百万连接的负载均衡，可代替多达数百个软件负载均衡器。\n　贡献：将ConnTable从负载均衡软件上转移到交换机中；更好地保证每个连接一致性(PCC)\n四层负载均衡面临的挑战：低延迟的完整双向通信 ；频繁的DIP池变动过程中，确保每个连接的一致性\n　前人工作不足：软件负载均衡器(ConnTable和VIPTable都在软件上，能保证PCC，延迟高，性能隔离差)、Duet(VIPTable在交换机上，不存储连接状态，能低延迟但是不能完全保证PCC）\n　本文工作：ConnTable和VIPTable都在交换机上，存储连接状态，低延迟，且比Duet保持PCC的效果好\n注：涉及到的基础概念可在文末查询。\n一、背景 1.四层负载均衡 　四层负载均衡维护两张表，ConnTable和VIPTable\n图1 ConnTable和VIPTable:\r\r 　ConnTable：记录每个连接映射到的DIP，即连接状态\n　VIPTable：记录VIP映射到的DIP池\n　当一个新连接(TCP SYN数据包)到达时，负载均衡软件根据VIP，从该VIP对应的DIP池中运行hash运算选择一个DIP，然后将该数据包转发到所选DIP对应的服务器上去。当该连接的后续数据包到达时，负载均衡软件直接将这些数据包转发到之前所选DIP对应的服务器。所以需要两个存储结构，分别用来记录连接和DIP的关系、VIP和DIP池的关系。一般用ConnTable记录连接和DIP的映射关系，用VIPTable记录VIP和DIP池的映射关系。当新连接到达时，将不会命中ConnTable，此时由交换机在VIPTable中根据新连接的VIP选择一个DIP，选择DIP之后，由交换机的CPU将这个连接和为它选择的DIP记录在ConnTable中，这样该连接的后续数据包到达时，直接根据ConnTable进行转发即可。\n　每个连接的一致性(PCC)：同一连接的每个数据包都映射到相同的DIP。\n　破坏每个连接的一致性：当DIP池由于添加或删除服务器而发生变化时，同一连接的数据包可能会哈希到不同的DIP，从而破坏每个连接的一致性（per-connection consistency, PCC）。\n　破坏PCC的情况分析：\n　1）如果在ConnTable中记录连接状态，则向DIP池中添加DIP不会影响已经写入ConnTable的连接的PCC，因为已经写入ConnTable的连接的数据包不经过VIPTable，直接转发到记录的DIP去；而DIP池中删除DIP一定会将这个DIP的连接全部断开后再删除，也不会影响已经写入ConnTable的连接的PCC。所以在记录连接状态的情况下，只有在新连接到达，且还没有将新连接状态写入ConnTable时，VIPTable更新，才有可能破坏PCC。\n　举例说明，假设有一个新连接A，A的第一个数据包到达，未命中ConnTable，经过hash计算，选择了VIP对应的DIP池中索引为20的DIP，记作a_dip，此时向VIPTable的此DIP池中增加3个DIP，这3个DIP位于a_dip前，则a_dip的索引变为23，在A的第二个数据包到达时，连接A-a_dip还没来得及写入ConnTable，第二个数据包也去匹配VIPTable，但由于向VIPTable中插入了3个DIP，这次经过hash计算后索引仍为20，但索引20存储的DIP已经不是a_dip了，第一个数据包和第二个数据包映射到了不同的DIP，PCC被破坏。\n　所以在记录连接状态的情况下，只有“新连接到达时”到“完成向ConnTable写入新连接状态”的这一时间段内更新VIPTable会影响PCC，其他时间更新VIPTable不会影响PCC。换句话说，更新VIPTable时，要考虑是否有新连接到达，要对新连接进行处理以保护PCC。\n　2）如果在ConnTable中不记录连接状态，则每次都运行hash运算来选择同一DIP，则只要VIPTable发生变化，就可能破坏PCC。\n　VIPTable必须是原子更新，且要与向ConnTable中插入\u0026quot;连接-DIP\u0026quot;的动作同步。\n2.前人的解决方案 2.1 负载均衡软件(Software Load Balancer, SLB) 　在软件中实现ConnTable和VIPTable，需要大量服务器，高成本、高延迟、高抖动，性能隔离差，但保证了PCC。在软件实现中，负载均衡器锁定VIPTable，并将新的传入连接保存在缓冲区中，防止它们匹配VIPTable。然后，SLB将新的DIP池映射更新到VIPTable，然后释放缓冲区中的连接。这样，SLB可以确保在VIPTable更新之前和之后的PCC，但是代价是CPU慢路径包处理和缓冲延迟。\n2.2 Duet 　在交换机上实现VIPTable，但仅用交换机处理具有较高流量的VIP，使用SLB(包含VIPTable和ConnTable)处理其他VIP，但无法保证频繁的DIP池更新情况下的PCC。\n　由于Duet不记录连接状态(即ConnTable中不存储DIP)，每次都依靠Hash算法来选择对应的DIP，导致DIP池中的DIP频繁添加或删除时，同一连接的不同数据包可能会映射到不同的DIP上。为应对此种情况，Duet定期将VIP迁移到交换机，或等所有旧连接都完成再更新VIPTable。\n二、本文的工作 　在ASIC交换机上实现ConnTable和VIPTable，始终在交换机上处理所有连接。\n　存在的问题，ConnTable太大，无法存储在SRAM中；VIPTable更新造成的破坏PCC的问题。\n1.控制ConnTable的规模 　ASIC交换机的SRAM大小为50-100MB，而正常的ConnTable有几百MB，所以对ConnTable的存储内容进行压缩。\n　P4中的Match-Action表的数据包括匹配字段(match field，就是key)、动作数据(action data)，ConnTable的匹配字段即能够标识一个连接的五元组，动作数据即为该连接的VIP所选择的DIP。所以可以从两个方向缩减ConnTable的规模。一是存储的匹配字段的大小，另一个就是缩短动作数据。\n　在Silkroad中，ConnTable的匹配字段不存储连接的五元组，而存储五元组的16位的hash摘要，从而减少匹配字段的大小；动作数据不存储DIP，而存储大小为6位的DIP池版本号。\n1.1 ConnTable用 hash摘要标识连接而引入的问题 　问题描述：如果两个连接的hash计算结果相同，即hash摘要相同，发生冲突，这时使用hash摘要去匹配ConnTable会导致误报。例如，假设连接A的hash摘要为digest，连接B计算后的hash摘要也是digest，连接A已经存在于ConnTable中，此时连接B作为新连接到达，则连接B将被错误地当作连接A，数据包将不经过VIPTable，直接转发到连接A的DIP对应的服务器上，而连接A的DIP，和连接B的VIP，不一定具有映射关系，导致误报。\n　问题解决：每当连接与ConnTable中的条目匹配，就将连接的TCP SYN数据包重定向到交换机的CPU，交换机软件对ConnTable中的每个条目具有完整的5元组信息，因此可以识别新连接的错误命中。\n　ConnTable这样的大型表，在ASIC交换机上会以多个物理级表的形式实例化，即物理上将ConnTable拆分成了几个子表，假设为ConnTable0,ConnTable1,ConnTable2。利用Match-Action的多阶段体系结构，我们可以在不同阶段使用不同的Hash函数进行映射，即在ConnTable0上使用Hash0，在ConnTable1上使用Hash1\u0026hellip;。当新连接B的Hash摘要与ConnTable0中的连接A的Hash摘要相同时，CPU检测到冲突，则将连接A迁移到另一个阶段，即计算其在ConnTable2中的Hash摘要并它迁移到ConnTable2中，这时连接B存储在ConnTable0中，连接A存储在ConnTable2中，由于ConnTable0和ConnTable2的Hash计算方式不同，连接A的Hash摘要和连接B的Hash摘要不同，冲突解决。这实际上利用了Cuckoo Hash的思想，即将冲突的条目放到别的槽里。\n1.2 ConnTable中用DIP池的版本来代替DIP引入了新表 　如下图所示，由于在ConnTable中使用了“Conn-Version”的映射，必须增加一张表维护Version和DIP池的映射关系，才能让连接中的数据包转发到对应的DIP上去。由于不同VIP对应DIP池的版本号可能相同，所以Version不是唯一标识DIP池的字段，VIP+Version才是唯一标识DIP池的字段。所以引入一张新表DIPPoolTable，记录VIP Version和DIP池的映射关系。\n图2 DIPPoolTable:\r\r 　DIP池更新时，先创建一个原DIP池的副本，然后在这个副本上进行更改，这个更改后的副本就成为了新DIP池，再将新版本号分配给新DIP池，再对VIPTable进行编程，将连接映射到最新的DIP池版本。当使用DIP池的连接超时并从ConnTable中删除时，DIP池将销毁，销毁时池的版本号会释放回环形缓冲区。交换机软件跟踪连接到池的映射，并管理DIP池的创建、删除、存储版本号的环形缓冲区。\n　可以通过版本重用减少活动版本的数量，从而减少版本位的大小。在添加的新DIP和删除的DIP数量相同时，可以修改现有池，将现有池重新用作最新池，而不是重新创建DIP池并获得新版本号。比如图2，之前20.0.0.1：80的V1中有两个DIP，现在进行更新，删去红色划线的DIP，增加绿色的DIP，更新后DIP的数量不变。如果重新建立DIP池，则获得版本号V3，如果重用原有DIP池，则版本号为V1。智能地重用版本号降低了版本号增加的速度。\n　根据大型Web服务提供商的数据，6bit的版本号足够处理DIP池更新的各种情况。当映射到每个DIP池版本的连接数量很大且寿命很短时，采用Version的ConnTable比记录DIP的ConnTable节省了很多开销。当活跃连接的数量很少且寿命很长时，将退回到“Conn-DIP”的映射，而不使用Version。\n2.保证每个连接的一致性 　SilkRoad在ConnTable中存储了连接状态。在本文第一章的第一小节“四层负载均衡”中我们提到过破坏PCC的条件，在ConnTable存储连接状态的情况下，VIPTable更新时仅需要考虑处理到达交换机但未写入ConnTable中的新连接。\n　在软件负载均衡器(SLB)中，在VIPTable更新时，会锁定VIPTable，并设立一个缓冲区存储新连接，当VIPTable更新完毕，释放缓冲区中的新连接。SilkRoad采用的方法与SLB中的方法一致，也是将新连接存储起来，存储到一个新的表TransitTable中，但在细节上有所不同。\n　天真的设计：将每个新连接都存储在TransitTable中，并记录其选择的DIP池版本。\n　缺点：TransitTable特别大。\n　前边在第一章也分析过了，ConnTable存储链接状态时，不需要存储所有新连接，仅考虑在DIP池更新时到达但未写入ConnTable的连接，即在TransitTable中存储映射到旧DIP池的挂起连接(挂起连接：在时刻t到达，但尚未插入ConnTable中的连接)。文章把处理挂起连接分为3步。\n　第一步：当收到VIPTable的更新请求时，会有一些连接A、B、C还没有被CPU插入到ConnTable，这时开始记录新连接D、E、F到TransitTable，因为VIPTable这时还没有开始更新，所以新连接D、E、F映射到了旧版本的DIP池，即TransitTable存储了VIPTable更新时，映射到旧DIP池但没有插入到ConnTable的新连接（第二步中可知，连接A、B、C在VIPTable更新时已经插入到了ConnTable中）。\n　第二步：当收到VIPTable更新请求之前的连接A、B、C都插入到ConnTable时，停止记录新连接到TransitTable。然后更新VIPTable。更新完毕后，所有未命中ConnTable的数据包都会先经过TransitTable，如果命中TransitTable，说明该连接应该映射到旧版本的DIP池，如果未命中TransitTable，则将匹配VIPTable，将映射到新版本的DIP池。\n　第三步：当TransitTable中的所有连接都插入ConnTable后，清除TransitTable，完成该过程。\n　所以由以上三步，我们只需要记录挂起连接和旧版本到TransitTable中。进一步思考，挂起连接要么映射到旧版本，要么映射到新版本，而根据DIPPoolTable的新版本创建规则，创建新版本时先创建旧版本的副本，然后修改副本为新版本。所以DIPPoolTable中存储了所有的版本，用新版本号-1即可找到旧版本，所以TransitTable中可以只存储挂起连接而不必存储旧版本号。\n　TransitTable中只存储连接，则可以转化为连接是否存储在TransitTable中的问题，即元素是否存在于集合中的问题。所以TransitTable可以用Bloom Filter来实现，Bloom Filter可以节省大量内存，但Bloom Filter可能存在误报，导致连接映射到旧版本。Bloom Filter可以用事务寄存器来实现。所以实际上，在SilkRoad中，TransitTable不是Match-Action表，而是用事务寄存器实现的Bloom Filter。Bloom Filter的大小设置影响误报率，Silkroad将其大小设置为256字节。\n3.两个VIPTable更新的例子 　1）对于更新时已经存在于ConnTable中的连接，当DIP池更新前后，不会影响PCC。如下图所示，虽然更新了v1所对应的DIP池，但由于DIPPoolTable的更新机制，conn_a仍然能映射到原来v1的DIP池中去。\n图3 更新时已存在于ConnTable的连接的PCC:\r\r 　2）对于更新时到达的新连接，VIPTable在更新时，复制原来的VIPTable得到一个副本，然后在副本上修改为新的VIPTable（Lock Free RCU的思想），修改完毕后，再清空旧的VIPTable和BloomFilter。所以BloomFilter只需要存储新连接摘要，而不需要存储旧的版本号。\n图4 更新时到达的新连接的PCC:\r\r 4.为什么使用Bloomfilter存储新连接？  Silkroad使用布隆过滤器实现缓存新连接而没有使用数组，可能不是因为布隆过滤器的高性能，可能就是恰好想到了布隆过滤器，实验以后发现能用，就用了。 如果Transit基本保持在8个连接，连接摘要16位，用表存储摘要，一共占用16 * 8 =16字节，而布隆过滤器占用256字节，为什么不用Table？可能是CPU将表项插入到表中速度较慢，而寄存器读写不需要经过CPU。 为什么不使用其他方法，如顺序查找？一个周期内对一个寄存器只能操作一次。  5.整体架构 图5 SilkRoad总体架构:\r\r 　系统整体架构如上图所示,除了前文中提到的ConnTable，VIPTable，TransitTable，DIPPoolTable以外，增加了一个LearnTable，用来触发CPU学习新连接。\n三、实现 　基线switch.p4之上构建了SilkRoad的P4原型，并在可编程交换机ASIC [1]上进行了编译。基线switch.p4以大约5000行P4代码实现了典型云数据中心（L2 / L3 / ACL / QoS / \u0026hellip;）所需的各种联网功能。基线switch.p4的简化版本在[16]中开源。我们添加了约400行P4代码，这些代码实现了SilkRoad所需的所有表和元数据（图10）。 [32]中展示了我们原型的更多细节。\n　我们将所有表实现为exact-match表，但TransitTable作为事务内存上的Bloom过滤器除外。 ASIC通常支持字打包，这允许一次有效地与SRAM块中的多个字匹配[19]。我们精心设计单词打包，以最大程度地提高存储效率，同时最大程度减少误报[27]。\n　我们还在交换软件中实现了一个控制平面，该平面处理来自学习过滤器的新连接事件以及来自ConnTable的连接到期事件。该软件运行杜鹃哈希算法以插入或删除ConnTable中的连接条目。此外，控制平面对DIP池更新执行3步PCC更新。事件和更新处理程序用大约1000行C代码编写，而条目插入/删除是开关驱动程序软件的一部分。\n四、涉及到的基础知识 1.负载均衡(Load Balance) 　现代负载均衡技术通常操作于网络的第四层或第七层。本文提到的是4层(L4)负载均衡技术(具体是什么Google一下吧)。\n　四层的负载均衡就是基于IP+端口的负载均衡：在三层负载均衡的基础上，通过发布三层的IP地址（VIP），然后加四层的端口号，来决定哪些流量需要做负载均衡，对需要处理的流量进行NAT处理，转发至后台服务器，并记录下这个TCP或者UDP的流量是由哪台服务器处理的，后续这个连接的所有流量都同样转发到同一台服务器处理。\n2.VIP(Virtual IP) 　虚拟IP: 就是一个未分配给真实主机的IP，也就是说对外提供数据库服务器的主机除了有一个真实IP外还有一个虚IP，使用这两个IP中的 任意一个都可以连接到这台主机，所有项目中数据库链接一项配置的都是这个虚IP，当服务器发生故障无法对外提供服务时，动态将这个虚IP切换到备用主机。\n　例：主机A，查询主机A IP得到10.1.2.3，主机A还有一个虚拟IP，10.1.2.4，当用户访问10.1.2.4时，会访问到主机A，当用户访问到10.1.2.3时，也会访问到主机A，但当主机A宕机时，可以使得10.1.2.4映射到备用主机B，使得访问10.1.2.4时访问到主机B，从而达到高可用的效果。\n3.DIP(Direct IP) 　直接IP，即真实的IP地址。\n4.连接池 　连接池的作用就是为了提高性能，将已经创建好的连接保存在池中，当有请求来时，直接使用已经创建好的连接对Server端进行访问。这样省略了创建连接和销毁连接的过程（TCP连接建立时的三次握手和销毁时的四次握手），从而在性能上得到了提高。\n5.性能隔离(Performance Isolation) 　一台服务器实例为多个VIP提供服务时各个VIP获得的服务互不影响，则称为性能隔离。\n6.DIP池更新 　向DIP池中添加或删除DIP。大部分DIP池更新来自于服务升级，即服务升级会导致DIP池中DIP的添加或删除。\n7.布隆过滤器(Bloom Filter) 　用来判断一个元素是否存在于集合中。判定不存在的元素一定不存在，判定存在的元素可能不存在。\n","description":"在switch.p4的基础上编写400行P4代码，在一台可编程ASIC交换机上实现百万连接的负载均衡，可代替多达数百个软件负载均衡器，主要解决每个连接一致性问题","id":28,"section":"posts","tags":["P4"],"title":"SilkRoad ：使用ASIC交换机作为高速低成本的有状态四层负载均衡器","uri":"https://yyyIce.github.io/zh/posts/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BBsilkroad/"},{"content":"Sample images from Pixabay\n","description":"随便练点什么","id":29,"section":"gallery","tags":null,"title":"练习","uri":"https://yyyIce.github.io/zh/gallery/%E7%BB%83%E4%B9%A0/"},{"content":"咸鱼的博客。\n这一页没构思好怎么写。\n以后再说吧👍\n","description":"About myself","id":30,"section":"","tags":null,"title":"关于我","uri":"https://yyyIce.github.io/zh/about/"}]